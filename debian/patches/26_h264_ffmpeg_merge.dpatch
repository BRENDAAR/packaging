#! /bin/sh /usr/share/dpatch/dpatch-run
## 26_h264_ffmpeg_merge.dpatch by Michael Haas <laga@laga.ath.cx>
##
## All lines beginning with `## DP:' are a description of the patch.
## DP: Pull h264.c updates and related changesets from ffmpeg trunk
## DP: See http://svn.mythtv.org/trac/ticket/5645 for upstream inclusion status
## DP: h264-resync-fixes.tar.gz in that ticket contains the complete patch
## DP: series 

@DPATCH@

Index: mythtv/libs/libavutil/mathematics.c
===================================================================
--- mythtv/libs/libavutil/mathematics.c	(revision 18209)
+++ mythtv/libs/libavutil/mathematics.c	(working copy)
@@ -113,7 +113,7 @@
 #if 0
 #include "integer.h"
 #undef printf
-main(){
+main(void){
     int64_t a,b,c,d,e;
 
     for(a=7; a<(1LL<<62); a+=a/3+1){
Index: mythtv/libs/libavutil/crc.c
===================================================================
--- mythtv/libs/libavutil/crc.c	(revision 18209)
+++ mythtv/libs/libavutil/crc.c	(working copy)
@@ -107,7 +107,7 @@
 
 #ifdef TEST
 #undef printf
-main(){
+main(void){
     uint8_t buf[1999];
     int i;
     int p[4][4]={{1, 32, AV_CRC_32_IEEE_LE, 0x3D5CDD04},
Index: mythtv/libs/libavutil/md5.c
===================================================================
--- mythtv/libs/libavutil/md5.c	(revision 18209)
+++ mythtv/libs/libavutil/md5.c	(working copy)
@@ -164,7 +164,7 @@
 #ifdef TEST
 #include <stdio.h>
 #undef printf
-main(){
+main(void){
     uint64_t md5val;
     int i;
     uint8_t in[1000];
Index: mythtv/libs/libavutil/lls.c
===================================================================
--- mythtv/libs/libavutil/lls.c	(revision 18209)
+++ mythtv/libs/libavutil/lls.c	(working copy)
@@ -113,7 +113,7 @@
 #include <stdlib.h>
 #include <stdio.h>
 
-int main(){
+int main(void){
     LLSModel m;
     int i, order;
 
Index: mythtv/libs/libavutil/tree.c
===================================================================
--- mythtv/libs/libavutil/tree.c	(revision 18209)
+++ mythtv/libs/libavutil/tree.c	(working copy)
@@ -132,7 +132,7 @@
     return a-b;
 }
 
-int main(){
+int main(void){
     int i,j,k;
     AVTreeNode *root= NULL;
 
Index: mythtv/libs/libavutil/softfloat.c
===================================================================
--- mythtv/libs/libavutil/softfloat.c	(revision 18209)
+++ mythtv/libs/libavutil/softfloat.c	(working copy)
@@ -27,7 +27,7 @@
 
 #undef printf
 
-int main(){
+int main(void){
     SoftFloat one= av_int2sf(1, 0);
     SoftFloat sf1, sf2;
     double d1, d2;
Index: mythtv/libs/libavutil/aes.c
===================================================================
--- mythtv/libs/libavutil/aes.c	(revision 18209)
+++ mythtv/libs/libavutil/aes.c	(working copy)
@@ -194,7 +194,7 @@
 #ifdef TEST
 #include "log.h"
 
-int main(){
+int main(void){
     int i,j;
     AVAES ae, ad, b;
     uint8_t rkey[2][16]= {
Index: mythtv/libs/libavutil/mem.h
===================================================================
--- mythtv/libs/libavutil/mem.h	(revision 18209)
+++ mythtv/libs/libavutil/mem.h	(working copy)
@@ -28,8 +28,10 @@
 
 #ifdef __GNUC__
   #define DECLARE_ALIGNED(n,t,v)       t v __attribute__ ((aligned (n)))
+  #define DECLARE_ASM_CONST(n,t,v)     static const t v attribute_used __attribute__ ((aligned (n)))
 #else
   #define DECLARE_ALIGNED(n,t,v)      __declspec(align(n)) t v
+  #define DECLARE_ASM_CONST(n,t,v)    __declspec(align(n)) static const t v
 #endif
 
 /**
Index: mythtv/libs/libavutil/adler32.c
===================================================================
--- mythtv/libs/libavutil/adler32.c	(revision 18209)
+++ mythtv/libs/libavutil/adler32.c	(working copy)
@@ -54,7 +54,7 @@
 #include "log.h"
 #define LEN 7001
 volatile int checksum;
-int main(){
+int main(void){
     int i;
     char data[LEN];
     av_log_level = AV_LOG_DEBUG;
Index: mythtv/libs/libavutil/sha1.c
===================================================================
--- mythtv/libs/libavutil/sha1.c	(revision 18209)
+++ mythtv/libs/libavutil/sha1.c	(working copy)
@@ -149,7 +149,7 @@
 #include <stdio.h>
 #undef printf
 
-int main(){
+int main(void){
     int i, k;
     AVSHA1 ctx;
     unsigned char digest[20];
Index: mythtv/libs/libavutil/integer.c
===================================================================
--- mythtv/libs/libavutil/integer.c	(revision 18209)
+++ mythtv/libs/libavutil/integer.c	(working copy)
@@ -171,7 +171,7 @@
         7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7
 };
 
-main(){
+main(void){
     int64_t a,b;
 
     for(a=7; a<256*256*256; a+=13215){
Index: mythtv/libs/libavutil/common.h
===================================================================
--- mythtv/libs/libavutil/common.h	(revision 18209)
+++ mythtv/libs/libavutil/common.h	(working copy)
@@ -57,6 +57,14 @@
 #endif
 #endif
 
+#ifndef av_cold
+#if defined(__GNUC__) && (__GNUC__ > 4 || __GNUC__ == 4 && __GNUC_MINOR__ > 2)
+#    define av_cold __attribute__((cold))
+#else
+#    define av_cold
+#endif
+#endif
+
 #ifdef HAVE_AV_CONFIG_H
 #    include "internal.h"
 #endif /* HAVE_AV_CONFIG_H */
@@ -89,7 +97,9 @@
 #define FFSIGN(a) ((a) > 0 ? 1 : -1)
 
 #define FFMAX(a,b) ((a) > (b) ? (a) : (b))
+#define FFMAX3(a,b,c) FFMAX(FFMAX(a,b),c)
 #define FFMIN(a,b) ((a) > (b) ? (b) : (a))
+#define FFMIN3(a,b,c) FFMIN(FFMIN(a,b),c)
 
 #define FFSWAP(type,a,b) do{type SWAP_tmp= b; b= a; a= SWAP_tmp;}while(0)
 
Index: mythtv/libs/libavcodec/dvbsubdec.c
===================================================================
--- mythtv/libs/libavcodec/dvbsubdec.c	(revision 18209)
+++ mythtv/libs/libavcodec/dvbsubdec.c	(working copy)
@@ -340,7 +340,7 @@
         av_log(0, AV_LOG_ERROR, "Memory deallocation error!\n");
 }
 
-static int dvbsub_init_decoder(AVCodecContext *avctx)
+static av_cold int dvbsub_init_decoder(AVCodecContext *avctx)
 {
     int i, r, g, b, a = 0;
     DVBSubContext *ctx = (DVBSubContext*) avctx->priv_data;
@@ -413,7 +413,7 @@
     return 0;
 }
 
-static int dvbsub_close_decoder(AVCodecContext *avctx)
+static av_cold int dvbsub_close_decoder(AVCodecContext *avctx)
 {
     DVBSubContext *ctx = (DVBSubContext*) avctx->priv_data;
     DVBSubRegionDisplay *display;
Index: mythtv/libs/libavcodec/nellymoserdec.c
===================================================================
--- mythtv/libs/libavcodec/nellymoserdec.c	(revision 18209)
+++ mythtv/libs/libavcodec/nellymoserdec.c	(working copy)
@@ -329,7 +329,7 @@
     }
 }
 
-static int decode_init(AVCodecContext * avctx) {
+static av_cold int decode_init(AVCodecContext * avctx) {
     NellyMoserDecodeContext *s = avctx->priv_data;
     int i;
 
@@ -391,7 +391,7 @@
     return buf_size;
 }
 
-static int decode_end(AVCodecContext * avctx) {
+static av_cold int decode_end(AVCodecContext * avctx) {
     NellyMoserDecodeContext *s = avctx->priv_data;
 
     ff_mdct_end(&s->imdct_ctx);
Index: mythtv/libs/libavcodec/nuv.c
===================================================================
--- mythtv/libs/libavcodec/nuv.c	(revision 18209)
+++ mythtv/libs/libavcodec/nuv.c	(working copy)
@@ -236,7 +236,7 @@
     return orig_size;
 }
 
-static int decode_init(AVCodecContext *avctx) {
+static av_cold int decode_init(AVCodecContext *avctx) {
     NuvContext *c = avctx->priv_data;
     avctx->pix_fmt = PIX_FMT_YUV420P;
     c->pic.data[0] = NULL;
@@ -253,7 +253,7 @@
     return 0;
 }
 
-static int decode_end(AVCodecContext *avctx) {
+static av_cold int decode_end(AVCodecContext *avctx) {
     NuvContext *c = avctx->priv_data;
     av_freep(&c->decomp_buf);
     if (c->pic.data[0])
Index: mythtv/libs/libavcodec/roqaudioenc.c
===================================================================
--- mythtv/libs/libavcodec/roqaudioenc.c	(revision 18209)
+++ mythtv/libs/libavcodec/roqaudioenc.c	(working copy)
@@ -37,7 +37,7 @@
     short lastSample[2];
 } ROQDPCMContext_t;
 
-static void roq_dpcm_table_init(void)
+static av_cold void roq_dpcm_table_init(void)
 {
     int i;
 
@@ -158,7 +158,7 @@
     return out - frame;
 }
 
-static int roq_dpcm_encode_close(AVCodecContext *avctx)
+static av_cold int roq_dpcm_encode_close(AVCodecContext *avctx)
 {
     av_freep(&avctx->coded_frame);
 
Index: mythtv/libs/libavcodec/vcr1.c
===================================================================
--- mythtv/libs/libavcodec/vcr1.c	(revision 18209)
+++ mythtv/libs/libavcodec/vcr1.c	(working copy)
@@ -137,14 +137,14 @@
 }
 #endif
 
-static void common_init(AVCodecContext *avctx){
+static av_cold void common_init(AVCodecContext *avctx){
     VCR1Context * const a = avctx->priv_data;
 
     avctx->coded_frame= (AVFrame*)&a->picture;
     a->avctx= avctx;
 }
 
-static int decode_init(AVCodecContext *avctx){
+static av_cold int decode_init(AVCodecContext *avctx){
 
     common_init(avctx);
 
@@ -154,7 +154,7 @@
 }
 
 #if 0
-static int encode_init(AVCodecContext *avctx){
+static av_cold int encode_init(AVCodecContext *avctx){
 
     common_init(avctx);
 
Index: mythtv/libs/libavcodec/libxvidff.c
===================================================================
--- mythtv/libs/libavcodec/libxvidff.c	(revision 18209)
+++ mythtv/libs/libavcodec/libxvidff.c	(working copy)
@@ -83,7 +83,7 @@
  * @param avctx AVCodecContext pointer to context
  * @return Returns 0 on success, -1 on failure
  */
-int ff_xvid_encode_init(AVCodecContext *avctx)  {
+av_cold int ff_xvid_encode_init(AVCodecContext *avctx)  {
     int xerr, i;
     int xvid_flags = avctx->flags;
     xvid_context_t *x = avctx->priv_data;
@@ -463,7 +463,7 @@
  * @param avctx AVCodecContext pointer to context
  * @return Returns 0, success guaranteed
  */
-int ff_xvid_encode_close(AVCodecContext *avctx) {
+av_cold int ff_xvid_encode_close(AVCodecContext *avctx) {
     xvid_context_t *x = avctx->priv_data;
 
     xvid_encore(x->encoder_handle, XVID_ENC_DESTROY, NULL, NULL);
Index: mythtv/libs/libavcodec/vqavideo.c
===================================================================
--- mythtv/libs/libavcodec/vqavideo.c	(revision 18209)
+++ mythtv/libs/libavcodec/vqavideo.c	(working copy)
@@ -54,7 +54,7 @@
  * file. This is an interesting technique, although it makes random file
  * seeking difficult despite the fact that the frames are all intracoded.
  *
- * V1,2 VQA uses 12-bit codebook indices. If the 12-bit indices were
+ * V1,2 VQA uses 12-bit codebook indexes. If the 12-bit indexes were
  * packed into bytes and then RLE compressed, bytewise, the results would
  * be poor. That is why the coding method divides each index into 2 parts,
  * the top 4 bits and the bottom 8 bits, then RL encodes the 4-bit pieces
@@ -129,11 +129,11 @@
 
 } VqaContext;
 
-static int vqa_decode_init(AVCodecContext *avctx)
+static av_cold int vqa_decode_init(AVCodecContext *avctx)
 {
     VqaContext *s = avctx->priv_data;
     unsigned char *vqa_header;
-    int i, j, codebook_index;;
+    int i, j, codebook_index;
 
     s->avctx = avctx;
     avctx->pix_fmt = PIX_FMT_PAL8;
@@ -595,7 +595,7 @@
     return buf_size;
 }
 
-static int vqa_decode_end(AVCodecContext *avctx)
+static av_cold int vqa_decode_end(AVCodecContext *avctx)
 {
     VqaContext *s = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/indeo2.c
===================================================================
--- mythtv/libs/libavcodec/indeo2.c	(revision 18209)
+++ mythtv/libs/libavcodec/indeo2.c	(working copy)
@@ -188,7 +188,7 @@
     return buf_size;
 }
 
-static int ir2_decode_init(AVCodecContext *avctx){
+static av_cold int ir2_decode_init(AVCodecContext *avctx){
     Ir2Context * const ic = avctx->priv_data;
 
     ic->avctx = avctx;
Index: mythtv/libs/libavcodec/libfaad.c
===================================================================
--- mythtv/libs/libavcodec/libfaad.c	(revision 18209)
+++ mythtv/libs/libavcodec/libfaad.c	(working copy)
@@ -192,7 +192,7 @@
 #endif
 }
 
-static int faac_decode_end(AVCodecContext *avctx)
+static av_cold int faac_decode_end(AVCodecContext *avctx)
 {
     FAACContext *s = avctx->priv_data;
 
@@ -202,7 +202,7 @@
     return 0;
 }
 
-static int faac_decode_init(AVCodecContext *avctx)
+static av_cold int faac_decode_init(AVCodecContext *avctx)
 {
     FAACContext *s = avctx->priv_data;
     faacDecConfigurationPtr faac_cfg;
Index: mythtv/libs/libavcodec/ac3dec.c
===================================================================
--- mythtv/libs/libavcodec/ac3dec.c	(revision 18209)
+++ mythtv/libs/libavcodec/ac3dec.c	(working copy)
@@ -237,7 +237,7 @@
 /*
  * Initialize tables at runtime.
  */
-static void ac3_tables_init(void)
+static av_cold void ac3_tables_init(void)
 {
     int i;
 
@@ -303,7 +303,7 @@
 /**
  * AVCodec initialization
  */
-static int ac3_decode_init(AVCodecContext *avctx)
+static av_cold int ac3_decode_init(AVCodecContext *avctx)
 {
     AC3DecodeContext *ctx = avctx->priv_data;
     ctx->avctx = avctx;
@@ -1185,7 +1185,7 @@
 /**
  * Uninitialize the AC-3 decoder.
  */
-static int ac3_decode_end(AVCodecContext *avctx)
+static av_cold int ac3_decode_end(AVCodecContext *avctx)
 {
     AC3DecodeContext *ctx = (AC3DecodeContext *)avctx->priv_data;
     ff_mdct_end(&ctx->imdct_512);
Index: mythtv/libs/libavcodec/smacker.c
===================================================================
--- mythtv/libs/libavcodec/smacker.c	(revision 18209)
+++ mythtv/libs/libavcodec/smacker.c	(working copy)
@@ -509,7 +509,7 @@
  * Init smacker decoder
  *
  */
-static int decode_init(AVCodecContext *avctx)
+static av_cold int decode_init(AVCodecContext *avctx)
 {
     SmackVContext * const c = avctx->priv_data;
 
@@ -543,7 +543,7 @@
  * Uninit smacker decoder
  *
  */
-static int decode_end(AVCodecContext *avctx)
+static av_cold int decode_end(AVCodecContext *avctx)
 {
     SmackVContext * const smk = avctx->priv_data;
 
@@ -559,7 +559,7 @@
 }
 
 
-static int smka_decode_init(AVCodecContext *avctx)
+static av_cold int smka_decode_init(AVCodecContext *avctx)
 {
     return 0;
 }
Index: mythtv/libs/libavcodec/sparc/dsputil_vis.c
===================================================================
--- mythtv/libs/libavcodec/sparc/dsputil_vis.c	(revision 18209)
+++ mythtv/libs/libavcodec/sparc/dsputil_vis.c	(working copy)
@@ -3999,7 +3999,7 @@
 /* libavcodec initialization code */
 void dsputil_init_vis(DSPContext* c, AVCodecContext *avctx)
 {
-  /* VIS specific optimisations */
+  /* VIS specific optimizations */
   int accel = vis_level ();
 
   if (accel & ACCEL_SPARC_VIS) {
Index: mythtv/libs/libavcodec/cljr.c
===================================================================
--- mythtv/libs/libavcodec/cljr.c	(revision 18209)
+++ mythtv/libs/libavcodec/cljr.c	(working copy)
@@ -104,14 +104,14 @@
 }
 #endif
 
-static void common_init(AVCodecContext *avctx){
+static av_cold void common_init(AVCodecContext *avctx){
     CLJRContext * const a = avctx->priv_data;
 
     avctx->coded_frame= (AVFrame*)&a->picture;
     a->avctx= avctx;
 }
 
-static int decode_init(AVCodecContext *avctx){
+static av_cold int decode_init(AVCodecContext *avctx){
 
     common_init(avctx);
 
@@ -121,7 +121,7 @@
 }
 
 #if 0
-static int encode_init(AVCodecContext *avctx){
+static av_cold int encode_init(AVCodecContext *avctx){
 
     common_init(avctx);
 
Index: mythtv/libs/libavcodec/dnxhdenc.c
===================================================================
--- mythtv/libs/libavcodec/dnxhdenc.c	(revision 18209)
+++ mythtv/libs/libavcodec/dnxhdenc.c	(working copy)
@@ -47,7 +47,7 @@
     AVFrame frame;
     int cid;
     const CIDEntry *cid_table;
-    uint8_t *msip; ///< Macroblock Scan Indices Payload
+    uint8_t *msip; ///< Macroblock Scan Indexes Payload
     uint32_t *slice_size;
 
     struct DNXHDEncContext *thread[MAX_THREADS];
Index: mythtv/libs/libavcodec/libvorbis.c
===================================================================
--- mythtv/libs/libavcodec/libvorbis.c	(revision 18209)
+++ mythtv/libs/libavcodec/libvorbis.c	(working copy)
@@ -81,7 +81,7 @@
     return vorbis_encode_setup_init(vi);
 }
 
-static int oggvorbis_encode_init(AVCodecContext *avccontext) {
+static av_cold int oggvorbis_encode_init(AVCodecContext *avccontext) {
     OggVorbisContext *context = avccontext->priv_data ;
     ogg_packet header, header_comm, header_code;
     uint8_t *p;
@@ -191,7 +191,7 @@
 }
 
 
-static int oggvorbis_encode_close(AVCodecContext *avccontext) {
+static av_cold int oggvorbis_encode_close(AVCodecContext *avccontext) {
     OggVorbisContext *context = avccontext->priv_data ;
 /*  ogg_packet op ; */
 
Index: mythtv/libs/libavcodec/h264pred.c
===================================================================
--- mythtv/libs/libavcodec/h264pred.c	(revision 18209)
+++ mythtv/libs/libavcodec/h264pred.c	(working copy)
@@ -677,6 +677,29 @@
     }
 }
 
+//the following 4 function should not be optimized!
+static void pred8x8_mad_cow_dc_l0t(uint8_t *src, int stride){
+    pred8x8_top_dc_c(src, stride);
+    pred4x4_dc_c(src, NULL, stride);
+}
+
+static void pred8x8_mad_cow_dc_0lt(uint8_t *src, int stride){
+    pred8x8_dc_c(src, stride);
+    pred4x4_top_dc_c(src, NULL, stride);
+}
+
+static void pred8x8_mad_cow_dc_l00(uint8_t *src, int stride){
+    pred8x8_left_dc_c(src, stride);
+    pred4x4_128_dc_c(src + 4*stride    , NULL, stride);
+    pred4x4_128_dc_c(src + 4*stride + 4, NULL, stride);
+}
+
+static void pred8x8_mad_cow_dc_0l0(uint8_t *src, int stride){
+    pred8x8_left_dc_c(src, stride);
+    pred4x4_128_dc_c(src    , NULL, stride);
+    pred4x4_128_dc_c(src + 4, NULL, stride);
+}
+
 static void pred8x8_dc_rv40_c(uint8_t *src, int stride){
     int i;
     int dc0=0;
@@ -1032,6 +1055,10 @@
         h->pred8x8[DC_PRED8x8     ]= pred8x8_dc_c;
         h->pred8x8[LEFT_DC_PRED8x8]= pred8x8_left_dc_c;
         h->pred8x8[TOP_DC_PRED8x8 ]= pred8x8_top_dc_c;
+        h->pred8x8[ALZHEIMER_DC_L0T_PRED8x8 ]= pred8x8_mad_cow_dc_l0t;
+        h->pred8x8[ALZHEIMER_DC_0LT_PRED8x8 ]= pred8x8_mad_cow_dc_0lt;
+        h->pred8x8[ALZHEIMER_DC_L00_PRED8x8 ]= pred8x8_mad_cow_dc_l00;
+        h->pred8x8[ALZHEIMER_DC_0L0_PRED8x8 ]= pred8x8_mad_cow_dc_0l0;
     }else{
         h->pred8x8[DC_PRED8x8     ]= pred8x8_dc_rv40_c;
         h->pred8x8[LEFT_DC_PRED8x8]= pred8x8_left_dc_rv40_c;
Index: mythtv/libs/libavcodec/adxenc.c
===================================================================
--- mythtv/libs/libavcodec/adxenc.c	(revision 18209)
+++ mythtv/libs/libavcodec/adxenc.c	(working copy)
@@ -110,7 +110,7 @@
     return 0x20+4;
 }
 
-static int adx_encode_init(AVCodecContext *avctx)
+static av_cold int adx_encode_init(AVCodecContext *avctx)
 {
     if (avctx->channels > 2)
         return -1; /* only stereo or mono =) */
@@ -126,7 +126,7 @@
     return 0;
 }
 
-static int adx_encode_close(AVCodecContext *avctx)
+static av_cold int adx_encode_close(AVCodecContext *avctx)
 {
     av_freep(&avctx->coded_frame);
 
Index: mythtv/libs/libavcodec/h264pred.h
===================================================================
--- mythtv/libs/libavcodec/h264pred.h	(revision 18209)
+++ mythtv/libs/libavcodec/h264pred.h	(working copy)
@@ -59,6 +59,11 @@
 #define LEFT_DC_PRED8x8       4
 #define TOP_DC_PRED8x8        5
 #define DC_128_PRED8x8        6
+
+#define ALZHEIMER_DC_L0T_PRED8x8 7
+#define ALZHEIMER_DC_0LT_PRED8x8 8
+#define ALZHEIMER_DC_L00_PRED8x8 9
+#define ALZHEIMER_DC_0L0_PRED8x8 10
 //@}
 
 /**
@@ -67,7 +72,7 @@
 typedef struct H264PredContext{
     void (*pred4x4  [9+3+2])(uint8_t *src, uint8_t *topright, int stride);//FIXME move to dsp?
     void (*pred8x8l [9+3])(uint8_t *src, int topleft, int topright, int stride);
-    void (*pred8x8  [4+3])(uint8_t *src, int stride);
+    void (*pred8x8  [4+3+4])(uint8_t *src, int stride);
     void (*pred16x16[4+3])(uint8_t *src, int stride);
 }H264PredContext;
 
Index: mythtv/libs/libavcodec/i386/mpegvideo_mmx.c
===================================================================
--- mythtv/libs/libavcodec/i386/mpegvideo_mmx.c	(revision 18209)
+++ mythtv/libs/libavcodec/i386/mpegvideo_mmx.c	(working copy)
@@ -179,7 +179,7 @@
                 if (level < -2048 || level > 2047)
                     fprintf(stderr, "unquant error %d %d\n", i, level);
 #endif
-  We can suppose that result of two multiplications can't be greate of 0xFFFF
+  We can suppose that result of two multiplications can't be greater than 0xFFFF
   i.e. is 16-bit, so we use here only PMULLW instruction and can avoid
   a complex multiplication.
 =====================================================
Index: mythtv/libs/libavcodec/i386/h264_i386.h
===================================================================
--- mythtv/libs/libavcodec/i386/h264_i386.h	(revision 0)
+++ mythtv/libs/libavcodec/i386/h264_i386.h	(revision 0)
@@ -0,0 +1,144 @@
+/*
+ * H.26L/H.264/AVC/JVT/14496-10/... encoder/decoder
+ * Copyright (c) 2003 Michael Niedermayer <michaelni@gmx.at>
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+/**
+ * @file h264_i386.h
+ * H.264 / AVC / MPEG4 part10 codec.
+ * non-MMX i386-specific optimizations for H.264
+ * @author Michael Niedermayer <michaelni@gmx.at>
+ */
+
+#ifndef FFMPEG_H264_I386_H
+#define FFMPEG_H264_I386_H
+
+
+#include "cabac.h"
+
+//FIXME use some macros to avoid duplicatin get_cabac (cannot be done yet as that would make optimization work hard)
+#if defined(ARCH_X86) && defined(HAVE_7REGS) && defined(HAVE_EBX_AVAILABLE) && !defined(BROKEN_RELOCATIONS)
+static int decode_significance_x86(CABACContext *c, int max_coeff, uint8_t *significant_coeff_ctx_base, int *index){
+    void *end= significant_coeff_ctx_base + max_coeff - 1;
+    int minusstart= -(int)significant_coeff_ctx_base;
+    int minusindex= 4-(int)index;
+    int coeff_count;
+    asm volatile(
+        "movl "RANGE    "(%3), %%esi            \n\t"
+        "movl "LOW      "(%3), %%ebx            \n\t"
+
+        "2:                                     \n\t"
+
+        BRANCHLESS_GET_CABAC("%%edx", "%3", "(%1)", "%%ebx", "%%bx", "%%esi", "%%eax", "%%al")
+
+        "test $1, %%edx                         \n\t"
+        " jz 3f                                 \n\t"
+
+        BRANCHLESS_GET_CABAC("%%edx", "%3", "61(%1)", "%%ebx", "%%bx", "%%esi", "%%eax", "%%al")
+
+        "mov  %2, %%"REG_a"                     \n\t"
+        "movl %4, %%ecx                         \n\t"
+        "add  %1, %%"REG_c"                     \n\t"
+        "movl %%ecx, (%%"REG_a")                \n\t"
+
+        "test $1, %%edx                         \n\t"
+        " jnz 4f                                \n\t"
+
+        "add  $4, %%"REG_a"                     \n\t"
+        "mov  %%"REG_a", %2                     \n\t"
+
+        "3:                                     \n\t"
+        "add  $1, %1                            \n\t"
+        "cmp  %5, %1                            \n\t"
+        " jb 2b                                 \n\t"
+        "mov  %2, %%"REG_a"                     \n\t"
+        "movl %4, %%ecx                         \n\t"
+        "add  %1, %%"REG_c"                     \n\t"
+        "movl %%ecx, (%%"REG_a")                \n\t"
+        "4:                                     \n\t"
+        "add  %6, %%eax                         \n\t"
+        "shr $2, %%eax                          \n\t"
+
+        "movl %%esi, "RANGE    "(%3)            \n\t"
+        "movl %%ebx, "LOW      "(%3)            \n\t"
+        :"=&a"(coeff_count), "+r"(significant_coeff_ctx_base), "+m"(index)
+        :"r"(c), "m"(minusstart), "m"(end), "m"(minusindex)
+        : "%"REG_c, "%ebx", "%edx", "%esi", "memory"
+    );
+    return coeff_count;
+}
+
+static int decode_significance_8x8_x86(CABACContext *c, uint8_t *significant_coeff_ctx_base, int *index, const uint8_t *sig_off){
+    int minusindex= 4-(int)index;
+    int coeff_count;
+    long last=0;
+    asm volatile(
+        "movl "RANGE    "(%3), %%esi            \n\t"
+        "movl "LOW      "(%3), %%ebx            \n\t"
+
+        "mov %1, %%"REG_D"                      \n\t"
+        "2:                                     \n\t"
+
+        "mov %6, %%"REG_a"                      \n\t"
+        "movzbl (%%"REG_a", %%"REG_D"), %%edi   \n\t"
+        "add %5, %%"REG_D"                      \n\t"
+
+        BRANCHLESS_GET_CABAC("%%edx", "%3", "(%%"REG_D")", "%%ebx", "%%bx", "%%esi", "%%eax", "%%al")
+
+        "mov %1, %%edi                          \n\t"
+        "test $1, %%edx                         \n\t"
+        " jz 3f                                 \n\t"
+
+        "movzbl "MANGLE(last_coeff_flag_offset_8x8)"(%%edi), %%edi\n\t"
+        "add %5, %%"REG_D"                      \n\t"
+
+        BRANCHLESS_GET_CABAC("%%edx", "%3", "15(%%"REG_D")", "%%ebx", "%%bx", "%%esi", "%%eax", "%%al")
+
+        "mov %2, %%"REG_a"                      \n\t"
+        "mov %1, %%edi                          \n\t"
+        "movl %%edi, (%%"REG_a")                \n\t"
+
+        "test $1, %%edx                         \n\t"
+        " jnz 4f                                \n\t"
+
+        "add $4, %%"REG_a"                      \n\t"
+        "mov %%"REG_a", %2                      \n\t"
+
+        "3:                                     \n\t"
+        "addl $1, %%edi                         \n\t"
+        "mov %%edi, %1                          \n\t"
+        "cmpl $63, %%edi                        \n\t"
+        " jb 2b                                 \n\t"
+        "mov %2, %%"REG_a"                      \n\t"
+        "movl %%edi, (%%"REG_a")                \n\t"
+        "4:                                     \n\t"
+        "addl %4, %%eax                         \n\t"
+        "shr $2, %%eax                          \n\t"
+
+        "movl %%esi, "RANGE    "(%3)            \n\t"
+        "movl %%ebx, "LOW      "(%3)            \n\t"
+        :"=&a"(coeff_count),"+m"(last), "+m"(index)
+        :"r"(c), "m"(minusindex), "m"(significant_coeff_ctx_base), "m"(sig_off)
+        : "%"REG_c, "%ebx", "%edx", "%esi", "%"REG_D, "memory"
+    );
+    return coeff_count;
+}
+#endif /* defined(ARCH_X86) && && defined(HAVE_7REGS) && defined(HAVE_EBX_AVAILABLE) && !defined(BROKEN_RELOCATIONS) */
+
+#endif /* FFMPEG_H264_I386_H */
Index: mythtv/libs/libavcodec/i386/motion_est_mmx.c
===================================================================
--- mythtv/libs/libavcodec/i386/motion_est_mmx.c	(revision 18209)
+++ mythtv/libs/libavcodec/i386/motion_est_mmx.c	(working copy)
@@ -24,13 +24,13 @@
 #include "dsputil.h"
 #include "x86_cpu.h"
 
-static const __attribute__ ((aligned(8))) uint64_t round_tab[3]={
+DECLARE_ASM_CONST(8, uint64_t, round_tab[3])={
 0x0000000000000000ULL,
 0x0001000100010001ULL,
 0x0002000200020002ULL,
 };
 
-static attribute_used __attribute__ ((aligned(8))) uint64_t bone= 0x0101010101010101LL;
+DECLARE_ASM_CONST(8, uint64_t, bone)= 0x0101010101010101LL;
 
 static inline void sad8_1_mmx(uint8_t *blk1, uint8_t *blk2, int stride, int h)
 {
Index: mythtv/libs/libavcodec/i386/idct_mmx.c
===================================================================
--- mythtv/libs/libavcodec/i386/idct_mmx.c	(revision 18209)
+++ mythtv/libs/libavcodec/i386/idct_mmx.c	(working copy)
@@ -397,7 +397,7 @@
     static const short _T3[] ATTR_ALIGN(8) = {T3,T3,T3,T3};
     static const short _C4[] ATTR_ALIGN(8) = {C4,C4,C4,C4};
 
-    /* column code adapted from peter gubanov */
+    /* column code adapted from Peter Gubanov */
     /* http://www.elecard.com/peter/idct.shtml */
 
     movq_m2r (*_T1, mm0);               // mm0 = T1
Index: mythtv/libs/libavcodec/i386/dsputil_mmx.c
===================================================================
--- mythtv/libs/libavcodec/i386/dsputil_mmx.c	(revision 18209)
+++ mythtv/libs/libavcodec/i386/dsputil_mmx.c	(working copy)
@@ -790,7 +790,7 @@
       "movq (%1,%3),%%mm4\n"    /* mm4 = pix2[1][0-7] */
 
       /* todo: mm1-mm2, mm3-mm4 */
-      /* algo: substract mm1 from mm2 with saturation and vice versa */
+      /* algo: subtract mm1 from mm2 with saturation and vice versa */
       /*       OR the results to get absolute difference */
       "movq %%mm1,%%mm5\n"
       "movq %%mm3,%%mm6\n"
@@ -850,7 +850,7 @@
       "movq 8(%1),%%mm4\n"      /* mm4 = pix2[8-15] */
 
       /* todo: mm1-mm2, mm3-mm4 */
-      /* algo: substract mm1 from mm2 with saturation and vice versa */
+      /* algo: subtract mm1 from mm2 with saturation and vice versa */
       /*       OR the results to get absolute difference */
       "movq %%mm1,%%mm5\n"
       "movq %%mm3,%%mm6\n"
@@ -910,7 +910,7 @@
       "movdqu (%1,%4),%%xmm4\n" /* mm4 = pix2[1][0-15] */
 
       /* todo: mm1-mm2, mm3-mm4 */
-      /* algo: substract mm1 from mm2 with saturation and vice versa */
+      /* algo: subtract mm1 from mm2 with saturation and vice versa */
       /*       OR the results to get absolute difference */
       "movdqa %%xmm1,%%xmm5\n"
       "movdqa %%xmm3,%%xmm6\n"
Index: mythtv/libs/libavcodec/i386/h264dsp_mmx.c
===================================================================
--- mythtv/libs/libavcodec/i386/h264dsp_mmx.c	(revision 18209)
+++ mythtv/libs/libavcodec/i386/h264dsp_mmx.c	(working copy)
@@ -19,6 +19,9 @@
  */
 
 
+DECLARE_ALIGNED_8 (static const uint64_t, ff_pb_3_1  ) = 0x0103010301030103ULL;
+DECLARE_ALIGNED_8 (static const uint64_t, ff_pb_7_3  ) = 0x0307030703070307ULL;
+
 /***********************************/
 /* IDCT */
 
@@ -547,7 +550,7 @@
 }
 
 static void h264_loop_filter_strength_mmx2( int16_t bS[2][4][4], uint8_t nnz[40], int8_t ref[2][40], int16_t mv[2][40][2],
-                                            int bidir, int edges, int step, int mask_mv0, int mask_mv1 ) {
+                                            int bidir, int edges, int step, int mask_mv0, int mask_mv1, int field ) {
     int dir;
     asm volatile(
         "pxor %%mm7, %%mm7 \n\t"
@@ -556,6 +559,13 @@
         "movq %2, %%mm4 \n\t"
         ::"m"(ff_pb_1), "m"(ff_pb_3), "m"(ff_pb_7)
     );
+    if(field)
+        asm volatile(
+            "movq %0, %%mm5 \n\t"
+            "movq %1, %%mm4 \n\t"
+            ::"m"(ff_pb_3_1), "m"(ff_pb_7_3)
+        );
+
     // could do a special case for dir==0 && edges==1, but it only reduces the
     // average filter time by 1.2%
     for( dir=1; dir>=0; dir-- ) {
Index: mythtv/libs/libavcodec/i386/simple_idct_mmx.c
===================================================================
--- mythtv/libs/libavcodec/i386/simple_idct_mmx.c	(revision 18209)
+++ mythtv/libs/libavcodec/i386/simple_idct_mmx.c	(working copy)
@@ -48,8 +48,8 @@
 #define ROW_SHIFT 11
 #define COL_SHIFT 20 // 6
 
-static const uint64_t attribute_used __attribute__((aligned(8))) wm1010= 0xFFFF0000FFFF0000ULL;
-static const uint64_t attribute_used __attribute__((aligned(8))) d40000= 0x0000000000040000ULL;
+DECLARE_ASM_CONST(8, uint64_t, wm1010)= 0xFFFF0000FFFF0000ULL;
+DECLARE_ASM_CONST(8, uint64_t, d40000)= 0x0000000000040000ULL;
 
 static const int16_t __attribute__((aligned(8))) coeffs[]= {
         1<<(ROW_SHIFT-1), 0, 1<<(ROW_SHIFT-1), 0,
Index: mythtv/libs/libavcodec/i386/cavsdsp_mmx.c
===================================================================
--- mythtv/libs/libavcodec/i386/cavsdsp_mmx.c	(revision 18209)
+++ mythtv/libs/libavcodec/i386/cavsdsp_mmx.c	(working copy)
@@ -2,7 +2,7 @@
  * Chinese AVS video (AVS1-P2, JiZhun profile) decoder.
  * Copyright (c) 2006  Stefan Gehrer <stefan.gehrer@gmx.de>
  *
- * MMX optimised DSP functions, based on H.264 optimisations by
+ * MMX optimized DSP functions, based on H.264 optimizations by
  * Michael Niedermayer and Loren Merritt
  *
  * This file is part of FFmpeg.
Index: mythtv/libs/libavcodec/dv.c
===================================================================
--- mythtv/libs/libavcodec/dv.c	(revision 18209)
+++ mythtv/libs/libavcodec/dv.c	(working copy)
@@ -107,7 +107,7 @@
     }
 }
 
-static int dvvideo_init(AVCodecContext *avctx)
+static av_cold int dvvideo_init(AVCodecContext *avctx)
 {
     DVVideoContext *s = avctx->priv_data;
     DSPContext dsp;
Index: mythtv/libs/libavcodec/pngenc.c
===================================================================
--- mythtv/libs/libavcodec/pngenc.c	(revision 18209)
+++ mythtv/libs/libavcodec/pngenc.c	(working copy)
@@ -313,7 +313,7 @@
     goto the_end;
 }
 
-static int png_enc_init(AVCodecContext *avctx){
+static av_cold int png_enc_init(AVCodecContext *avctx){
     PNGEncContext *s = avctx->priv_data;
 
     avcodec_get_frame_defaults((AVFrame*)&s->picture);
Index: mythtv/libs/libavcodec/idcinvideo.c
===================================================================
--- mythtv/libs/libavcodec/idcinvideo.c	(revision 18209)
+++ mythtv/libs/libavcodec/idcinvideo.c	(working copy)
@@ -115,7 +115,7 @@
  *  num_huff_nodes[prev] - contains the index to the root node of the tree.
  *    That is: huff_nodes[prev][num_huff_nodes[prev]] is the root node.
  */
-static void huff_build_tree(IdcinContext *s, int prev) {
+static av_cold void huff_build_tree(IdcinContext *s, int prev) {
     hnode_t *node, *hnodes;
      int num_hnodes, i;
 
@@ -145,7 +145,7 @@
     s->num_huff_nodes[prev] = num_hnodes - 1;
 }
 
-static int idcin_decode_init(AVCodecContext *avctx)
+static av_cold int idcin_decode_init(AVCodecContext *avctx)
 {
     IdcinContext *s = avctx->priv_data;
     int i, j, histogram_index = 0;
@@ -245,7 +245,7 @@
     return buf_size;
 }
 
-static int idcin_decode_end(AVCodecContext *avctx)
+static av_cold int idcin_decode_end(AVCodecContext *avctx)
 {
     IdcinContext *s = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/rawenc.c
===================================================================
--- mythtv/libs/libavcodec/rawenc.c	(revision 18209)
+++ mythtv/libs/libavcodec/rawenc.c	(working copy)
@@ -27,7 +27,7 @@
 #include "avcodec.h"
 #include "raw.h"
 
-static int raw_init_encoder(AVCodecContext *avctx)
+static av_cold int raw_init_encoder(AVCodecContext *avctx)
 {
     avctx->coded_frame = (AVFrame *)avctx->priv_data;
     avctx->coded_frame->pict_type = FF_I_TYPE;
Index: mythtv/libs/libavcodec/dnxhddec.c
===================================================================
--- mythtv/libs/libavcodec/dnxhddec.c	(revision 18209)
+++ mythtv/libs/libavcodec/dnxhddec.c	(working copy)
@@ -48,7 +48,7 @@
 #define DNXHD_VLC_BITS 9
 #define DNXHD_DC_VLC_BITS 7
 
-static int dnxhd_decode_init(AVCodecContext *avctx)
+static av_cold int dnxhd_decode_init(AVCodecContext *avctx)
 {
     DNXHDContext *ctx = avctx->priv_data;
 
@@ -321,7 +321,7 @@
     return buf_size;
 }
 
-static int dnxhd_decode_close(AVCodecContext *avctx)
+static av_cold int dnxhd_decode_close(AVCodecContext *avctx)
 {
     DNXHDContext *ctx = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/motion-test.c
===================================================================
--- mythtv/libs/libavcodec/motion-test.c	(revision 18209)
+++ mythtv/libs/libavcodec/motion-test.c	(working copy)
@@ -112,7 +112,7 @@
         }
     }
     emms_c();
-    dummy = d1; /* avoid optimisation */
+    dummy = d1; /* avoid optimization */
     ti = gettime() - ti;
 
     printf("  %0.0f kop/s\n",
Index: mythtv/libs/libavcodec/rv10.c
===================================================================
--- mythtv/libs/libavcodec/rv10.c	(revision 18209)
+++ mythtv/libs/libavcodec/rv10.c	(working copy)
@@ -240,13 +240,13 @@
 
     put_bits(&s->pb, 1, 1);     /* marker */
 
-    put_bits(&s->pb, 1, (s->pict_type == P_TYPE));
+    put_bits(&s->pb, 1, (s->pict_type == FF_P_TYPE));
 
     put_bits(&s->pb, 1, 0);     /* not PB frame */
 
     put_bits(&s->pb, 5, s->qscale);
 
-    if (s->pict_type == I_TYPE) {
+    if (s->pict_type == FF_I_TYPE) {
         /* specific MPEG like DC coding not used */
     }
     /* if multiple packets per frame are sent, the position at which
@@ -273,13 +273,13 @@
 
     assert(s->f_code == 1);
     assert(s->unrestricted_mv == 1);
-//    assert(s->h263_aic== (s->pict_type == I_TYPE));
+//    assert(s->h263_aic== (s->pict_type == FF_I_TYPE));
     assert(s->alt_inter_vlc == 0);
     assert(s->umvplus == 0);
     assert(s->modified_quant==1);
     assert(s->loop_filter==1);
 
-    s->h263_aic= s->pict_type == I_TYPE;
+    s->h263_aic= s->pict_type == FF_I_TYPE;
     if(s->h263_aic){
         s->y_dc_scale_table=
         s->c_dc_scale_table= ff_aic_dc_scale_table;
@@ -315,9 +315,9 @@
     marker = get_bits1(&s->gb);
 
     if (get_bits1(&s->gb))
-        s->pict_type = P_TYPE;
+        s->pict_type = FF_P_TYPE;
     else
-        s->pict_type = I_TYPE;
+        s->pict_type = FF_I_TYPE;
 //printf("h:%X ver:%d\n",h,s->rv10_version);
     if(!marker) av_log(s->avctx, AV_LOG_ERROR, "marker missing\n");
     pb_frame = get_bits1(&s->gb);
@@ -337,7 +337,7 @@
         return -1;
     }
 
-    if (s->pict_type == I_TYPE) {
+    if (s->pict_type == FF_I_TYPE) {
         if (s->rv10_version == 3) {
             /* specific MPEG like DC coding not used */
             s->last_dc[0] = get_bits(&s->gb, 8);
@@ -402,16 +402,16 @@
 
     i= get_bits(&s->gb, 2);
     switch(i){
-    case 0: s->pict_type= I_TYPE; break;
-    case 1: s->pict_type= I_TYPE; break; //hmm ...
-    case 2: s->pict_type= P_TYPE; break;
-    case 3: s->pict_type= B_TYPE; break;
+    case 0: s->pict_type= FF_I_TYPE; break;
+    case 1: s->pict_type= FF_I_TYPE; break; //hmm ...
+    case 2: s->pict_type= FF_P_TYPE; break;
+    case 3: s->pict_type= FF_B_TYPE; break;
     default:
         av_log(s->avctx, AV_LOG_ERROR, "unknown frame type\n");
         return -1;
     }
 
-    if(s->last_picture_ptr==NULL && s->pict_type==B_TYPE){
+    if(s->last_picture_ptr==NULL && s->pict_type==FF_B_TYPE){
         av_log(s->avctx, AV_LOG_ERROR, "early B pix\n");
         return -1;
     }
@@ -482,7 +482,7 @@
     if(seq - s->time >  0x4000) seq -= 0x8000;
     if(seq - s->time < -0x4000) seq += 0x8000;
     if(seq != s->time){
-        if(s->pict_type!=B_TYPE){
+        if(s->pict_type!=FF_B_TYPE){
             s->time= seq;
             s->pp_time= s->time - s->last_non_b_time;
             s->last_non_b_time= s->time;
@@ -505,7 +505,7 @@
 
     s->f_code = 1;
     s->unrestricted_mv = 1;
-    s->h263_aic= s->pict_type == I_TYPE;
+    s->h263_aic= s->pict_type == FF_I_TYPE;
 //    s->alt_inter_vlc=1;
 //    s->obmc=1;
 //    s->umvplus=1;
@@ -517,12 +517,12 @@
                    seq, s->mb_x, s->mb_y, s->pict_type, s->qscale, s->no_rounding);
     }
 
-    assert(s->pict_type != B_TYPE || !s->low_delay);
+    assert(s->pict_type != FF_B_TYPE || !s->low_delay);
 
     return s->mb_width*s->mb_height - mb_pos;
 }
 
-static int rv10_decode_init(AVCodecContext *avctx)
+static av_cold int rv10_decode_init(AVCodecContext *avctx)
 {
     MpegEncContext *s = avctx->priv_data;
     static int done=0;
@@ -588,7 +588,7 @@
     return 0;
 }
 
-static int rv10_decode_end(AVCodecContext *avctx)
+static av_cold int rv10_decode_end(AVCodecContext *avctx)
 {
     MpegEncContext *s = avctx->priv_data;
 
@@ -623,7 +623,7 @@
         av_log(s->avctx, AV_LOG_ERROR, "COUNT ERROR\n");
         return -1;
     }
-//if(s->pict_type == P_TYPE) return 0;
+//if(s->pict_type == FF_P_TYPE) return 0;
 
     if ((s->mb_x == 0 && s->mb_y == 0) || s->current_picture_ptr==NULL) {
         if(s->current_picture_ptr){ //FIXME write parser so we always have complete frames?
@@ -690,7 +690,7 @@
             av_log(s->avctx, AV_LOG_ERROR, "ERROR at MB %d %d\n", s->mb_x, s->mb_y);
             return -1;
         }
-        if(s->pict_type != B_TYPE)
+        if(s->pict_type != FF_B_TYPE)
             ff_h263_update_motion_val(s);
         MPV_decode_mb(s, s->block);
         if(s->loop_filter)
@@ -759,7 +759,7 @@
         ff_er_frame_end(s);
         MPV_frame_end(s);
 
-        if (s->pict_type == B_TYPE || s->low_delay) {
+        if (s->pict_type == FF_B_TYPE || s->low_delay) {
             *pict= *(AVFrame*)s->current_picture_ptr;
         } else if (s->last_picture_ptr != NULL) {
             *pict= *(AVFrame*)s->last_picture_ptr;
Index: mythtv/libs/libavcodec/qpeg.c
===================================================================
--- mythtv/libs/libavcodec/qpeg.c	(revision 18209)
+++ mythtv/libs/libavcodec/qpeg.c	(working copy)
@@ -285,7 +285,7 @@
     return buf_size;
 }
 
-static int decode_init(AVCodecContext *avctx){
+static av_cold int decode_init(AVCodecContext *avctx){
     QpegContext * const a = avctx->priv_data;
 
     a->avctx = avctx;
@@ -296,7 +296,7 @@
     return 0;
 }
 
-static int decode_end(AVCodecContext *avctx){
+static av_cold int decode_end(AVCodecContext *avctx){
     QpegContext * const a = avctx->priv_data;
     AVFrame * const p= (AVFrame*)&a->pic;
 
Index: mythtv/libs/libavcodec/pngdec.c
===================================================================
--- mythtv/libs/libavcodec/pngdec.c	(revision 18209)
+++ mythtv/libs/libavcodec/pngdec.c	(working copy)
@@ -529,7 +529,7 @@
     goto the_end;
 }
 
-static int png_dec_init(AVCodecContext *avctx){
+static av_cold int png_dec_init(AVCodecContext *avctx){
     PNGDecContext *s = avctx->priv_data;
 
     avcodec_get_frame_defaults((AVFrame*)&s->picture);
Index: mythtv/libs/libavcodec/mpegaudioenc.c
===================================================================
--- mythtv/libs/libavcodec/mpegaudioenc.c	(revision 18209)
+++ mythtv/libs/libavcodec/mpegaudioenc.c	(working copy)
@@ -61,7 +61,7 @@
 #include "mpegaudiodata.h"
 #include "mpegaudiotab.h"
 
-static int MPA_encode_init(AVCodecContext *avctx)
+static av_cold int MPA_encode_init(AVCodecContext *avctx)
 {
     MpegAudioContext *s = avctx->priv_data;
     int freq = avctx->sample_rate;
@@ -781,7 +781,7 @@
     return pbBufPtr(&s->pb) - s->pb.buf;
 }
 
-static int MPA_encode_close(AVCodecContext *avctx)
+static av_cold int MPA_encode_close(AVCodecContext *avctx)
 {
     av_freep(&avctx->coded_frame);
     return 0;
Index: mythtv/libs/libavcodec/vmnc.c
===================================================================
--- mythtv/libs/libavcodec/vmnc.c	(revision 18209)
+++ mythtv/libs/libavcodec/vmnc.c	(working copy)
@@ -456,7 +456,7 @@
  * Init VMnc decoder
  *
  */
-static int decode_init(AVCodecContext *avctx)
+static av_cold int decode_init(AVCodecContext *avctx)
 {
     VmncContext * const c = avctx->priv_data;
 
@@ -496,7 +496,7 @@
  * Uninit VMnc decoder
  *
  */
-static int decode_end(AVCodecContext *avctx)
+static av_cold int decode_end(AVCodecContext *avctx)
 {
     VmncContext * const c = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/xvmcvideo.c
===================================================================
--- mythtv/libs/libavcodec/xvmcvideo.c	(revision 18209)
+++ mythtv/libs/libavcodec/xvmcvideo.c	(working copy)
@@ -123,9 +123,9 @@
 
     render->pict_type=s->pict_type; // for later frame dropping use
     switch(s->pict_type){
-        case  I_TYPE:
+        case  FF_I_TYPE:
             return 0;// no prediction from other frames
-        case  B_TYPE:
+        case  FF_B_TYPE:
             render->p_past_surface = findPastSurface(s, render);
             render->p_future_surface = findFutureSurface(s);
             if (!render->p_past_surface)
@@ -136,7 +136,7 @@
                        "B frame and future frame is null!\n");
             else return 0;
             return 0; // pretend things are ok even if they aren't
-        case  P_TYPE:
+        case  FF_P_TYPE:
             render->p_past_surface = findPastSurface(s, render);
             if (!render->p_past_surface)
                 av_log(s->avctx, AV_LOG_ERROR, "XvMC: error, decoding "
Index: mythtv/libs/libavcodec/bethsoftvideo.c
===================================================================
--- mythtv/libs/libavcodec/bethsoftvideo.c	(revision 18209)
+++ mythtv/libs/libavcodec/bethsoftvideo.c	(working copy)
@@ -36,7 +36,7 @@
     AVFrame frame;
 } BethsoftvidContext;
 
-static int bethsoftvid_decode_init(AVCodecContext *avctx)
+static av_cold int bethsoftvid_decode_init(AVCodecContext *avctx)
 {
     BethsoftvidContext *vid = avctx->priv_data;
     vid->frame.reference = 1;
@@ -120,7 +120,7 @@
     return buf_size;
 }
 
-static int bethsoftvid_decode_end(AVCodecContext *avctx)
+static av_cold int bethsoftvid_decode_end(AVCodecContext *avctx)
 {
     BethsoftvidContext * vid = avctx->priv_data;
     if(vid->frame.data[0])
Index: mythtv/libs/libavcodec/rawdec.c
===================================================================
--- mythtv/libs/libavcodec/rawdec.c	(revision 18209)
+++ mythtv/libs/libavcodec/rawdec.c	(working copy)
@@ -63,7 +63,7 @@
     return PIX_FMT_YUV420P;
 }
 
-static int raw_init_decoder(AVCodecContext *avctx)
+static av_cold int raw_init_decoder(AVCodecContext *avctx)
 {
     RawVideoContext *context = avctx->priv_data;
 
@@ -143,7 +143,7 @@
     return buf_size;
 }
 
-static int raw_close_decoder(AVCodecContext *avctx)
+static av_cold int raw_close_decoder(AVCodecContext *avctx)
 {
     RawVideoContext *context = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/motion_est.c
===================================================================
--- mythtv/libs/libavcodec/motion_est.c	(revision 18209)
+++ mythtv/libs/libavcodec/motion_est.c	(working copy)
@@ -2026,7 +2026,7 @@
                             continue;
 
                     for(j=0; j<fcode && j<8; j++){
-                        if(s->pict_type==B_TYPE || s->current_picture.mc_mb_var[xy] < s->current_picture.mb_var[xy])
+                        if(s->pict_type==FF_B_TYPE || s->current_picture.mc_mb_var[xy] < s->current_picture.mb_var[xy])
                             score[j]-= 170;
                     }
                 }
@@ -2058,7 +2058,7 @@
     MotionEstContext * const c= &s->me;
     const int f_code= s->f_code;
     int y, range;
-    assert(s->pict_type==P_TYPE);
+    assert(s->pict_type==FF_P_TYPE);
 
     range = (((s->out_format == FMT_MPEG1 || s->msmpeg4_version) ? 8 : 16) << f_code);
 
Index: mythtv/libs/libavcodec/indeo3.c
===================================================================
--- mythtv/libs/libavcodec/indeo3.c	(revision 18209)
+++ mythtv/libs/libavcodec/indeo3.c	(working copy)
@@ -62,7 +62,7 @@
 
 static int corrector_type_2[8] = { 9, 7, 6, 8, 5, 4, 3, 2 };
 
-static void build_modpred(Indeo3DecodeContext *s)
+static av_cold void build_modpred(Indeo3DecodeContext *s)
 {
   int i, j;
 
@@ -97,7 +97,7 @@
   unsigned char *buf2, int min_width_160);
 
 /* ---------------------------------------------------------------------- */
-static void iv_alloc_frames(Indeo3DecodeContext *s)
+static av_cold void iv_alloc_frames(Indeo3DecodeContext *s)
 {
   int luma_width, luma_height, luma_pixels, chroma_width, chroma_height,
       chroma_pixels, i;
@@ -155,7 +155,7 @@
 }
 
 /* ---------------------------------------------------------------------- */
-static void iv_free_func(Indeo3DecodeContext *s)
+static av_cold void iv_free_func(Indeo3DecodeContext *s)
 {
   int i;
 
@@ -1057,7 +1057,7 @@
   }
 }
 
-static int indeo3_decode_init(AVCodecContext *avctx)
+static av_cold int indeo3_decode_init(AVCodecContext *avctx)
 {
     Indeo3DecodeContext *s = avctx->priv_data;
 
@@ -1124,7 +1124,7 @@
     return buf_size;
 }
 
-static int indeo3_decode_end(AVCodecContext *avctx)
+static av_cold int indeo3_decode_end(AVCodecContext *avctx)
 {
     Indeo3DecodeContext *s = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/h263.c
===================================================================
--- mythtv/libs/libavcodec/h263.c	(revision 18209)
+++ mythtv/libs/libavcodec/h263.c	(working copy)
@@ -204,7 +204,7 @@
         put_bits(&s->pb, 16, s->width);
         put_bits(&s->pb, 16, s->height);
       }
-      put_bits(&s->pb, 2, s->pict_type == P_TYPE); /* PictureType */
+      put_bits(&s->pb, 2, s->pict_type == FF_P_TYPE); /* PictureType */
       put_bits(&s->pb, 1, 1); /* DeblockingFlag: on */
       put_bits(&s->pb, 5, s->qscale); /* Quantizer */
       put_bits(&s->pb, 1, 0); /* ExtraInformation */
@@ -261,7 +261,7 @@
     if (!s->h263_plus) {
         /* H.263v1 */
         put_bits(&s->pb, 3, format);
-        put_bits(&s->pb, 1, (s->pict_type == P_TYPE));
+        put_bits(&s->pb, 1, (s->pict_type == FF_P_TYPE));
         /* By now UMV IS DISABLED ON H.263v1, since the restrictions
         of H.263v1 UMV implies to check the predicted MV after
         calculation of the current MB to see if we're on the limits */
@@ -297,7 +297,7 @@
         put_bits(&s->pb,1,1); /* "1" to prevent start code emulation */
         put_bits(&s->pb,3,0); /* Reserved */
 
-        put_bits(&s->pb, 3, s->pict_type == P_TYPE);
+        put_bits(&s->pb, 3, s->pict_type == FF_P_TYPE);
 
         put_bits(&s->pb,1,0); /* Reference Picture Resampling: off */
         put_bits(&s->pb,1,0); /* Reduced-Resolution Update: off */
@@ -376,12 +376,12 @@
             put_bits(&s->pb, 1, 1);
         put_bits(&s->pb, 5, s->qscale); /* GQUANT */
         put_bits(&s->pb, 1, 1);
-        put_bits(&s->pb, 2, s->pict_type == I_TYPE); /* GFID */
+        put_bits(&s->pb, 2, s->pict_type == FF_I_TYPE); /* GFID */
     }else{
         int gob_number= mb_line / s->gob_index;
 
         put_bits(&s->pb, 5, gob_number); /* GN */
-        put_bits(&s->pb, 2, s->pict_type == I_TYPE); /* GFID */
+        put_bits(&s->pb, 2, s->pict_type == FF_I_TYPE); /* GFID */
         put_bits(&s->pb, 5, s->qscale); /* GQUANT */
     }
 }
@@ -556,7 +556,7 @@
 
     ff_clean_h263_qscales(s);
 
-    if(s->pict_type== B_TYPE){
+    if(s->pict_type== FF_B_TYPE){
         int odd=0;
         /* ok, come on, this isn't funny anymore, there's more code for handling this mpeg4 mess than for the actual adaptive quantization */
 
@@ -900,8 +900,8 @@
 {
     int cbpc, cbpy, pred_x, pred_y;
     PutBitContext * const pb2    = s->data_partitioning                         ? &s->pb2    : &s->pb;
-    PutBitContext * const tex_pb = s->data_partitioning && s->pict_type!=B_TYPE ? &s->tex_pb : &s->pb;
-    PutBitContext * const dc_pb  = s->data_partitioning && s->pict_type!=I_TYPE ? &s->pb2    : &s->pb;
+    PutBitContext * const tex_pb = s->data_partitioning && s->pict_type!=FF_B_TYPE ? &s->tex_pb : &s->pb;
+    PutBitContext * const dc_pb  = s->data_partitioning && s->pict_type!=FF_I_TYPE ? &s->pb2    : &s->pb;
     const int interleaved_stats= (s->flags&CODEC_FLAG_PASS1) && !s->data_partitioning ? 1 : 0;
     const int dquant_code[5]= {1,0,9,2,3};
 
@@ -909,7 +909,7 @@
     if (!s->mb_intra) {
         int i, cbp;
 
-        if(s->pict_type==B_TYPE){
+        if(s->pict_type==FF_B_TYPE){
             static const int mb_type_table[8]= {-1, 3, 2, 1,-1,-1,-1, 0}; /* convert from mv_dir to type */
             int mb_type=  mb_type_table[s->mv_dir];
 
@@ -1042,7 +1042,7 @@
                 s->p_tex_bits+= get_bits_diff(s);
             }
 
-        }else{ /* s->pict_type==B_TYPE */
+        }else{ /* s->pict_type==FF_B_TYPE */
             cbp= get_p_cbp(s, block, motion_x, motion_y);
 
             if ((cbp | motion_x | motion_y | s->dquant) == 0 && s->mv_type==MV_TYPE_16X16) {
@@ -1067,7 +1067,7 @@
                         int diff;
                         Picture *pic= s->reordered_input_picture[i+1];
 
-                        if(pic==NULL || pic->pict_type!=B_TYPE) break;
+                        if(pic==NULL || pic->pict_type!=FF_B_TYPE) break;
 
                         b_pic= pic->data[0] + offset;
                         if(pic->type != FF_BUFFER_TYPE_SHARED)
@@ -1219,7 +1219,7 @@
         }
 
         cbpc = cbp & 3;
-        if (s->pict_type == I_TYPE) {
+        if (s->pict_type == FF_I_TYPE) {
             if(s->dquant) cbpc+=4;
             put_bits(&s->pb,
                 intra_MCBPC_bits[cbpc],
@@ -1413,7 +1413,7 @@
         }
 
         cbpc = cbp & 3;
-        if (s->pict_type == I_TYPE) {
+        if (s->pict_type == FF_I_TYPE) {
             if(s->dquant) cbpc+=4;
             put_bits(&s->pb,
                 intra_MCBPC_bits[cbpc],
@@ -1471,7 +1471,7 @@
     uint8_t *dest_cb= s->dest[1];
     uint8_t *dest_cr= s->dest[2];
 
-//    if(s->pict_type==B_TYPE && !s->readable) return;
+//    if(s->pict_type==FF_B_TYPE && !s->readable) return;
 
     /*
        Diag Top
@@ -2268,7 +2268,7 @@
 
 /* must be called before writing the header */
 void ff_set_mpeg4_time(MpegEncContext * s){
-    if(s->pict_type==B_TYPE){
+    if(s->pict_type==FF_B_TYPE){
         ff_mpeg4_init_direct_mv(s);
     }else{
         s->last_time_base= s->time_base;
@@ -2458,7 +2458,7 @@
     int time_incr;
     int time_div, time_mod;
 
-    if(s->pict_type==I_TYPE){
+    if(s->pict_type==FF_I_TYPE){
         if(!(s->flags&CODEC_FLAG_GLOBAL_HEADER)){
             if(s->strict_std_compliance < FF_COMPLIANCE_VERY_STRICT) //HACK, the reference sw is buggy
                 mpeg4_encode_visual_object_header(s);
@@ -2469,7 +2469,7 @@
             mpeg4_encode_gop_header(s);
     }
 
-    s->partitioned_frame= s->data_partitioning && s->pict_type!=B_TYPE;
+    s->partitioned_frame= s->data_partitioning && s->pict_type!=FF_B_TYPE;
 
 //printf("num:%d rate:%d base:%d\n", s->picture_number, s->time_base.den, FRAME_RATE_BASE);
 
@@ -2498,8 +2498,8 @@
     put_bits(&s->pb, s->time_increment_bits, time_mod); /* time increment */
     put_bits(&s->pb, 1, 1);                             /* marker */
     put_bits(&s->pb, 1, 1);                             /* vop coded */
-    if (    s->pict_type == P_TYPE
-        || (s->pict_type == S_TYPE && s->vol_sprite_usage==GMC_SPRITE)) {
+    if (    s->pict_type == FF_P_TYPE
+        || (s->pict_type == FF_S_TYPE && s->vol_sprite_usage==GMC_SPRITE)) {
         put_bits(&s->pb, 1, s->no_rounding);    /* rounding type */
     }
     put_bits(&s->pb, 3, 0);     /* intra dc VLC threshold */
@@ -2511,9 +2511,9 @@
 
     put_bits(&s->pb, 5, s->qscale);
 
-    if (s->pict_type != I_TYPE)
+    if (s->pict_type != FF_I_TYPE)
         put_bits(&s->pb, 3, s->f_code); /* fcode_for */
-    if (s->pict_type == B_TYPE)
+    if (s->pict_type == FF_B_TYPE)
         put_bits(&s->pb, 3, s->b_code); /* fcode_back */
     //    printf("****frame %d\n", picture_number);
 }
@@ -3077,7 +3077,7 @@
     const int tex_pb_len= put_bits_count(&s->tex_pb);
     const int bits= put_bits_count(&s->pb);
 
-    if(s->pict_type==I_TYPE){
+    if(s->pict_type==FF_I_TYPE){
         put_bits(&s->pb, 19, DC_MARKER);
         s->misc_bits+=19 + pb2_len + bits - s->last_bits;
         s->i_tex_bits+= tex_pb_len;
@@ -3101,13 +3101,13 @@
 
 int ff_mpeg4_get_video_packet_prefix_length(MpegEncContext *s){
     switch(s->pict_type){
-        case I_TYPE:
+        case FF_I_TYPE:
             return 16;
-        case P_TYPE:
-        case S_TYPE:
+        case FF_P_TYPE:
+        case FF_S_TYPE:
             return s->f_code+15;
-        case B_TYPE:
-            return FFMAX(FFMAX(s->f_code, s->b_code)+15, 17);
+        case FF_B_TYPE:
+            return FFMAX3(s->f_code, s->b_code, 2) + 15;
         default:
             return -1;
     }
@@ -3144,7 +3144,7 @@
 // disabling the while lopp since it causes playback issues #3001
 #if 0
     while(v<=0xFF){
-        if(s->pict_type==B_TYPE || (v>>(8-s->pict_type)!=1) || s->partitioned_frame)
+        if(s->pict_type==FF_B_TYPE || (v>>(8-s->pict_type)!=1) || s->partitioned_frame)
             break;
         skip_bits(&s->gb, 8+s->pict_type);
         bits_count+= 8+s->pict_type;
@@ -3210,7 +3210,7 @@
         av_log(s->avctx, AV_LOG_ERROR, "illegal mb_num in video packet (%d %d) \n", mb_num, s->mb_num);
         return -1;
     }
-    if(s->pict_type == B_TYPE){
+    if(s->pict_type == FF_B_TYPE){
         while(s->next_picture.mbskip_table[ s->mb_index2xy[ mb_num ] ]) mb_num++;
         if(mb_num >= s->mb_num) return -1; // slice contains just skipped MBs which where allready decoded
     }
@@ -3244,20 +3244,20 @@
         if(s->shape != BIN_ONLY_SHAPE){
             skip_bits(&s->gb, 3); /* intra dc vlc threshold */
 //FIXME don't just ignore everything
-            if(s->pict_type == S_TYPE && s->vol_sprite_usage==GMC_SPRITE){
+            if(s->pict_type == FF_S_TYPE && s->vol_sprite_usage==GMC_SPRITE){
                 mpeg4_decode_sprite_trajectory(s, &s->gb);
                 av_log(s->avctx, AV_LOG_ERROR, "untested\n");
             }
 
             //FIXME reduced res stuff here
 
-            if (s->pict_type != I_TYPE) {
+            if (s->pict_type != FF_I_TYPE) {
                 int f_code = get_bits(&s->gb, 3);       /* fcode_for */
                 if(f_code==0){
                     av_log(s->avctx, AV_LOG_ERROR, "Error, video packet header damaged (f_code=0)\n");
                 }
             }
-            if (s->pict_type == B_TYPE) {
+            if (s->pict_type == FF_B_TYPE) {
                 int b_code = get_bits(&s->gb, 3);
                 if(b_code==0){
                     av_log(s->avctx, AV_LOG_ERROR, "Error, video packet header damaged (b_code=0)\n");
@@ -3416,7 +3416,7 @@
             if(s->mb_x == s->resync_mb_x && s->mb_y == s->resync_mb_y+1)
                 s->first_slice_line=0;
 
-            if(s->pict_type==I_TYPE){
+            if(s->pict_type==FF_I_TYPE){
                 int i;
 
                 do{
@@ -3465,7 +3465,7 @@
                 skip_bits1(&s->gb);
                 if(bits&0x10000){
                     /* skip mb */
-                    if(s->pict_type==S_TYPE && s->vol_sprite_usage==GMC_SPRITE){
+                    if(s->pict_type==FF_S_TYPE && s->vol_sprite_usage==GMC_SPRITE){
                         s->current_picture.mb_type[xy]= MB_TYPE_SKIP | MB_TYPE_16x16 | MB_TYPE_GMC | MB_TYPE_L0;
                         mx= get_amv(s, 0);
                         my= get_amv(s, 1);
@@ -3506,7 +3506,7 @@
                     if(s->mbintra_table[xy])
                         ff_clean_intra_table_entries(s);
 
-                    if(s->pict_type==S_TYPE && s->vol_sprite_usage==GMC_SPRITE && (cbpc & 16) == 0)
+                    if(s->pict_type==FF_S_TYPE && s->vol_sprite_usage==GMC_SPRITE && (cbpc & 16) == 0)
                         s->mcsel= get_bits1(&s->gb);
                     else s->mcsel= 0;
 
@@ -3578,7 +3578,7 @@
             if(s->mb_x == s->resync_mb_x && s->mb_y == s->resync_mb_y+1)
                 s->first_slice_line=0;
 
-            if(s->pict_type==I_TYPE){
+            if(s->pict_type==FF_I_TYPE){
                 int ac_pred= get_bits1(&s->gb);
                 int cbpy = get_vlc2(&s->gb, cbpy_vlc.table, CBPY_VLC_BITS, 1);
                 if(cbpy<0){
@@ -3652,8 +3652,8 @@
 int ff_mpeg4_decode_partitions(MpegEncContext *s)
 {
     int mb_num;
-    const int part_a_error= s->pict_type==I_TYPE ? (DC_ERROR|MV_ERROR) : MV_ERROR;
-    const int part_a_end  = s->pict_type==I_TYPE ? (DC_END  |MV_END)   : MV_END;
+    const int part_a_error= s->pict_type==FF_I_TYPE ? (DC_ERROR|MV_ERROR) : MV_ERROR;
+    const int part_a_end  = s->pict_type==FF_I_TYPE ? (DC_END  |MV_END)   : MV_END;
 
     mb_num= mpeg4_decode_partition_a(s);
     if(mb_num<0){
@@ -3669,7 +3669,7 @@
 
     s->mb_num_left= mb_num;
 
-    if(s->pict_type==I_TYPE){
+    if(s->pict_type==FF_I_TYPE){
         while(show_bits(&s->gb, 9) == 1)
             skip_bits(&s->gb, 9);
         if(get_bits_long(&s->gb, 19)!=DC_MARKER){
@@ -3687,11 +3687,11 @@
     ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x-1, s->mb_y, part_a_end);
 
     if( mpeg4_decode_partition_b(s, mb_num) < 0){
-        if(s->pict_type==P_TYPE)
+        if(s->pict_type==FF_P_TYPE)
             ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x, s->mb_y, DC_ERROR);
         return -1;
     }else{
-        if(s->pict_type==P_TYPE)
+        if(s->pict_type==FF_P_TYPE)
             ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x-1, s->mb_y, DC_END);
     }
 
@@ -3716,7 +3716,7 @@
         ff_set_qscale(s, s->current_picture.qscale_table[xy] );
     }
 
-    if (s->pict_type == P_TYPE || s->pict_type==S_TYPE) {
+    if (s->pict_type == FF_P_TYPE || s->pict_type==FF_S_TYPE) {
         int i;
         for(i=0; i<4; i++){
             s->mv[0][i][0] = s->current_picture.motion_val[0][ s->block_index[i] ][0];
@@ -3730,7 +3730,7 @@
                 s->block_last_index[i] = -1;
             s->mv_dir = MV_DIR_FORWARD;
             s->mv_type = MV_TYPE_16X16;
-            if(s->pict_type==S_TYPE && s->vol_sprite_usage==GMC_SPRITE){
+            if(s->pict_type==FF_S_TYPE && s->vol_sprite_usage==GMC_SPRITE){
                 s->mcsel=1;
                 s->mb_skipped = 0;
             }else{
@@ -3802,7 +3802,7 @@
         s->block_index[i]+= 1;
     s->mb_x++;
 
-    assert(s->pict_type == P_TYPE);
+    assert(s->pict_type == FF_P_TYPE);
 
     do{
         if (get_bits1(&s->gb)) {
@@ -3902,7 +3902,7 @@
 
     assert(!s->h263_pred);
 
-    if (s->pict_type == P_TYPE) {
+    if (s->pict_type == FF_P_TYPE) {
         do{
             if (get_bits1(&s->gb)) {
                 /* skip mb */
@@ -4002,10 +4002,10 @@
         }
 
         if(s->obmc){
-            if(s->pict_type == P_TYPE && s->mb_x+1<s->mb_width && s->mb_num_left != 1)
+            if(s->pict_type == FF_P_TYPE && s->mb_x+1<s->mb_width && s->mb_num_left != 1)
                 preview_obmc(s);
         }
-    } else if(s->pict_type==B_TYPE) {
+    } else if(s->pict_type==FF_B_TYPE) {
         int mb_type;
         const int stride= s->b8_stride;
         int16_t *mot_val0 = s->current_picture.motion_val[0][ 2*(s->mb_x + s->mb_y*stride) ];
@@ -4169,7 +4169,7 @@
 
     assert(s->h263_pred);
 
-    if (s->pict_type == P_TYPE || s->pict_type==S_TYPE) {
+    if (s->pict_type == FF_P_TYPE || s->pict_type==FF_S_TYPE) {
         do{
             if (get_bits1(&s->gb)) {
                 /* skip mb */
@@ -4178,7 +4178,7 @@
                     s->block_last_index[i] = -1;
                 s->mv_dir = MV_DIR_FORWARD;
                 s->mv_type = MV_TYPE_16X16;
-                if(s->pict_type==S_TYPE && s->vol_sprite_usage==GMC_SPRITE){
+                if(s->pict_type==FF_S_TYPE && s->vol_sprite_usage==GMC_SPRITE){
                     s->current_picture.mb_type[xy]= MB_TYPE_SKIP | MB_TYPE_GMC | MB_TYPE_16x16 | MB_TYPE_L0;
                     s->mcsel=1;
                     s->mv[0][0][0]= get_amv(s, 0);
@@ -4207,7 +4207,7 @@
         s->mb_intra = ((cbpc & 4) != 0);
         if (s->mb_intra) goto intra;
 
-        if(s->pict_type==S_TYPE && s->vol_sprite_usage==GMC_SPRITE && (cbpc & 16) == 0)
+        if(s->pict_type==FF_S_TYPE && s->vol_sprite_usage==GMC_SPRITE && (cbpc & 16) == 0)
             s->mcsel= get_bits1(&s->gb);
         else s->mcsel= 0;
         cbpy = get_vlc2(&s->gb, cbpy_vlc.table, CBPY_VLC_BITS, 1) ^ 0x0F;
@@ -4286,7 +4286,7 @@
                 mot_val[1] = my;
             }
         }
-    } else if(s->pict_type==B_TYPE) {
+    } else if(s->pict_type==FF_B_TYPE) {
         int modb1; // first bit of modb
         int modb2; // second bit of modb
         int mb_type;
@@ -4480,7 +4480,7 @@
     if(s->codec_id==CODEC_ID_MPEG4){
         if(mpeg4_is_resync(s)){
             const int delta= s->mb_x + 1 == s->mb_width ? 2 : 1;
-            if(s->pict_type==B_TYPE && s->next_picture.mbskip_table[xy + delta])
+            if(s->pict_type==FF_B_TYPE && s->next_picture.mbskip_table[xy + delta])
                 return SLICE_OK;
             return SLICE_END;
         }
@@ -4574,7 +4574,7 @@
         /* DC coef */
         if(s->codec_id == CODEC_ID_RV10){
 #ifdef CONFIG_RV10_DECODER
-          if (s->rv10_version == 3 && s->pict_type == I_TYPE) {
+          if (s->rv10_version == 3 && s->pict_type == FF_I_TYPE) {
             int component, diff;
             component = (n <= 3 ? 0 : n - 4 + 1);
             level = s->last_dc[component];
@@ -5043,7 +5043,7 @@
         if (!width)
             return -1;
 
-        s->pict_type = I_TYPE + get_bits1(&s->gb);
+        s->pict_type = FF_I_TYPE + get_bits1(&s->gb);
 
         s->h263_long_vectors = get_bits1(&s->gb);
 
@@ -5110,10 +5110,10 @@
         /* MPPTYPE */
         s->pict_type = get_bits(&s->gb, 3);
         switch(s->pict_type){
-        case 0: s->pict_type= I_TYPE;break;
-        case 1: s->pict_type= P_TYPE;break;
-        case 3: s->pict_type= B_TYPE;break;
-        case 7: s->pict_type= I_TYPE;break; //ZYGO
+        case 0: s->pict_type= FF_I_TYPE;break;
+        case 1: s->pict_type= FF_P_TYPE;break;
+        case 3: s->pict_type= FF_B_TYPE;break;
+        case 7: s->pict_type= FF_I_TYPE;break; //ZYGO
         default:
             return -1;
         }
@@ -5233,7 +5233,7 @@
         show_pict_info(s);
      }
 #if 1
-    if (s->pict_type == I_TYPE && s->codec_tag == ff_get_fourcc("ZYGO")){
+    if (s->pict_type == FF_I_TYPE && s->codec_tag == ff_get_fourcc("ZYGO")){
         int i,j;
         for(i=0; i<85; i++) av_log(s->avctx, AV_LOG_DEBUG, "%d", get_bits1(&s->gb));
         av_log(s->avctx, AV_LOG_DEBUG, "\n");
@@ -5739,7 +5739,7 @@
 
 /**
  * decodes the user data stuff in the header.
- * allso inits divx/xvid/lavc_version/build
+ * Also initializes divx/xvid/lavc_version/build.
  */
 static int decode_user_data(MpegEncContext *s, GetBitContext *gb){
     char buf[256];
@@ -5795,13 +5795,13 @@
 static int decode_vop_header(MpegEncContext *s, GetBitContext *gb){
     int time_incr, time_increment;
 
-    s->pict_type = get_bits(gb, 2) + I_TYPE;        /* pict type: I = 0 , P = 1 */
-    if(s->pict_type==B_TYPE && s->low_delay && s->vol_control_parameters==0 && !(s->flags & CODEC_FLAG_LOW_DELAY)){
+    s->pict_type = get_bits(gb, 2) + FF_I_TYPE;        /* pict type: I = 0 , P = 1 */
+    if(s->pict_type==FF_B_TYPE && s->low_delay && s->vol_control_parameters==0 && !(s->flags & CODEC_FLAG_LOW_DELAY)){
         av_log(s->avctx, AV_LOG_ERROR, "low_delay flag incorrectly, clearing it\n");
         s->low_delay=0;
     }
 
-    s->partitioned_frame= s->data_partitioning && s->pict_type!=B_TYPE;
+    s->partitioned_frame= s->data_partitioning && s->pict_type!=FF_B_TYPE;
     if(s->partitioned_frame)
         s->decode_mb= mpeg4_decode_partitioned_mb;
     else
@@ -5828,7 +5828,7 @@
 
 //    printf("%d %X\n", s->time_increment_bits, time_increment);
 //av_log(s->avctx, AV_LOG_DEBUG, " type:%d modulo_time_base:%d increment:%d t_frame %d\n", s->pict_type, time_incr, time_increment, s->t_frame);
-    if(s->pict_type!=B_TYPE){
+    if(s->pict_type!=FF_B_TYPE){
         s->last_time_base= s->time_base;
         s->time_base+= time_incr;
         s->time= s->time_base*s->avctx->time_base.den + time_increment;
@@ -5880,8 +5880,8 @@
     }
 //printf("time %d %d %d || %"PRId64" %"PRId64" %"PRId64"\n", s->time_increment_bits, s->avctx->time_base.den, s->time_base,
 //s->time, s->last_non_b_time, s->last_non_b_time - s->pp_time);
-    if (s->shape != BIN_ONLY_SHAPE && ( s->pict_type == P_TYPE
-                          || (s->pict_type == S_TYPE && s->vol_sprite_usage==GMC_SPRITE))) {
+    if (s->shape != BIN_ONLY_SHAPE && ( s->pict_type == FF_P_TYPE
+                          || (s->pict_type == FF_S_TYPE && s->vol_sprite_usage==GMC_SPRITE))) {
         /* rounding type for motion estimation */
         s->no_rounding = get_bits1(gb);
     } else {
@@ -5890,7 +5890,7 @@
 //FIXME reduced res stuff
 
      if (s->shape != RECT_SHAPE) {
-         if (s->vol_sprite_usage != 1 || s->pict_type != I_TYPE) {
+         if (s->vol_sprite_usage != 1 || s->pict_type != FF_I_TYPE) {
              int width, height, hor_spat_ref, ver_spat_ref;
 
              width = get_bits(gb, 13);
@@ -5930,7 +5930,7 @@
          ff_init_scantable(s->dsp.idct_permutation, &s->intra_v_scantable, ff_alternate_vertical_scan);
      }
 
-     if(s->pict_type == S_TYPE && (s->vol_sprite_usage==STATIC_SPRITE || s->vol_sprite_usage==GMC_SPRITE)){
+     if(s->pict_type == FF_S_TYPE && (s->vol_sprite_usage==STATIC_SPRITE || s->vol_sprite_usage==GMC_SPRITE)){
          mpeg4_decode_sprite_trajectory(s, gb);
          if(s->sprite_brightness_change) av_log(s->avctx, AV_LOG_ERROR, "sprite_brightness_change not supported\n");
          if(s->vol_sprite_usage==STATIC_SPRITE) av_log(s->avctx, AV_LOG_ERROR, "static sprite not supported\n");
@@ -5943,7 +5943,7 @@
              return -1; // makes no sense to continue, as there is nothing left from the image then
          }
 
-         if (s->pict_type != I_TYPE) {
+         if (s->pict_type != FF_I_TYPE) {
              s->f_code = get_bits(gb, 3);       /* fcode_for */
              if(s->f_code==0){
                  av_log(s->avctx, AV_LOG_ERROR, "Error, header damaged or not MPEG4 header (f_code=0)\n");
@@ -5952,7 +5952,7 @@
          }else
              s->f_code=1;
 
-         if (s->pict_type == B_TYPE) {
+         if (s->pict_type == FF_B_TYPE) {
              s->b_code = get_bits(gb, 3);
          }else
              s->b_code=1;
@@ -5960,14 +5960,14 @@
          if(s->avctx->debug&FF_DEBUG_PICT_INFO){
              av_log(s->avctx, AV_LOG_DEBUG, "qp:%d fc:%d,%d %s size:%d pro:%d alt:%d top:%d %spel part:%d resync:%d w:%d a:%d rnd:%d vot:%d%s dc:%d\n",
                  s->qscale, s->f_code, s->b_code,
-                 s->pict_type == I_TYPE ? "I" : (s->pict_type == P_TYPE ? "P" : (s->pict_type == B_TYPE ? "B" : "S")),
+                 s->pict_type == FF_I_TYPE ? "I" : (s->pict_type == FF_P_TYPE ? "P" : (s->pict_type == FF_B_TYPE ? "B" : "S")),
                  gb->size_in_bits,s->progressive_sequence, s->alternate_scan, s->top_field_first,
                  s->quarter_sample ? "q" : "h", s->data_partitioning, s->resync_marker, s->num_sprite_warping_points,
                  s->sprite_warping_accuracy, 1-s->no_rounding, s->vo_type, s->vol_control_parameters ? " VOLC" : " ", s->intra_dc_threshold);
          }
 
          if(!s->scalability){
-             if (s->shape!=RECT_SHAPE && s->pict_type!=I_TYPE) {
+             if (s->shape!=RECT_SHAPE && s->pict_type!=FF_I_TYPE) {
                  skip_bits1(gb); // vop shape coding type
              }
          }else{
@@ -6117,7 +6117,7 @@
     }
     s->h263_plus = 0;
 
-    s->pict_type = I_TYPE + get_bits1(&s->gb);
+    s->pict_type = FF_I_TYPE + get_bits1(&s->gb);
 
     s->unrestricted_mv = get_bits1(&s->gb);
     s->h263_long_vectors = s->unrestricted_mv;
@@ -6208,10 +6208,10 @@
     s->width = width;
     s->height = height;
 
-    s->pict_type = I_TYPE + get_bits(&s->gb, 2);
-    s->dropable= s->pict_type > P_TYPE;
+    s->pict_type = FF_I_TYPE + get_bits(&s->gb, 2);
+    s->dropable= s->pict_type > FF_P_TYPE;
     if (s->dropable)
-        s->pict_type = P_TYPE;
+        s->pict_type = FF_P_TYPE;
 
     skip_bits1(&s->gb); /* deblocking flag */
     s->chroma_qscale= s->qscale = get_bits(&s->gb, 5);
Index: mythtv/libs/libavcodec/snow.c
===================================================================
--- mythtv/libs/libavcodec/snow.c	(revision 18209)
+++ mythtv/libs/libavcodec/snow.c	(working copy)
@@ -3703,7 +3703,7 @@
     }
 }
 
-static int common_init(AVCodecContext *avctx){
+static av_cold int common_init(AVCodecContext *avctx){
     SnowContext *s = avctx->priv_data;
     int width, height;
     int i, j;
@@ -3864,7 +3864,7 @@
     coef_sum = (uint64_t)coef_sum * coef_sum >> 16;
     assert(coef_sum < INT_MAX);
 
-    if(pict->pict_type == I_TYPE){
+    if(pict->pict_type == FF_I_TYPE){
         s->m.current_picture.mb_var_sum= coef_sum;
         s->m.current_picture.mc_mb_var_sum= 0;
     }else{
@@ -4025,7 +4025,7 @@
 
 #endif /* QUANTIZE2==1 */
 
-static int encode_init(AVCodecContext *avctx)
+static av_cold int encode_init(AVCodecContext *avctx)
 {
     SnowContext *s = avctx->priv_data;
     int plane_index;
@@ -4263,7 +4263,7 @@
     frame_start(s);
 
     s->m.current_picture_ptr= &s->m.current_picture;
-    if(pict->pict_type == P_TYPE){
+    if(pict->pict_type == FF_P_TYPE){
         int block_width = (width +15)>>4;
         int block_height= (height+15)>>4;
         int stride= s->current_picture.linesize[0];
@@ -4312,13 +4312,13 @@
 
 redo_frame:
 
-    if(pict->pict_type == I_TYPE)
+    if(pict->pict_type == FF_I_TYPE)
         s->spatial_decomposition_count= 5;
     else
         s->spatial_decomposition_count= 5;
 
     s->m.pict_type = pict->pict_type;
-    s->qbias= pict->pict_type == P_TYPE ? 2 : 0;
+    s->qbias= pict->pict_type == FF_P_TYPE ? 2 : 0;
 
     common_init_after_header(avctx);
 
@@ -4351,7 +4351,7 @@
         predict_plane(s, s->spatial_idwt_buffer, plane_index, 0);
 
         if(   plane_index==0
-           && pict->pict_type == P_TYPE
+           && pict->pict_type == FF_P_TYPE
            && !(avctx->flags&CODEC_FLAG_PASS2)
            && s->m.me.scene_change_score > s->avctx->scenechange_threshold){
             ff_init_range_encoder(c, buf, buf_size);
@@ -4402,7 +4402,7 @@
                 if(!QUANTIZE2)
                     quantize(s, b, b->ibuf, b->buf, b->stride, s->qbias);
                 if(orientation==0)
-                    decorrelate(s, b, b->ibuf, b->stride, pict->pict_type == P_TYPE, 0);
+                    decorrelate(s, b, b->ibuf, b->stride, pict->pict_type == FF_P_TYPE, 0);
                 encode_subband(s, b, b->ibuf, b->parent ? b->parent->ibuf : NULL, b->stride, orientation);
                 assert(b->parent==NULL || b->parent->stride == b->stride*2);
                 if(orientation==0)
@@ -4432,7 +4432,7 @@
 STOP_TIMER("pred-conv")}
       }else{
             //ME/MC only
-            if(pict->pict_type == I_TYPE){
+            if(pict->pict_type == FF_I_TYPE){
                 for(y=0; y<h; y++){
                     for(x=0; x<w; x++){
                         s->current_picture.data[plane_index][y*s->current_picture.linesize[plane_index] + x]=
@@ -4491,7 +4491,7 @@
     return ff_rac_terminate(c);
 }
 
-static void common_end(SnowContext *s){
+static av_cold void common_end(SnowContext *s){
     int plane_index, level, orientation, i;
 
     av_freep(&s->spatial_dwt_buffer);
@@ -4522,7 +4522,7 @@
     }
 }
 
-static int encode_end(AVCodecContext *avctx)
+static av_cold int encode_end(AVCodecContext *avctx)
 {
     SnowContext *s = avctx->priv_data;
 
@@ -4532,7 +4532,7 @@
     return 0;
 }
 
-static int decode_init(AVCodecContext *avctx)
+static av_cold int decode_init(AVCodecContext *avctx)
 {
     avctx->pix_fmt= PIX_FMT_YUV420P;
 
@@ -4712,7 +4712,7 @@
     return bytes_read;
 }
 
-static int decode_end(AVCodecContext *avctx)
+static av_cold int decode_end(AVCodecContext *avctx)
 {
     SnowContext *s = avctx->priv_data;
 
@@ -4749,13 +4749,13 @@
 #endif
 
 
-#if 0
+#ifdef TEST
 #undef malloc
 #undef free
 #undef printf
 #undef random
 
-int main(){
+int main(void){
     int width=256;
     int height=256;
     int buffer[2][width*height];
@@ -4898,4 +4898,4 @@
 }
     return 0;
 }
-#endif /* 0 */
+#endif /* TEST */
Index: mythtv/libs/libavcodec/kmvc.c
===================================================================
--- mythtv/libs/libavcodec/kmvc.c	(revision 18209)
+++ mythtv/libs/libavcodec/kmvc.c	(working copy)
@@ -338,7 +338,7 @@
 /*
  * Init kmvc decoder
  */
-static int decode_init(AVCodecContext * avctx)
+static av_cold int decode_init(AVCodecContext * avctx)
 {
     KmvcContext *const c = avctx->priv_data;
     int i;
@@ -390,7 +390,7 @@
 /*
  * Uninit kmvc decoder
  */
-static int decode_end(AVCodecContext * avctx)
+static av_cold int decode_end(AVCodecContext * avctx)
 {
     KmvcContext *const c = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/flicvideo.c
===================================================================
--- mythtv/libs/libavcodec/flicvideo.c	(revision 18209)
+++ mythtv/libs/libavcodec/flicvideo.c	(working copy)
@@ -76,7 +76,7 @@
     int fli_type;  /* either 0xAF11 or 0xAF12, affects palette resolution */
 } FlicDecodeContext;
 
-static int flic_decode_init(AVCodecContext *avctx)
+static av_cold int flic_decode_init(AVCodecContext *avctx)
 {
     FlicDecodeContext *s = avctx->priv_data;
     unsigned char *fli_header = (unsigned char *)avctx->extradata;
@@ -725,7 +725,7 @@
 }
 
 
-static int flic_decode_end(AVCodecContext *avctx)
+static av_cold int flic_decode_end(AVCodecContext *avctx)
 {
     FlicDecodeContext *s = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/zmbvenc.c
===================================================================
--- mythtv/libs/libavcodec/zmbvenc.c	(revision 18209)
+++ mythtv/libs/libavcodec/zmbvenc.c	(working copy)
@@ -231,7 +231,7 @@
 /**
  * Init zmbv encoder
  */
-static int encode_init(AVCodecContext *avctx)
+static av_cold int encode_init(AVCodecContext *avctx)
 {
     ZmbvEncContext * const c = avctx->priv_data;
     int zret; // Zlib return code
@@ -297,7 +297,7 @@
 /**
  * Uninit zmbv encoder
  */
-static int encode_end(AVCodecContext *avctx)
+static av_cold int encode_end(AVCodecContext *avctx)
 {
     ZmbvEncContext * const c = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/asv1.c
===================================================================
--- mythtv/libs/libavcodec/asv1.c	(revision 18209)
+++ mythtv/libs/libavcodec/asv1.c	(working copy)
@@ -113,7 +113,7 @@
 static VLC ac_ccp_vlc;
 static VLC asv2_level_vlc;
 
-static void init_vlcs(ASV1Context *a){
+static av_cold void init_vlcs(ASV1Context *a){
     static int done = 0;
 
     if (!done) {
@@ -521,7 +521,7 @@
 }
 #endif /* CONFIG_ENCODERS */
 
-static void common_init(AVCodecContext *avctx){
+static av_cold void common_init(AVCodecContext *avctx){
     ASV1Context * const a = avctx->priv_data;
 
     dsputil_init(&a->dsp, avctx);
@@ -535,7 +535,7 @@
     a->avctx= avctx;
 }
 
-static int decode_init(AVCodecContext *avctx){
+static av_cold int decode_init(AVCodecContext *avctx){
     ASV1Context * const a = avctx->priv_data;
     AVFrame *p= (AVFrame*)&a->picture;
     int i;
@@ -570,7 +570,7 @@
 }
 
 #ifdef CONFIG_ENCODERS
-static int encode_init(AVCodecContext *avctx){
+static av_cold int encode_init(AVCodecContext *avctx){
     ASV1Context * const a = avctx->priv_data;
     int i;
     const int scale= avctx->codec_id == CODEC_ID_ASV1 ? 1 : 2;
@@ -595,7 +595,7 @@
 }
 #endif
 
-static int decode_end(AVCodecContext *avctx){
+static av_cold int decode_end(AVCodecContext *avctx){
     ASV1Context * const a = avctx->priv_data;
 
     av_freep(&a->bitstream_buffer);
Index: mythtv/libs/libavcodec/qtrle.c
===================================================================
--- mythtv/libs/libavcodec/qtrle.c	(revision 18209)
+++ mythtv/libs/libavcodec/qtrle.c	(working copy)
@@ -81,7 +81,7 @@
     int rle_code;
     int row_ptr, pixel_ptr;
     int row_inc = s->frame.linesize[0];
-    unsigned char pi1, pi2, pi3, pi4, pi5, pi6, pi7, pi8;  /* 8 palette indices */
+    unsigned char pi1, pi2, pi3, pi4, pi5, pi6, pi7, pi8;  /* 8 palette indexes */
     unsigned char *rgb = s->frame.data[0];
     int pixel_limit = s->frame.linesize[0] * s->avctx->height;
 
@@ -124,7 +124,7 @@
                 /* decode the run length code */
                 rle_code = -rle_code;
                 /* get the next 4 bytes from the stream, treat them as palette
-                 * indices, and output them rle_code times */
+                 * indexes, and output them rle_code times */
                 CHECK_STREAM_PTR(4);
                 pi1 = ((s->buf[stream_ptr]) >> 4) & 0x0f;
                 pi2 = (s->buf[stream_ptr++]) & 0x0f;
@@ -172,7 +172,7 @@
     int rle_code;
     int row_ptr, pixel_ptr;
     int row_inc = s->frame.linesize[0];
-    unsigned char pi1, pi2, pi3, pi4;  /* 4 palette indices */
+    unsigned char pi1, pi2, pi3, pi4;  /* 4 palette indexes */
     unsigned char *rgb = s->frame.data[0];
     int pixel_limit = s->frame.linesize[0] * s->avctx->height;
 
@@ -215,7 +215,7 @@
                 /* decode the run length code */
                 rle_code = -rle_code;
                 /* get the next 4 bytes from the stream, treat them as palette
-                 * indices, and output them rle_code times */
+                 * indexes, and output them rle_code times */
                 CHECK_STREAM_PTR(4);
                 pi1 = s->buf[stream_ptr++];
                 pi2 = s->buf[stream_ptr++];
@@ -487,7 +487,7 @@
     }
 }
 
-static int qtrle_decode_init(AVCodecContext *avctx)
+static av_cold int qtrle_decode_init(AVCodecContext *avctx)
 {
     QtrleContext *s = avctx->priv_data;
 
@@ -603,7 +603,7 @@
     return buf_size;
 }
 
-static int qtrle_decode_end(AVCodecContext *avctx)
+static av_cold int qtrle_decode_end(AVCodecContext *avctx)
 {
     QtrleContext *s = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/error_resilience.c
===================================================================
--- mythtv/libs/libavcodec/error_resilience.c	(revision 18209)
+++ mythtv/libs/libavcodec/error_resilience.c	(working copy)
@@ -565,7 +565,7 @@
 
 #ifdef HAVE_XVMC
     //prevent dsp.sad() check, that requires access to the image
-    if(s->avctx->xvmc_acceleration && s->pict_type==I_TYPE) return 1;
+    if(s->avctx->xvmc_acceleration && s->pict_type==FF_I_TYPE) return 1;
 #endif
 
     skip_amount= FFMAX(undamaged_count/50, 1); //check only upto 50 MBs
@@ -584,7 +584,7 @@
             j++;
             if((j%skip_amount) != 0) continue; //skip a few to speed things up
 
-            if(s->pict_type==I_TYPE){
+            if(s->pict_type==FF_I_TYPE){
                 uint8_t *mb_ptr     = s->current_picture.data[0] + mb_x*16 + mb_y*16*s->linesize;
                 uint8_t *last_mb_ptr= s->last_picture.data   [0] + mb_x*16 + mb_y*16*s->linesize;
 
@@ -893,7 +893,7 @@
     }
 
     /* guess MVs */
-    if(s->pict_type==B_TYPE){
+    if(s->pict_type==FF_B_TYPE){
         for(mb_y=0; mb_y<s->mb_height; mb_y++){
             for(mb_x=0; mb_x<s->mb_width; mb_x++){
                 int xy= mb_x*2 + mb_y*2*s->b8_stride;
@@ -1031,7 +1031,7 @@
         const int mb_xy= s->mb_index2xy[i];
         int error= s->error_status_table[mb_xy];
 
-        if(s->pict_type!=B_TYPE && (error&(DC_ERROR|MV_ERROR|AC_ERROR))){
+        if(s->pict_type!=FF_B_TYPE && (error&(DC_ERROR|MV_ERROR|AC_ERROR))){
             s->mbskip_table[mb_xy]=0;
         }
         s->mbintra_table[mb_xy]=1;
Index: mythtv/libs/libavcodec/interplayvideo.c
===================================================================
--- mythtv/libs/libavcodec/interplayvideo.c	(revision 18209)
+++ mythtv/libs/libavcodec/interplayvideo.c	(working copy)
@@ -836,7 +836,7 @@
     }
 }
 
-static int ipvideo_decode_init(AVCodecContext *avctx)
+static av_cold int ipvideo_decode_init(AVCodecContext *avctx)
 {
     IpvideoContext *s = avctx->priv_data;
 
@@ -920,7 +920,7 @@
     return buf_size;
 }
 
-static int ipvideo_decode_end(AVCodecContext *avctx)
+static av_cold int ipvideo_decode_end(AVCodecContext *avctx)
 {
     IpvideoContext *s = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/utils.c
===================================================================
--- mythtv/libs/libavcodec/utils.c	(revision 18209)
+++ mythtv/libs/libavcodec/utils.c	(working copy)
@@ -1298,6 +1298,7 @@
     case S_TYPE: return 'S';
     case SI_TYPE:return 'i';
     case SP_TYPE:return 'p';
+    case FF_BI_TYPE:return 'b';
     default:     return '?';
     }
 }
Index: mythtv/libs/libavcodec/truespeech.c
===================================================================
--- mythtv/libs/libavcodec/truespeech.c	(revision 18209)
+++ mythtv/libs/libavcodec/truespeech.c	(working copy)
@@ -50,7 +50,7 @@
     int16_t filters[32]; // filters for every subframe
 } TSContext;
 
-static int truespeech_decode_init(AVCodecContext * avctx)
+static av_cold int truespeech_decode_init(AVCodecContext * avctx)
 {
 //    TSContext *c = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/msmpeg4.c
===================================================================
--- mythtv/libs/libavcodec/msmpeg4.c	(revision 18209)
+++ mythtv/libs/libavcodec/msmpeg4.c	(working copy)
@@ -263,7 +263,7 @@
                     int intra_luma_count  = s->ac_stats[1][0][level][run][last];
                     int intra_chroma_count= s->ac_stats[1][1][level][run][last];
 
-                    if(s->pict_type==I_TYPE){
+                    if(s->pict_type==FF_I_TYPE){
                         size       += intra_luma_count  *rl_length[i  ][level][run][last];
                         chroma_size+= intra_chroma_count*rl_length[i+3][level][run][last];
                     }else{
@@ -288,7 +288,7 @@
 //    printf("type:%d, best:%d, qp:%d, var:%d, mcvar:%d, size:%d //\n",
 //           s->pict_type, best, s->qscale, s->mb_var_sum, s->mc_mb_var_sum, best_size);
 
-    if(s->pict_type==P_TYPE) chroma_best= best;
+    if(s->pict_type==FF_P_TYPE) chroma_best= best;
 
     memset(s->ac_stats, 0, sizeof(int)*(MAX_LEVEL+1)*(MAX_RUN+1)*2*2*2);
 
@@ -297,7 +297,7 @@
 
     if(s->pict_type != s->last_non_b_pict_type){
         s->rl_table_index= 2;
-        if(s->pict_type==I_TYPE)
+        if(s->pict_type==FF_I_TYPE)
             s->rl_chroma_table_index= 1;
         else
             s->rl_chroma_table_index= 2;
@@ -324,10 +324,10 @@
     s->use_skip_mb_code = 1; /* only if P frame */
     s->per_mb_rl_table = 0;
     if(s->msmpeg4_version==4)
-        s->inter_intra_pred= (s->width*s->height < 320*240 && s->bit_rate<=II_BITRATE && s->pict_type==P_TYPE);
+        s->inter_intra_pred= (s->width*s->height < 320*240 && s->bit_rate<=II_BITRATE && s->pict_type==FF_P_TYPE);
 //printf("%d %d %d %d %d\n", s->pict_type, s->bit_rate, s->inter_intra_pred, s->width, s->height);
 
-    if (s->pict_type == I_TYPE) {
+    if (s->pict_type == FF_I_TYPE) {
         s->slice_height= s->mb_height/1;
         put_bits(&s->pb, 5, 0x16 + s->mb_height/s->slice_height);
 
@@ -550,7 +550,7 @@
 #endif
 
         if(s->msmpeg4_version<=2){
-            if (s->pict_type == I_TYPE) {
+            if (s->pict_type == FF_I_TYPE) {
                 put_bits(&s->pb,
                          v2_intra_cbpc[cbp&3][1], v2_intra_cbpc[cbp&3][0]);
             } else {
@@ -565,7 +565,7 @@
                      cbpy_tab[cbp>>2][1],
                      cbpy_tab[cbp>>2][0]);
         }else{
-            if (s->pict_type == I_TYPE) {
+            if (s->pict_type == FF_I_TYPE) {
                 put_bits(&s->pb,
                          ff_msmp4_mb_i_table[coded_cbp][1], ff_msmp4_mb_i_table[coded_cbp][0]);
             } else {
@@ -1176,15 +1176,15 @@
     }
 
     s->pict_type = get_bits(&s->gb, 2) + 1;
-    if (s->pict_type != I_TYPE &&
-        s->pict_type != P_TYPE){
+    if (s->pict_type != FF_I_TYPE &&
+        s->pict_type != FF_P_TYPE){
         av_log(s->avctx, AV_LOG_ERROR, "invalid picture type\n");
         return -1;
     }
 #if 0
 {
     static int had_i=0;
-    if(s->pict_type == I_TYPE) had_i=1;
+    if(s->pict_type == FF_I_TYPE) had_i=1;
     if(!had_i) return -1;
 }
 #endif
@@ -1194,7 +1194,7 @@
         return -1;
     }
 
-    if (s->pict_type == I_TYPE) {
+    if (s->pict_type == FF_I_TYPE) {
         code = get_bits(&s->gb, 5);
         if(s->msmpeg4_version==1){
             if(code==0 || code>s->mb_height){
@@ -1428,7 +1428,7 @@
 {
     int cbp, code, i;
 
-    if (s->pict_type == P_TYPE) {
+    if (s->pict_type == FF_P_TYPE) {
         if (s->use_skip_mb_code) {
             if (get_bits1(&s->gb)) {
                 /* skip mb */
@@ -1495,7 +1495,7 @@
         } else{
             s->ac_pred = 0;
             cbp|= get_vlc2(&s->gb, cbpy_vlc.table, CBPY_VLC_BITS, 1)<<2; //FIXME check errors
-            if(s->pict_type==P_TYPE) cbp^=0x3C;
+            if(s->pict_type==FF_P_TYPE) cbp^=0x3C;
         }
     }
 
@@ -1516,7 +1516,7 @@
     uint8_t *coded_val;
     uint32_t * const mb_type_ptr= &s->current_picture.mb_type[ s->mb_x + s->mb_y*s->mb_stride ];
 
-    if (s->pict_type == P_TYPE) {
+    if (s->pict_type == FF_P_TYPE) {
         if (s->use_skip_mb_code) {
             if (get_bits1(&s->gb)) {
                 /* skip mb */
Index: mythtv/libs/libavcodec/8bps.c
===================================================================
--- mythtv/libs/libavcodec/8bps.c	(revision 18209)
+++ mythtv/libs/libavcodec/8bps.c	(working copy)
@@ -148,7 +148,7 @@
  * Init 8BPS decoder
  *
  */
-static int decode_init(AVCodecContext *avctx)
+static av_cold int decode_init(AVCodecContext *avctx)
 {
         EightBpsContext * const c = avctx->priv_data;
 
@@ -208,7 +208,7 @@
  * Uninit 8BPS decoder
  *
  */
-static int decode_end(AVCodecContext *avctx)
+static av_cold int decode_end(AVCodecContext *avctx)
 {
         EightBpsContext * const c = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/h264.c
===================================================================
--- mythtv/libs/libavcodec/h264.c	(revision 18209)
+++ mythtv/libs/libavcodec/h264.c	(working copy)
@@ -32,8 +32,12 @@
 #include "h264data.h"
 #include "h264_parser.h"
 #include "golomb.h"
+#include "rectangle.h"
 
 #include "cabac.h"
+#ifdef ARCH_X86
+#include "i386/h264_i386.h"
+#endif
 
 //#undef NDEBUG
 #include <assert.h>
@@ -45,18 +49,34 @@
 #define DELAYED_PIC_REF 4
 
 static VLC coeff_token_vlc[4];
+static VLC_TYPE coeff_token_vlc_tables[520+332+280+256][2];
+static const int coeff_token_vlc_tables_size[4]={520,332,280,256};
+
 static VLC chroma_dc_coeff_token_vlc;
+static VLC_TYPE chroma_dc_coeff_token_vlc_table[256][2];
+static const int chroma_dc_coeff_token_vlc_table_size = 256;
 
 static VLC total_zeros_vlc[15];
+static VLC_TYPE total_zeros_vlc_tables[15][512][2];
+static const int total_zeros_vlc_tables_size = 512;
+
 static VLC chroma_dc_total_zeros_vlc[3];
+static VLC_TYPE chroma_dc_total_zeros_vlc_tables[3][8][2];
+static const int chroma_dc_total_zeros_vlc_tables_size = 8;
 
 static VLC run_vlc[6];
+static VLC_TYPE run_vlc_tables[6][8][2];
+static const int run_vlc_tables_size = 8;
+
 static VLC run7_vlc;
+static VLC_TYPE run7_vlc_table[96][2];
+static const int run7_vlc_table_size = 96;
 
 static void svq3_luma_dc_dequant_idct_c(DCTELEM *block, int qp);
 static void svq3_add_idct_c(uint8_t *dst, DCTELEM *block, int stride, int qp, int dc);
 static void filter_mb( H264Context *h, int mb_x, int mb_y, uint8_t *img_y, uint8_t *img_cb, uint8_t *img_cr, unsigned int linesize, unsigned int uvlinesize);
 static void filter_mb_fast( H264Context *h, int mb_x, int mb_y, uint8_t *img_y, uint8_t *img_cb, uint8_t *img_cr, unsigned int linesize, unsigned int uvlinesize);
+static Picture * remove_long(H264Context *h, int i, int ref_mask);
 
 static av_always_inline uint32_t pack16to32(int a, int b){
 #ifdef WORDS_BIGENDIAN
@@ -74,121 +94,34 @@
 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8,
 };
 
+static const int left_block_options[4][8]={
+    {0,1,2,3,7,10,8,11},
+    {2,2,3,3,8,11,8,11},
+    {0,0,1,1,7,10,7,10},
+    {0,2,0,2,7,10,7,10}
+};
 
-/**
- * fill a rectangle.
- * @param h height of the rectangle, should be a constant
- * @param w width of the rectangle, should be a constant
- * @param size the size of val (1 or 4), should be a constant
- */
-static av_always_inline void fill_rectangle(void *vp, int w, int h, int stride, uint32_t val, int size){
-    uint8_t *p= (uint8_t*)vp;
-    assert(size==1 || size==4);
-    assert(w<=4);
-
-    w      *= size;
-    stride *= size;
-
-    assert((((long)vp)&(FFMIN(w, STRIDE_ALIGN)-1)) == 0);
-    assert((stride&(w-1))==0);
-    if(w==2){
-        const uint16_t v= size==4 ? val : val*0x0101;
-        *(uint16_t*)(p + 0*stride)= v;
-        if(h==1) return;
-        *(uint16_t*)(p + 1*stride)= v;
-        if(h==2) return;
-        *(uint16_t*)(p + 2*stride)= v;
-        *(uint16_t*)(p + 3*stride)= v;
-    }else if(w==4){
-        const uint32_t v= size==4 ? val : val*0x01010101;
-        *(uint32_t*)(p + 0*stride)= v;
-        if(h==1) return;
-        *(uint32_t*)(p + 1*stride)= v;
-        if(h==2) return;
-        *(uint32_t*)(p + 2*stride)= v;
-        *(uint32_t*)(p + 3*stride)= v;
-    }else if(w==8){
-    //gcc can't optimize 64bit math on x86_32
-#if defined(ARCH_X86_64) || (defined(MP_WORDSIZE) && MP_WORDSIZE >= 64)
-        const uint64_t v= val*0x0100000001ULL;
-        *(uint64_t*)(p + 0*stride)= v;
-        if(h==1) return;
-        *(uint64_t*)(p + 1*stride)= v;
-        if(h==2) return;
-        *(uint64_t*)(p + 2*stride)= v;
-        *(uint64_t*)(p + 3*stride)= v;
-    }else if(w==16){
-        const uint64_t v= val*0x0100000001ULL;
-        *(uint64_t*)(p + 0+0*stride)= v;
-        *(uint64_t*)(p + 8+0*stride)= v;
-        *(uint64_t*)(p + 0+1*stride)= v;
-        *(uint64_t*)(p + 8+1*stride)= v;
-        if(h==2) return;
-        *(uint64_t*)(p + 0+2*stride)= v;
-        *(uint64_t*)(p + 8+2*stride)= v;
-        *(uint64_t*)(p + 0+3*stride)= v;
-        *(uint64_t*)(p + 8+3*stride)= v;
-#else
-        *(uint32_t*)(p + 0+0*stride)= val;
-        *(uint32_t*)(p + 4+0*stride)= val;
-        if(h==1) return;
-        *(uint32_t*)(p + 0+1*stride)= val;
-        *(uint32_t*)(p + 4+1*stride)= val;
-        if(h==2) return;
-        *(uint32_t*)(p + 0+2*stride)= val;
-        *(uint32_t*)(p + 4+2*stride)= val;
-        *(uint32_t*)(p + 0+3*stride)= val;
-        *(uint32_t*)(p + 4+3*stride)= val;
-    }else if(w==16){
-        *(uint32_t*)(p + 0+0*stride)= val;
-        *(uint32_t*)(p + 4+0*stride)= val;
-        *(uint32_t*)(p + 8+0*stride)= val;
-        *(uint32_t*)(p +12+0*stride)= val;
-        *(uint32_t*)(p + 0+1*stride)= val;
-        *(uint32_t*)(p + 4+1*stride)= val;
-        *(uint32_t*)(p + 8+1*stride)= val;
-        *(uint32_t*)(p +12+1*stride)= val;
-        if(h==2) return;
-        *(uint32_t*)(p + 0+2*stride)= val;
-        *(uint32_t*)(p + 4+2*stride)= val;
-        *(uint32_t*)(p + 8+2*stride)= val;
-        *(uint32_t*)(p +12+2*stride)= val;
-        *(uint32_t*)(p + 0+3*stride)= val;
-        *(uint32_t*)(p + 4+3*stride)= val;
-        *(uint32_t*)(p + 8+3*stride)= val;
-        *(uint32_t*)(p +12+3*stride)= val;
-#endif
-    }else
-        assert(0);
-    assert(h==4);
-}
-
 static void fill_caches(H264Context *h, int mb_type, int for_deblock){
     MpegEncContext * const s = &h->s;
-    const int mb_xy= s->mb_x + s->mb_y*s->mb_stride;
+    const int mb_xy= h->mb_xy;
     int topleft_xy, top_xy, topright_xy, left_xy[2];
     int topleft_type, top_type, topright_type, left_type[2];
-    int left_block[8];
+    int * left_block;
+    int topleft_partition= -1;
     int i;
 
+    top_xy     = mb_xy  - (s->mb_stride << FIELD_PICTURE);
+
     //FIXME deblocking could skip the intra and nnz parts.
-    if(for_deblock && (h->slice_num == 1 || h->slice_table[mb_xy] == h->slice_table[mb_xy-s->mb_stride]) && !FRAME_MBAFF)
+    if(for_deblock && (h->slice_num == 1 || h->slice_table[mb_xy] == h->slice_table[top_xy]) && !FRAME_MBAFF)
         return;
 
     //wow what a mess, why didn't they simplify the interlacing&intra stuff, i can't imagine that these complex rules are worth it
 
-    top_xy     = mb_xy  - (s->mb_stride << FIELD_PICTURE);
     topleft_xy = top_xy - 1;
     topright_xy= top_xy + 1;
     left_xy[1] = left_xy[0] = mb_xy-1;
-    left_block[0]= 0;
-    left_block[1]= 1;
-    left_block[2]= 2;
-    left_block[3]= 3;
-    left_block[4]= 7;
-    left_block[5]= 10;
-    left_block[6]= 8;
-    left_block[7]= 11;
+    left_block = left_block_options[0];
     if(FRAME_MBAFF){
         const int pair_xy          = s->mb_x     + (s->mb_y & ~1)*s->mb_stride;
         const int top_pair_xy      = pair_xy     - s->mb_stride;
@@ -212,6 +145,10 @@
                 : (!curr_mb_frame_flag && !topleft_mb_frame_flag) // top macroblock
                 ) {
             topleft_xy -= s->mb_stride;
+        } else if(bottom && curr_mb_frame_flag && !left_mb_frame_flag) {
+            topleft_xy += s->mb_stride;
+            // take top left mv from the middle of the mb, as opposed to all other modes which use the bottom right partition
+            topleft_partition = 0;
         }
         if (bottom
                 ? !curr_mb_frame_flag // bottom macroblock
@@ -223,34 +160,13 @@
             left_xy[1] = left_xy[0] = pair_xy - 1;
             if (curr_mb_frame_flag) {
                 if (bottom) {
-                    left_block[0]= 2;
-                    left_block[1]= 2;
-                    left_block[2]= 3;
-                    left_block[3]= 3;
-                    left_block[4]= 8;
-                    left_block[5]= 11;
-                    left_block[6]= 8;
-                    left_block[7]= 11;
+                    left_block = left_block_options[1];
                 } else {
-                    left_block[0]= 0;
-                    left_block[1]= 0;
-                    left_block[2]= 1;
-                    left_block[3]= 1;
-                    left_block[4]= 7;
-                    left_block[5]= 10;
-                    left_block[6]= 7;
-                    left_block[7]= 10;
+                    left_block= left_block_options[2];
                 }
             } else {
                 left_xy[1] += s->mb_stride;
-                //left_block[0]= 0;
-                left_block[1]= 2;
-                left_block[2]= 0;
-                left_block[3]= 2;
-                //left_block[4]= 7;
-                left_block[5]= 10;
-                left_block[6]= 7;
-                left_block[7]= 10;
+                left_block = left_block_options[3];
             }
         }
     }
@@ -265,30 +181,19 @@
         left_type[0] = h->slice_table[left_xy[0] ] < 255 ? s->current_picture.mb_type[left_xy[0]] : 0;
         left_type[1] = h->slice_table[left_xy[1] ] < 255 ? s->current_picture.mb_type[left_xy[1]] : 0;
 
-        if(FRAME_MBAFF && !IS_INTRA(mb_type)){
+        if(MB_MBAFF && !IS_INTRA(mb_type)){
             int list;
-            int v = *(uint16_t*)&h->non_zero_count[mb_xy][14];
-            for(i=0; i<16; i++)
-                h->non_zero_count_cache[scan8[i]] = (v>>i)&1;
             for(list=0; list<h->list_count; list++){
+                //These values where changed for ease of performing MC, we need to change them back
+                //FIXME maybe we can make MC and loop filter use the same values or prevent
+                //the MC code from changing ref_cache and rather use a temporary array.
                 if(USES_LIST(mb_type,list)){
-                    uint32_t *src = (uint32_t*)s->current_picture.motion_val[list][h->mb2b_xy[mb_xy]];
-                    uint32_t *dst = (uint32_t*)h->mv_cache[list][scan8[0]];
                     int8_t *ref = &s->current_picture.ref_index[list][h->mb2b8_xy[mb_xy]];
-                    for(i=0; i<4; i++, dst+=8, src+=h->b_stride){
-                        dst[0] = src[0];
-                        dst[1] = src[1];
-                        dst[2] = src[2];
-                        dst[3] = src[3];
-                    }
                     *(uint32_t*)&h->ref_cache[list][scan8[ 0]] =
-                    *(uint32_t*)&h->ref_cache[list][scan8[ 2]] = pack16to32(ref[0],ref[1])*0x0101;
+                    *(uint32_t*)&h->ref_cache[list][scan8[ 2]] = (pack16to32(ref[0],ref[1])&0x00FF00FF)*0x0101;
                     ref += h->b8_stride;
                     *(uint32_t*)&h->ref_cache[list][scan8[ 8]] =
-                    *(uint32_t*)&h->ref_cache[list][scan8[10]] = pack16to32(ref[0],ref[1])*0x0101;
-                }else{
-                    fill_rectangle(&h-> mv_cache[list][scan8[ 0]], 4, 4, 8, 0, 4);
-                    fill_rectangle(&h->ref_cache[list][scan8[ 0]], 4, 4, 8, (uint8_t)LIST_NOT_USED, 1);
+                    *(uint32_t*)&h->ref_cache[list][scan8[10]] = (pack16to32(ref[0],ref[1])&0x00FF00FF)*0x0101;
                 }
             }
         }
@@ -298,30 +203,49 @@
         topright_type= h->slice_table[topright_xy] == h->slice_num ? s->current_picture.mb_type[topright_xy]: 0;
         left_type[0] = h->slice_table[left_xy[0] ] == h->slice_num ? s->current_picture.mb_type[left_xy[0]] : 0;
         left_type[1] = h->slice_table[left_xy[1] ] == h->slice_num ? s->current_picture.mb_type[left_xy[1]] : 0;
-    }
 
     if(IS_INTRA(mb_type)){
+        int type_mask= h->pps.constrained_intra_pred ? IS_INTRA(-1) : -1;
         h->topleft_samples_available=
         h->top_samples_available=
         h->left_samples_available= 0xFFFF;
         h->topright_samples_available= 0xEEEA;
 
-        if(!IS_INTRA(top_type) && (top_type==0 || h->pps.constrained_intra_pred)){
+        if(!(top_type & type_mask)){
             h->topleft_samples_available= 0xB3FF;
             h->top_samples_available= 0x33FF;
             h->topright_samples_available= 0x26EA;
         }
-        for(i=0; i<2; i++){
-            if(!IS_INTRA(left_type[i]) && (left_type[i]==0 || h->pps.constrained_intra_pred)){
+        if(IS_INTERLACED(mb_type) != IS_INTERLACED(left_type[0])){
+            if(IS_INTERLACED(mb_type)){
+                if(!(left_type[0] & type_mask)){
+                    h->topleft_samples_available&= 0xDFFF;
+                    h->left_samples_available&= 0x5FFF;
+                }
+                if(!(left_type[1] & type_mask)){
+                    h->topleft_samples_available&= 0xFF5F;
+                    h->left_samples_available&= 0xFF5F;
+                }
+            }else{
+                int left_typei = h->slice_table[left_xy[0] + s->mb_stride ] == h->slice_num
+                                ? s->current_picture.mb_type[left_xy[0] + s->mb_stride] : 0;
+                assert(left_xy[0] == left_xy[1]);
+                if(!((left_typei & type_mask) && (left_type[0] & type_mask))){
+                    h->topleft_samples_available&= 0xDF5F;
+                    h->left_samples_available&= 0x5F5F;
+                }
+            }
+        }else{
+            if(!(left_type[0] & type_mask)){
                 h->topleft_samples_available&= 0xDF5F;
                 h->left_samples_available&= 0x5F5F;
             }
         }
 
-        if(!IS_INTRA(topleft_type) && (topleft_type==0 || h->pps.constrained_intra_pred))
+        if(!(topleft_type & type_mask))
             h->topleft_samples_available&= 0x7FFF;
 
-        if(!IS_INTRA(topright_type) && (topright_type==0 || h->pps.constrained_intra_pred))
+        if(!(topright_type & type_mask))
             h->topright_samples_available&= 0xFBFF;
 
         if(IS_INTRA4x4(mb_type)){
@@ -332,7 +256,7 @@
                 h->intra4x4_pred_mode_cache[7+8*0]= h->intra4x4_pred_mode[top_xy][3];
             }else{
                 int pred;
-                if(!top_type || (IS_INTER(top_type) && h->pps.constrained_intra_pred))
+                if(!(top_type & type_mask))
                     pred= -1;
                 else{
                     pred= 2;
@@ -348,7 +272,7 @@
                     h->intra4x4_pred_mode_cache[3+8*2 + 2*8*i]= h->intra4x4_pred_mode[left_xy[i]][left_block[1+2*i]];
                 }else{
                     int pred;
-                    if(!left_type[i] || (IS_INTER(left_type[i]) && h->pps.constrained_intra_pred))
+                    if(!(left_type[i] & type_mask))
                         pred= -1;
                     else{
                         pred= 2;
@@ -359,6 +283,7 @@
             }
         }
     }
+    }
 
 
 /*
@@ -369,7 +294,7 @@
 4 L . .L . . . .
 5 L . .. . . . .
 */
-//FIXME constraint_intra_pred & partitioning & nnz (lets hope this is just a typo in the spec)
+//FIXME constraint_intra_pred & partitioning & nnz (let us hope this is just a typo in the spec)
     if(top_type){
         h->non_zero_count_cache[4+8*0]= h->non_zero_count[top_xy][4];
         h->non_zero_count_cache[5+8*0]= h->non_zero_count[top_xy][5];
@@ -485,12 +410,12 @@
                 }
             }
 
-            if((for_deblock || (IS_DIRECT(mb_type) && !h->direct_spatial_mv_pred)) && !FRAME_MBAFF)
+            if(for_deblock || ((IS_DIRECT(mb_type) && !h->direct_spatial_mv_pred) && !FRAME_MBAFF))
                 continue;
 
             if(USES_LIST(topleft_type, list)){
-                const int b_xy = h->mb2b_xy[topleft_xy] + 3 + 3*h->b_stride;
-                const int b8_xy= h->mb2b8_xy[topleft_xy] + 1 + h->b8_stride;
+                const int b_xy = h->mb2b_xy[topleft_xy] + 3 + h->b_stride + (topleft_partition & 2*h->b_stride);
+                const int b8_xy= h->mb2b8_xy[topleft_xy] + 1 + (topleft_partition & h->b8_stride);
                 *(uint32_t*)h->mv_cache[list][scan8[0] - 1 - 1*8]= *(uint32_t*)s->current_picture.motion_val[list][b_xy];
                 h->ref_cache[list][scan8[0] - 1 - 1*8]= s->current_picture.ref_index[list][b8_xy];
             }else{
@@ -558,7 +483,7 @@
                 *(uint32_t*)h->mvd_cache [list][scan8[4 ]]=
                 *(uint32_t*)h->mvd_cache [list][scan8[12]]= 0;
 
-                if(h->slice_type == B_TYPE){
+                if(h->slice_type_nos == FF_B_TYPE){
                     fill_rectangle(&h->direct_cache[scan8[0]], 4, 4, 8, 0, 1);
 
                     if(IS_DIRECT(top_type)){
@@ -627,8 +552,7 @@
 }
 
 static inline void write_back_intra_pred_mode(H264Context *h){
-    MpegEncContext * const s = &h->s;
-    const int mb_xy= s->mb_x + s->mb_y*s->mb_stride;
+    const int mb_xy= h->mb_xy;
 
     h->intra4x4_pred_mode[mb_xy][0]= h->intra4x4_pred_mode_cache[7+8*1];
     h->intra4x4_pred_mode[mb_xy][1]= h->intra4x4_pred_mode_cache[7+8*2];
@@ -660,8 +584,10 @@
         }
     }
 
-    if(!(h->left_samples_available&0x8000)){
+    if((h->left_samples_available&0x8888)!=0x8888){
+        static const int mask[4]={0x8000,0x2000,0x80,0x20};
         for(i=0; i<4; i++){
+            if(!(h->left_samples_available&mask[i])){
             int status= left[ h->intra4x4_pred_mode_cache[scan8[0] + 8*i] ];
             if(status<0){
                 av_log(h->s.avctx, AV_LOG_ERROR, "left block unavailable for requested intra4x4 mode %d at %d %d\n", status, s->mb_x, s->mb_y);
@@ -669,6 +595,7 @@
             } else if(status){
                 h->intra4x4_pred_mode_cache[scan8[0] + 8*i]= status;
             }
+            }
         }
     }
 
@@ -696,8 +623,11 @@
         }
     }
 
-    if(!(h->left_samples_available&0x8000)){
+    if((h->left_samples_available&0x8080) != 0x8080){
         mode= left[ mode ];
+        if(h->left_samples_available&0x8080){ //mad cow disease mode, aka MBAFF + constrained_intra_pred
+            mode= ALZHEIMER_DC_L0T_PRED8x8 + (!(h->left_samples_available&0x8000)) + 2*(mode == DC_128_PRED8x8);
+        }
         if(mode<0){
             av_log(h->s.avctx, AV_LOG_ERROR, "left block unavailable for requested intra mode at %d %d\n", s->mb_x, s->mb_y);
             return -1;
@@ -723,8 +653,7 @@
 }
 
 static inline void write_back_non_zero_count(H264Context *h){
-    MpegEncContext * const s = &h->s;
-    const int mb_xy= s->mb_x + s->mb_y*s->mb_stride;
+    const int mb_xy= h->mb_xy;
 
     h->non_zero_count[mb_xy][0]= h->non_zero_count_cache[7+8*1];
     h->non_zero_count[mb_xy][1]= h->non_zero_count_cache[7+8*2];
@@ -741,18 +670,10 @@
     h->non_zero_count[mb_xy][12]=h->non_zero_count_cache[1+8*5];
     h->non_zero_count[mb_xy][11]=h->non_zero_count_cache[2+8*5];
     h->non_zero_count[mb_xy][10]=h->non_zero_count_cache[2+8*4];
-
-    if(FRAME_MBAFF){
-        // store all luma nnzs, for deblocking
-        int v = 0, i;
-        for(i=0; i<16; i++)
-            v += (!!h->non_zero_count_cache[scan8[i]]) << i;
-        *(uint16_t*)&h->non_zero_count[mb_xy][14] = v;
-    }
 }
 
 /**
- * gets the predicted number of non zero coefficients.
+ * gets the predicted number of non-zero coefficients.
  * @param n block index
  */
 static inline int pred_non_zero_count(H264Context *h, int n){
@@ -787,7 +708,7 @@
 #define SET_DIAG_MV(MV_OP, REF_OP, X4, Y4)\
                 const int x4 = X4, y4 = Y4;\
                 const int mb_type = mb_types[(x4>>2)+(y4>>2)*s->mb_stride];\
-                if(!USES_LIST(mb_type,list) && !IS_8X8(mb_type))\
+                if(!USES_LIST(mb_type,list))\
                     return LIST_NOT_USED;\
                 mv = s->current_picture_ptr->motion_val[list][x4 + y4*h->b_stride];\
                 h->mv_cache[list][scan8[0]-2][0] = mv[0];\
@@ -807,8 +728,8 @@
             if(MB_FIELD
                && !IS_INTERLACED(mb_types[h->left_mb_xy[0]])
                && i >= scan8[0]+8){
-                // leftshift will turn LIST_NOT_USED into PART_NOT_AVAILABLE, but that's ok.
-                SET_DIAG_MV(>>1, <<1, s->mb_x*4-1, (s->mb_y&~1)*4 - 1 + ((i-scan8[0])>>3)*2);
+                // left shift will turn LIST_NOT_USED into PART_NOT_AVAILABLE, but that's OK.
+                SET_DIAG_MV(/2, <<1, s->mb_x*4-1, (s->mb_y&~1)*4 - 1 + ((i-scan8[0])>>3)*2);
             }
         }
 #undef SET_DIAG_MV
@@ -973,13 +894,14 @@
 }
 
 static inline void direct_dist_scale_factor(H264Context * const h){
-    const int poc = h->s.current_picture_ptr->poc;
+    MpegEncContext * const s = &h->s;
+    const int poc = h->s.current_picture_ptr->field_poc[ s->picture_structure == PICT_BOTTOM_FIELD ];
     const int poc1 = h->ref_list[1][0].poc;
     int i;
     for(i=0; i<h->ref_count[0]; i++){
         int poc0 = h->ref_list[0][i].poc;
         int td = av_clip(poc1 - poc0, -128, 127);
-        if(td == 0 /* FIXME || pic0 is a long-term ref */){
+        if(td == 0 || h->ref_list[0][i].long_ref){
             h->dist_scale_factor[i] = 256;
         }else{
             int tb = av_clip(poc - poc0, -128, 127);
@@ -999,23 +921,27 @@
     Picture * const ref1 = &h->ref_list[1][0];
     Picture * const cur = s->current_picture_ptr;
     int list, i, j;
-    if(cur->pict_type == I_TYPE)
-        cur->ref_count[0] = 0;
-    if(cur->pict_type != B_TYPE)
-        cur->ref_count[1] = 0;
+    int sidx= s->picture_structure&1;
+    int ref1sidx= ref1->reference&1;
     for(list=0; list<2; list++){
-        cur->ref_count[list] = h->ref_count[list];
+        cur->ref_count[sidx][list] = h->ref_count[list];
         for(j=0; j<h->ref_count[list]; j++)
-            cur->ref_poc[list][j] = h->ref_list[list][j].poc;
+            cur->ref_poc[sidx][list][j] = 4*h->ref_list[list][j].frame_num + (h->ref_list[list][j].reference&3);
     }
-    if(cur->pict_type != B_TYPE || h->direct_spatial_mv_pred)
+    if(s->picture_structure == PICT_FRAME){
+        memcpy(cur->ref_count[0], cur->ref_count[1], sizeof(cur->ref_count[0]));
+        memcpy(cur->ref_poc  [0], cur->ref_poc  [1], sizeof(cur->ref_poc  [0]));
+    }
+    if(cur->pict_type != FF_B_TYPE || h->direct_spatial_mv_pred)
         return;
     for(list=0; list<2; list++){
-        for(i=0; i<ref1->ref_count[list]; i++){
-            const int poc = ref1->ref_poc[list][i];
+        for(i=0; i<ref1->ref_count[ref1sidx][list]; i++){
+            int poc = ref1->ref_poc[ref1sidx][list][i];
+            if(((poc&3) == 3) != (s->picture_structure == PICT_FRAME))
+                poc= (poc&~3) + s->picture_structure;
             h->map_col_to_list0[list][i] = 0; /* bogus; fills in for missing frames */
             for(j=0; j<h->ref_count[list]; j++)
-                if(h->ref_list[list][j].poc == poc){
+                if(4*h->ref_list[list][j].frame_num + (h->ref_list[list][j].reference&3) == poc){
                     h->map_col_to_list0[list][i] = j;
                     break;
                 }
@@ -1023,7 +949,7 @@
     }
     if(FRAME_MBAFF){
         for(list=0; list<2; list++){
-            for(i=0; i<ref1->ref_count[list]; i++){
+            for(i=0; i<ref1->ref_count[ref1sidx][list]; i++){
                 j = h->map_col_to_list0[list][i];
                 h->map_col_to_list0_field[list][2*i] = 2*j;
                 h->map_col_to_list0_field[list][2*i+1] = 2*j+1;
@@ -1034,37 +960,80 @@
 
 static inline void pred_direct_motion(H264Context * const h, int *mb_type){
     MpegEncContext * const s = &h->s;
-    const int mb_xy =   s->mb_x +   s->mb_y*s->mb_stride;
-    const int b8_xy = 2*s->mb_x + 2*s->mb_y*h->b8_stride;
-    const int b4_xy = 4*s->mb_x + 4*s->mb_y*h->b_stride;
-    const int mb_type_col = h->ref_list[1][0].mb_type[mb_xy];
-    const int16_t (*l1mv0)[2] = (const int16_t (*)[2]) &h->ref_list[1][0].motion_val[0][b4_xy];
-    const int16_t (*l1mv1)[2] = (const int16_t (*)[2]) &h->ref_list[1][0].motion_val[1][b4_xy];
-    const int8_t *l1ref0 = &h->ref_list[1][0].ref_index[0][b8_xy];
-    const int8_t *l1ref1 = &h->ref_list[1][0].ref_index[1][b8_xy];
+    int b8_stride = h->b8_stride;
+    int b4_stride = h->b_stride;
+    int mb_xy = h->mb_xy;
+    int mb_type_col[2];
+    const int16_t (*l1mv0)[2], (*l1mv1)[2];
+    const int8_t *l1ref0, *l1ref1;
     const int is_b8x8 = IS_8X8(*mb_type);
     unsigned int sub_mb_type;
     int i8, i4;
 
 #define MB_TYPE_16x16_OR_INTRA (MB_TYPE_16x16|MB_TYPE_INTRA4x4|MB_TYPE_INTRA16x16|MB_TYPE_INTRA_PCM)
-    if(IS_8X8(mb_type_col) && !h->sps.direct_8x8_inference_flag){
-        /* FIXME save sub mb types from previous frames (or derive from MVs)
-         * so we know exactly what block size to use */
-        sub_mb_type = MB_TYPE_8x8|MB_TYPE_P0L0|MB_TYPE_P0L1|MB_TYPE_DIRECT2; /* B_SUB_4x4 */
-        *mb_type =    MB_TYPE_8x8|MB_TYPE_L0L1;
-    }else if(!is_b8x8 && (mb_type_col & MB_TYPE_16x16_OR_INTRA)){
-        sub_mb_type = MB_TYPE_16x16|MB_TYPE_P0L0|MB_TYPE_P0L1|MB_TYPE_DIRECT2; /* B_SUB_8x8 */
-        *mb_type =    MB_TYPE_16x16|MB_TYPE_P0L0|MB_TYPE_P0L1|MB_TYPE_DIRECT2; /* B_16x16 */
-    }else{
-        sub_mb_type = MB_TYPE_16x16|MB_TYPE_P0L0|MB_TYPE_P0L1|MB_TYPE_DIRECT2; /* B_SUB_8x8 */
-        *mb_type =    MB_TYPE_8x8|MB_TYPE_L0L1;
+
+    if(IS_INTERLACED(h->ref_list[1][0].mb_type[mb_xy])){ // AFL/AFR/FR/FL -> AFL/FL
+        if(h->ref_list[1][0].reference == PICT_FRAME){   // AFL/AFR/FR/FL -> AFL
+            if(!IS_INTERLACED(*mb_type)){                //     AFR/FR    -> AFL
+                int cur_poc = s->current_picture_ptr->poc;
+                int *col_poc = h->ref_list[1]->field_poc;
+                int col_parity = FFABS(col_poc[0] - cur_poc) >= FFABS(col_poc[1] - cur_poc);
+                mb_xy= s->mb_x + ((s->mb_y&~1) + col_parity)*s->mb_stride;
+                b8_stride = 0;
+            }
+        }else if(!(s->picture_structure & h->ref_list[1][0].reference)){// FL -> FL & differ parity
+            int fieldoff= 2*(h->ref_list[1][0].reference)-3;
+            mb_xy += s->mb_stride*fieldoff;
+        }
+        goto single_col;
+    }else{                                               // AFL/AFR/FR/FL -> AFR/FR
+        if(IS_INTERLACED(*mb_type)){                     // AFL       /FL -> AFR/FR
+            mb_xy= s->mb_x + (s->mb_y&~1)*s->mb_stride;
+            mb_type_col[0] = h->ref_list[1][0].mb_type[mb_xy];
+            mb_type_col[1] = h->ref_list[1][0].mb_type[mb_xy + s->mb_stride];
+            b8_stride *= 3;
+            b4_stride *= 6;
+            //FIXME IS_8X8(mb_type_col[0]) && !h->sps.direct_8x8_inference_flag
+            if(    (mb_type_col[0] & MB_TYPE_16x16_OR_INTRA)
+                && (mb_type_col[1] & MB_TYPE_16x16_OR_INTRA)
+                && !is_b8x8){
+                sub_mb_type = MB_TYPE_16x16|MB_TYPE_P0L0|MB_TYPE_P0L1|MB_TYPE_DIRECT2; /* B_SUB_8x8 */
+                *mb_type   |= MB_TYPE_16x8 |MB_TYPE_L0L1|MB_TYPE_DIRECT2; /* B_16x8 */
+            }else{
+                sub_mb_type = MB_TYPE_16x16|MB_TYPE_P0L0|MB_TYPE_P0L1|MB_TYPE_DIRECT2; /* B_SUB_8x8 */
+                *mb_type   |= MB_TYPE_8x8|MB_TYPE_L0L1;
+            }
+        }else{                                           //     AFR/FR    -> AFR/FR
+single_col:
+            mb_type_col[0] =
+            mb_type_col[1] = h->ref_list[1][0].mb_type[mb_xy];
+            if(IS_8X8(mb_type_col[0]) && !h->sps.direct_8x8_inference_flag){
+                /* FIXME save sub mb types from previous frames (or derive from MVs)
+                * so we know exactly what block size to use */
+                sub_mb_type = MB_TYPE_8x8|MB_TYPE_P0L0|MB_TYPE_P0L1|MB_TYPE_DIRECT2; /* B_SUB_4x4 */
+                *mb_type   |= MB_TYPE_8x8|MB_TYPE_L0L1;
+            }else if(!is_b8x8 && (mb_type_col[0] & MB_TYPE_16x16_OR_INTRA)){
+                sub_mb_type = MB_TYPE_16x16|MB_TYPE_P0L0|MB_TYPE_P0L1|MB_TYPE_DIRECT2; /* B_SUB_8x8 */
+                *mb_type   |= MB_TYPE_16x16|MB_TYPE_P0L0|MB_TYPE_P0L1|MB_TYPE_DIRECT2; /* B_16x16 */
+            }else{
+                sub_mb_type = MB_TYPE_16x16|MB_TYPE_P0L0|MB_TYPE_P0L1|MB_TYPE_DIRECT2; /* B_SUB_8x8 */
+                *mb_type   |= MB_TYPE_8x8|MB_TYPE_L0L1;
+            }
+        }
     }
-    if(!is_b8x8)
-        *mb_type |= MB_TYPE_DIRECT2;
-    if(MB_FIELD)
-        *mb_type |= MB_TYPE_INTERLACED;
 
-    tprintf(s->avctx, "mb_type = %08x, sub_mb_type = %08x, is_b8x8 = %d, mb_type_col = %08x\n", *mb_type, sub_mb_type, is_b8x8, mb_type_col);
+    l1mv0  = &h->ref_list[1][0].motion_val[0][h->mb2b_xy [mb_xy]];
+    l1mv1  = &h->ref_list[1][0].motion_val[1][h->mb2b_xy [mb_xy]];
+    l1ref0 = &h->ref_list[1][0].ref_index [0][h->mb2b8_xy[mb_xy]];
+    l1ref1 = &h->ref_list[1][0].ref_index [1][h->mb2b8_xy[mb_xy]];
+    if(!b8_stride){
+        if(s->mb_y&1){
+            l1ref0 += h->b8_stride;
+            l1ref1 += h->b8_stride;
+            l1mv0  +=  2*b4_stride;
+            l1mv1  +=  2*b4_stride;
+        }
+    }
 
     if(h->direct_spatial_mv_pred){
         int ref[2];
@@ -1078,13 +1047,9 @@
             int refa = h->ref_cache[list][scan8[0] - 1];
             int refb = h->ref_cache[list][scan8[0] - 8];
             int refc = h->ref_cache[list][scan8[0] - 8 + 4];
-            if(refc == -2)
+            if(refc == PART_NOT_AVAILABLE)
                 refc = h->ref_cache[list][scan8[0] - 8 - 1];
-            ref[list] = refa;
-            if(ref[list] < 0 || (refb < ref[list] && refb >= 0))
-                ref[list] = refb;
-            if(ref[list] < 0 || (refc < ref[list] && refc >= 0))
-                ref[list] = refc;
+            ref[list] = FFMIN3((unsigned)refa, (unsigned)refb, (unsigned)refc);
             if(ref[list] < 0)
                 ref[list] = -1;
         }
@@ -1103,19 +1068,49 @@
         }
 
         if(ref[1] < 0){
-            *mb_type &= ~MB_TYPE_P0L1;
-            sub_mb_type &= ~MB_TYPE_P0L1;
+            if(!is_b8x8)
+                *mb_type &= ~MB_TYPE_L1;
+            sub_mb_type &= ~MB_TYPE_L1;
         }else if(ref[0] < 0){
-            *mb_type &= ~MB_TYPE_P0L0;
-            sub_mb_type &= ~MB_TYPE_P0L0;
+            if(!is_b8x8)
+                *mb_type &= ~MB_TYPE_L0;
+            sub_mb_type &= ~MB_TYPE_L0;
         }
 
-        if(IS_16X16(*mb_type)){
+        if(IS_INTERLACED(*mb_type) != IS_INTERLACED(mb_type_col[0])){
+            for(i8=0; i8<4; i8++){
+                int x8 = i8&1;
+                int y8 = i8>>1;
+                int xy8 = x8+y8*b8_stride;
+                int xy4 = 3*x8+y8*b4_stride;
+                int a=0, b=0;
+
+                if(is_b8x8 && !IS_DIRECT(h->sub_mb_type[i8]))
+                    continue;
+                h->sub_mb_type[i8] = sub_mb_type;
+
+                fill_rectangle(&h->ref_cache[0][scan8[i8*4]], 2, 2, 8, (uint8_t)ref[0], 1);
+                fill_rectangle(&h->ref_cache[1][scan8[i8*4]], 2, 2, 8, (uint8_t)ref[1], 1);
+                if(!IS_INTRA(mb_type_col[y8])
+                   && (   (l1ref0[xy8] == 0 && FFABS(l1mv0[xy4][0]) <= 1 && FFABS(l1mv0[xy4][1]) <= 1)
+                       || (l1ref0[xy8]  < 0 && l1ref1[xy8] == 0 && FFABS(l1mv1[xy4][0]) <= 1 && FFABS(l1mv1[xy4][1]) <= 1))){
+                    if(ref[0] > 0)
+                        a= pack16to32(mv[0][0],mv[0][1]);
+                    if(ref[1] > 0)
+                        b= pack16to32(mv[1][0],mv[1][1]);
+                }else{
+                    a= pack16to32(mv[0][0],mv[0][1]);
+                    b= pack16to32(mv[1][0],mv[1][1]);
+                }
+                fill_rectangle(&h->mv_cache[0][scan8[i8*4]], 2, 2, 8, a, 4);
+                fill_rectangle(&h->mv_cache[1][scan8[i8*4]], 2, 2, 8, b, 4);
+            }
+        }else if(IS_16X16(*mb_type)){
             int a=0, b=0;
 
             fill_rectangle(&h->ref_cache[0][scan8[0]], 4, 4, 8, (uint8_t)ref[0], 1);
             fill_rectangle(&h->ref_cache[1][scan8[0]], 4, 4, 8, (uint8_t)ref[1], 1);
-            if(!IS_INTRA(mb_type_col)
+            if(!IS_INTRA(mb_type_col[0])
                && (   (l1ref0[0] == 0 && FFABS(l1mv0[0][0]) <= 1 && FFABS(l1mv0[0][1]) <= 1)
                    || (l1ref0[0]  < 0 && l1ref1[0] == 0 && FFABS(l1mv1[0][0]) <= 1 && FFABS(l1mv1[0][1]) <= 1
                        && (h->x264_build>33 || !h->x264_build)))){
@@ -1144,12 +1139,12 @@
                 fill_rectangle(&h->ref_cache[1][scan8[i8*4]], 2, 2, 8, (uint8_t)ref[1], 1);
 
                 /* col_zero_flag */
-                if(!IS_INTRA(mb_type_col) && (   l1ref0[x8 + y8*h->b8_stride] == 0
-                                              || (l1ref0[x8 + y8*h->b8_stride] < 0 && l1ref1[x8 + y8*h->b8_stride] == 0
+                if(!IS_INTRA(mb_type_col[0]) && (   l1ref0[x8 + y8*b8_stride] == 0
+                                              || (l1ref0[x8 + y8*b8_stride] < 0 && l1ref1[x8 + y8*b8_stride] == 0
                                                   && (h->x264_build>33 || !h->x264_build)))){
-                    const int16_t (*l1mv)[2]= l1ref0[x8 + y8*h->b8_stride] == 0 ? l1mv0 : l1mv1;
+                    const int16_t (*l1mv)[2]= l1ref0[x8 + y8*b8_stride] == 0 ? l1mv0 : l1mv1;
                     if(IS_SUB_8X8(sub_mb_type)){
-                        const int16_t *mv_col = l1mv[x8*3 + y8*3*h->b_stride];
+                        const int16_t *mv_col = l1mv[x8*3 + y8*3*b4_stride];
                         if(FFABS(mv_col[0]) <= 1 && FFABS(mv_col[1]) <= 1){
                             if(ref[0] == 0)
                                 fill_rectangle(&h->mv_cache[0][scan8[i8*4]], 2, 2, 8, 0, 4);
@@ -1158,7 +1153,7 @@
                         }
                     }else
                     for(i4=0; i4<4; i4++){
-                        const int16_t *mv_col = l1mv[x8*2 + (i4&1) + (y8*2 + (i4>>1))*h->b_stride];
+                        const int16_t *mv_col = l1mv[x8*2 + (i4&1) + (y8*2 + (i4>>1))*b4_stride];
                         if(FFABS(mv_col[0]) <= 1 && FFABS(mv_col[1]) <= 1){
                             if(ref[0] == 0)
                                 *(uint32_t*)h->mv_cache[0][scan8[i8*4+i4]] = 0;
@@ -1173,100 +1168,54 @@
         const int *map_col_to_list0[2] = {h->map_col_to_list0[0], h->map_col_to_list0[1]};
         const int *dist_scale_factor = h->dist_scale_factor;
 
-        if(FRAME_MBAFF){
-            if(IS_INTERLACED(*mb_type)){
-                map_col_to_list0[0] = h->map_col_to_list0_field[0];
-                map_col_to_list0[1] = h->map_col_to_list0_field[1];
-                dist_scale_factor = h->dist_scale_factor_field;
-            }
-            if(IS_INTERLACED(*mb_type) != IS_INTERLACED(mb_type_col)){
-                /* FIXME assumes direct_8x8_inference == 1 */
-                const int pair_xy = s->mb_x + (s->mb_y&~1)*s->mb_stride;
-                int mb_types_col[2];
-                int y_shift;
+        if(FRAME_MBAFF && IS_INTERLACED(*mb_type)){
+            map_col_to_list0[0] = h->map_col_to_list0_field[0];
+            map_col_to_list0[1] = h->map_col_to_list0_field[1];
+            dist_scale_factor = h->dist_scale_factor_field;
+        }
+        if(IS_INTERLACED(*mb_type) != IS_INTERLACED(mb_type_col[0])){
+            /* FIXME assumes direct_8x8_inference == 1 */
+            int y_shift  = 2*!IS_INTERLACED(*mb_type);
+            int ref_shift= FRAME_MBAFF ? y_shift : 1;
 
-                *mb_type = MB_TYPE_8x8|MB_TYPE_L0L1
-                         | (is_b8x8 ? 0 : MB_TYPE_DIRECT2)
-                         | (*mb_type & MB_TYPE_INTERLACED);
-                sub_mb_type = MB_TYPE_P0L0|MB_TYPE_P0L1|MB_TYPE_DIRECT2|MB_TYPE_16x16;
+            for(i8=0; i8<4; i8++){
+                const int x8 = i8&1;
+                const int y8 = i8>>1;
+                int ref0, scale;
+                const int16_t (*l1mv)[2]= l1mv0;
 
-                if(IS_INTERLACED(*mb_type)){
-                    /* frame to field scaling */
-                    mb_types_col[0] = h->ref_list[1][0].mb_type[pair_xy];
-                    mb_types_col[1] = h->ref_list[1][0].mb_type[pair_xy+s->mb_stride];
-                    if(s->mb_y&1){
-                        l1ref0 -= 2*h->b8_stride;
-                        l1ref1 -= 2*h->b8_stride;
-                        l1mv0 -= 4*h->b_stride;
-                        l1mv1 -= 4*h->b_stride;
-                    }
-                    y_shift = 0;
+                if(is_b8x8 && !IS_DIRECT(h->sub_mb_type[i8]))
+                    continue;
+                h->sub_mb_type[i8] = sub_mb_type;
 
-                    if(   (mb_types_col[0] & MB_TYPE_16x16_OR_INTRA)
-                       && (mb_types_col[1] & MB_TYPE_16x16_OR_INTRA)
-                       && !is_b8x8)
-                        *mb_type |= MB_TYPE_16x8;
-                    else
-                        *mb_type |= MB_TYPE_8x8;
-                }else{
-                    /* field to frame scaling */
-                    /* col_mb_y = (mb_y&~1) + (topAbsDiffPOC < bottomAbsDiffPOC ? 0 : 1)
-                     * but in MBAFF, top and bottom POC are equal */
-                    int dy = (s->mb_y&1) ? 1 : 2;
-                    mb_types_col[0] =
-                    mb_types_col[1] = h->ref_list[1][0].mb_type[pair_xy+s->mb_stride];
-                    l1ref0 += dy*h->b8_stride;
-                    l1ref1 += dy*h->b8_stride;
-                    l1mv0 += 2*dy*h->b_stride;
-                    l1mv1 += 2*dy*h->b_stride;
-                    y_shift = 2;
+                fill_rectangle(&h->ref_cache[1][scan8[i8*4]], 2, 2, 8, 0, 1);
+                if(IS_INTRA(mb_type_col[y8])){
+                    fill_rectangle(&h->ref_cache[0][scan8[i8*4]], 2, 2, 8, 0, 1);
+                    fill_rectangle(&h-> mv_cache[0][scan8[i8*4]], 2, 2, 8, 0, 4);
+                    fill_rectangle(&h-> mv_cache[1][scan8[i8*4]], 2, 2, 8, 0, 4);
+                    continue;
+                }
 
-                    if((mb_types_col[0] & (MB_TYPE_16x16_OR_INTRA|MB_TYPE_16x8))
-                       && !is_b8x8)
-                        *mb_type |= MB_TYPE_16x16;
-                    else
-                        *mb_type |= MB_TYPE_8x8;
+                ref0 = l1ref0[x8 + y8*b8_stride];
+                if(ref0 >= 0)
+                    ref0 = map_col_to_list0[0][ref0*2>>ref_shift];
+                else{
+                    ref0 = map_col_to_list0[1][l1ref1[x8 + y8*b8_stride]*2>>ref_shift];
+                    l1mv= l1mv1;
                 }
+                scale = dist_scale_factor[ref0];
+                fill_rectangle(&h->ref_cache[0][scan8[i8*4]], 2, 2, 8, ref0, 1);
 
-                for(i8=0; i8<4; i8++){
-                    const int x8 = i8&1;
-                    const int y8 = i8>>1;
-                    int ref0, scale;
-                    const int16_t (*l1mv)[2]= l1mv0;
-
-                    if(is_b8x8 && !IS_DIRECT(h->sub_mb_type[i8]))
-                        continue;
-                    h->sub_mb_type[i8] = sub_mb_type;
-
-                    fill_rectangle(&h->ref_cache[1][scan8[i8*4]], 2, 2, 8, 0, 1);
-                    if(IS_INTRA(mb_types_col[y8])){
-                        fill_rectangle(&h->ref_cache[0][scan8[i8*4]], 2, 2, 8, 0, 1);
-                        fill_rectangle(&h-> mv_cache[0][scan8[i8*4]], 2, 2, 8, 0, 4);
-                        fill_rectangle(&h-> mv_cache[1][scan8[i8*4]], 2, 2, 8, 0, 4);
-                        continue;
-                    }
-
-                    ref0 = l1ref0[x8 + (y8*2>>y_shift)*h->b8_stride];
-                    if(ref0 >= 0)
-                        ref0 = map_col_to_list0[0][ref0*2>>y_shift];
-                    else{
-                        ref0 = map_col_to_list0[1][l1ref1[x8 + (y8*2>>y_shift)*h->b8_stride]*2>>y_shift];
-                        l1mv= l1mv1;
-                    }
-                    scale = dist_scale_factor[ref0];
-                    fill_rectangle(&h->ref_cache[0][scan8[i8*4]], 2, 2, 8, ref0, 1);
-
-                    {
-                        const int16_t *mv_col = l1mv[x8*3 + (y8*6>>y_shift)*h->b_stride];
-                        int my_col = (mv_col[1]<<y_shift)/2;
-                        int mx = (scale * mv_col[0] + 128) >> 8;
-                        int my = (scale * my_col + 128) >> 8;
-                        fill_rectangle(&h->mv_cache[0][scan8[i8*4]], 2, 2, 8, pack16to32(mx,my), 4);
-                        fill_rectangle(&h->mv_cache[1][scan8[i8*4]], 2, 2, 8, pack16to32(mx-mv_col[0],my-my_col), 4);
-                    }
+                {
+                    const int16_t *mv_col = l1mv[x8*3 + y8*b4_stride];
+                    int my_col = (mv_col[1]<<y_shift)/2;
+                    int mx = (scale * mv_col[0] + 128) >> 8;
+                    int my = (scale * my_col + 128) >> 8;
+                    fill_rectangle(&h->mv_cache[0][scan8[i8*4]], 2, 2, 8, pack16to32(mx,my), 4);
+                    fill_rectangle(&h->mv_cache[1][scan8[i8*4]], 2, 2, 8, pack16to32(mx-mv_col[0],my-my_col), 4);
                 }
-                return;
             }
+            return;
         }
 
         /* one-to-one mv scaling */
@@ -1275,7 +1224,7 @@
             int ref, mv0, mv1;
 
             fill_rectangle(&h->ref_cache[1][scan8[0]], 4, 4, 8, 0, 1);
-            if(IS_INTRA(mb_type_col)){
+            if(IS_INTRA(mb_type_col[0])){
                 ref=mv0=mv1=0;
             }else{
                 const int ref0 = l1ref0[0] >= 0 ? map_col_to_list0[0][l1ref0[0]]
@@ -1303,32 +1252,32 @@
                     continue;
                 h->sub_mb_type[i8] = sub_mb_type;
                 fill_rectangle(&h->ref_cache[1][scan8[i8*4]], 2, 2, 8, 0, 1);
-                if(IS_INTRA(mb_type_col)){
+                if(IS_INTRA(mb_type_col[0])){
                     fill_rectangle(&h->ref_cache[0][scan8[i8*4]], 2, 2, 8, 0, 1);
                     fill_rectangle(&h-> mv_cache[0][scan8[i8*4]], 2, 2, 8, 0, 4);
                     fill_rectangle(&h-> mv_cache[1][scan8[i8*4]], 2, 2, 8, 0, 4);
                     continue;
                 }
 
-                ref0 = l1ref0[x8 + y8*h->b8_stride];
+                ref0 = l1ref0[x8 + y8*b8_stride];
                 if(ref0 >= 0)
                     ref0 = map_col_to_list0[0][ref0];
                 else{
-                    ref0 = map_col_to_list0[1][l1ref1[x8 + y8*h->b8_stride]];
+                    ref0 = map_col_to_list0[1][l1ref1[x8 + y8*b8_stride]];
                     l1mv= l1mv1;
                 }
                 scale = dist_scale_factor[ref0];
 
                 fill_rectangle(&h->ref_cache[0][scan8[i8*4]], 2, 2, 8, ref0, 1);
                 if(IS_SUB_8X8(sub_mb_type)){
-                    const int16_t *mv_col = l1mv[x8*3 + y8*3*h->b_stride];
+                    const int16_t *mv_col = l1mv[x8*3 + y8*3*b4_stride];
                     int mx = (scale * mv_col[0] + 128) >> 8;
                     int my = (scale * mv_col[1] + 128) >> 8;
                     fill_rectangle(&h->mv_cache[0][scan8[i8*4]], 2, 2, 8, pack16to32(mx,my), 4);
                     fill_rectangle(&h->mv_cache[1][scan8[i8*4]], 2, 2, 8, pack16to32(mx-mv_col[0],my-mv_col[1]), 4);
                 }else
                 for(i4=0; i4<4; i4++){
-                    const int16_t *mv_col = l1mv[x8*2 + (i4&1) + (y8*2 + (i4>>1))*h->b_stride];
+                    const int16_t *mv_col = l1mv[x8*2 + (i4&1) + (y8*2 + (i4>>1))*b4_stride];
                     int16_t *mv_l0 = h->mv_cache[0][scan8[i8*4+i4]];
                     mv_l0[0] = (scale * mv_col[0] + 128) >> 8;
                     mv_l0[1] = (scale * mv_col[1] + 128) >> 8;
@@ -1377,7 +1326,7 @@
         }
     }
 
-    if(h->slice_type == B_TYPE && h->pps.cabac){
+    if(h->slice_type_nos == FF_B_TYPE && h->pps.cabac){
         if(IS_8X8(mb_type)){
             uint8_t *direct_table = &h->direct_table[b8_xy];
             direct_table[1+0*h->b8_stride] = IS_DIRECT(h->sub_mb_type[1]) ? 1 : 0;
@@ -1394,7 +1343,7 @@
  * @param dst_length is the number of decoded bytes FIXME here or a decode rbsp tailing?
  * @returns decoded bytes, might be src+1 if no escapes
  */
-static uint8_t *decode_nal(H264Context *h, uint8_t *src, int *dst_length, int *consumed, int length){
+static const uint8_t *decode_nal(H264Context *h, const uint8_t *src, int *dst_length, int *consumed, int length){
     int i, si, di;
     uint8_t *dst;
     int bufidx;
@@ -1461,7 +1410,7 @@
  * identifies the exact end of the bitstream
  * @return the length of the trailing, or 0 if damaged
  */
-static int decode_rbsp_trailing(H264Context *h, uint8_t *src){
+static int decode_rbsp_trailing(H264Context *h, const uint8_t *src){
     int v= *src;
     int r;
 
@@ -1475,7 +1424,7 @@
 }
 
 /**
- * idct tranforms the 16 dc values and dequantize them.
+ * IDCT transforms the 16 dc values and dequantizes them.
  * @param qp quantization parameter
  */
 static void h264_luma_dc_dequant_idct_c(DCTELEM *block, int qp, int qmul){
@@ -1507,7 +1456,7 @@
         const int z2= temp[4*1+i] - temp[4*3+i];
         const int z3= temp[4*1+i] + temp[4*3+i];
 
-        block[stride*0 +offset]= ((((z0 + z3)*qmul + 128 ) >> 8)); //FIXME think about merging this into decode_resdual
+        block[stride*0 +offset]= ((((z0 + z3)*qmul + 128 ) >> 8)); //FIXME think about merging this into decode_residual
         block[stride*2 +offset]= ((((z1 + z2)*qmul + 128 ) >> 8));
         block[stride*8 +offset]= ((((z1 - z2)*qmul + 128 ) >> 8));
         block[stride*10+offset]= ((((z0 - z3)*qmul + 128 ) >> 8));
@@ -1516,7 +1465,7 @@
 
 #if 0
 /**
- * dct tranforms the 16 dc values.
+ * DCT transforms the 16 dc values.
  * @param qp quantization parameter ??? FIXME
  */
 static void h264_luma_dc_dct_c(DCTELEM *block/*, int qp*/){
@@ -1605,7 +1554,7 @@
  * gets the chroma qp.
  */
 static inline int get_chroma_qp(H264Context *h, int t, int qscale){
-    return h->pps.chroma_qp_table[t][qscale & 0xff];
+    return h->pps.chroma_qp_table[t][qscale];
 }
 
 //FIXME need to check that this does not overflow signed 32 bit for low qp, i am not sure, it's very close
@@ -1705,7 +1654,7 @@
     const int pic_width  = 16*s->mb_width;
     const int pic_height = 16*s->mb_height >> MB_FIELD;
 
-    if(!pic->data[0]) //FIXME this is unacceptable, some senseable error concealment must be done for missing reference frames
+    if(!pic->data[0]) //FIXME this is unacceptable, some sensible error concealment must be done for missing reference frames
         return;
 
     if(mx&7) extra_width -= 3;
@@ -1888,7 +1837,7 @@
                       qpel_mc_func (*qpix_avg)[16], h264_chroma_mc_func (*chroma_avg),
                       h264_weight_func *weight_op, h264_biweight_func *weight_avg){
     MpegEncContext * const s = &h->s;
-    const int mb_xy= s->mb_x + s->mb_y*s->mb_stride;
+    const int mb_xy= h->mb_xy;
     const int mb_type= s->current_picture.mb_type[mb_xy];
 
     assert(IS_INTER(mb_type));
@@ -1970,42 +1919,72 @@
     prefetch_motion(h, 1);
 }
 
-static void decode_init_vlc(void){
+static av_cold void decode_init_vlc(void){
     static int done = 0;
 
     if (!done) {
         int i;
+        int offset;
         done = 1;
 
+        chroma_dc_coeff_token_vlc.table = chroma_dc_coeff_token_vlc_table;
+        chroma_dc_coeff_token_vlc.table_allocated = chroma_dc_coeff_token_vlc_table_size;
         init_vlc(&chroma_dc_coeff_token_vlc, CHROMA_DC_COEFF_TOKEN_VLC_BITS, 4*5,
                  &chroma_dc_coeff_token_len [0], 1, 1,
-                 &chroma_dc_coeff_token_bits[0], 1, 1, 1);
+                 &chroma_dc_coeff_token_bits[0], 1, 1,
+                 INIT_VLC_USE_NEW_STATIC);
 
+        offset = 0;
         for(i=0; i<4; i++){
+            coeff_token_vlc[i].table = coeff_token_vlc_tables+offset;
+            coeff_token_vlc[i].table_allocated = coeff_token_vlc_tables_size[i];
             init_vlc(&coeff_token_vlc[i], COEFF_TOKEN_VLC_BITS, 4*17,
                      &coeff_token_len [i][0], 1, 1,
-                     &coeff_token_bits[i][0], 1, 1, 1);
+                     &coeff_token_bits[i][0], 1, 1,
+                     INIT_VLC_USE_NEW_STATIC);
+            offset += coeff_token_vlc_tables_size[i];
         }
+        /*
+         * This is a one time safety check to make sure that
+         * the packed static coeff_token_vlc table sizes
+         * were initialized correctly.
+         */
+        assert(offset == sizeof(coeff_token_vlc_tables)/(sizeof(VLC_TYPE)*2));
 
         for(i=0; i<3; i++){
-            init_vlc(&chroma_dc_total_zeros_vlc[i], CHROMA_DC_TOTAL_ZEROS_VLC_BITS, 4,
+            chroma_dc_total_zeros_vlc[i].table = chroma_dc_total_zeros_vlc_tables[i];
+            chroma_dc_total_zeros_vlc[i].table_allocated = chroma_dc_total_zeros_vlc_tables_size;
+            init_vlc(&chroma_dc_total_zeros_vlc[i],
+                     CHROMA_DC_TOTAL_ZEROS_VLC_BITS, 4,
                      &chroma_dc_total_zeros_len [i][0], 1, 1,
-                     &chroma_dc_total_zeros_bits[i][0], 1, 1, 1);
+                     &chroma_dc_total_zeros_bits[i][0], 1, 1,
+                     INIT_VLC_USE_NEW_STATIC);
         }
         for(i=0; i<15; i++){
-            init_vlc(&total_zeros_vlc[i], TOTAL_ZEROS_VLC_BITS, 16,
+            total_zeros_vlc[i].table = total_zeros_vlc_tables[i];
+            total_zeros_vlc[i].table_allocated = total_zeros_vlc_tables_size;
+            init_vlc(&total_zeros_vlc[i],
+                     TOTAL_ZEROS_VLC_BITS, 16,
                      &total_zeros_len [i][0], 1, 1,
-                     &total_zeros_bits[i][0], 1, 1, 1);
+                     &total_zeros_bits[i][0], 1, 1,
+                     INIT_VLC_USE_NEW_STATIC);
         }
 
         for(i=0; i<6; i++){
-            init_vlc(&run_vlc[i], RUN_VLC_BITS, 7,
+            run_vlc[i].table = run_vlc_tables[i];
+            run_vlc[i].table_allocated = run_vlc_tables_size;
+            init_vlc(&run_vlc[i],
+                     RUN_VLC_BITS, 7,
                      &run_len [i][0], 1, 1,
-                     &run_bits[i][0], 1, 1, 1);
+                     &run_bits[i][0], 1, 1,
+                     INIT_VLC_USE_NEW_STATIC);
         }
+        run7_vlc.table = run7_vlc_table,
+        run7_vlc.table_allocated = run7_vlc_table_size;
         init_vlc(&run7_vlc, RUN7_VLC_BITS, 16,
                  &run_len [6][0], 1, 1,
-                 &run_bits[6][0], 1, 1, 1);
+                 &run_bits[6][0], 1, 1,
+                 INIT_VLC_USE_NEW_STATIC);
     }
 }
 
@@ -2037,7 +2016,6 @@
         av_freep(&hx->top_borders[1]);
         av_freep(&hx->top_borders[0]);
         av_freep(&hx->s.obmc_scratchpad);
-        av_freep(&hx->s.allocated_edge_emu_buffer);
     }
 }
 
@@ -2121,12 +2099,10 @@
     CHECKED_ALLOCZ(h->slice_table_base  , (big_mb_num+s->mb_stride) * sizeof(uint8_t))
     CHECKED_ALLOCZ(h->cbp_table, big_mb_num * sizeof(uint16_t))
 
-    if( h->pps.cabac ) {
-        CHECKED_ALLOCZ(h->chroma_pred_mode_table, big_mb_num * sizeof(uint8_t))
-        CHECKED_ALLOCZ(h->mvd_table[0], 32*big_mb_num * sizeof(uint16_t));
-        CHECKED_ALLOCZ(h->mvd_table[1], 32*big_mb_num * sizeof(uint16_t));
-        CHECKED_ALLOCZ(h->direct_table, 32*big_mb_num * sizeof(uint8_t));
-    }
+    CHECKED_ALLOCZ(h->chroma_pred_mode_table, big_mb_num * sizeof(uint8_t))
+    CHECKED_ALLOCZ(h->mvd_table[0], 32*big_mb_num * sizeof(uint16_t));
+    CHECKED_ALLOCZ(h->mvd_table[1], 32*big_mb_num * sizeof(uint16_t));
+    CHECKED_ALLOCZ(h->direct_table, 32*big_mb_num * sizeof(uint8_t));
 
     memset(h->slice_table_base, -1, (big_mb_num+s->mb_stride)  * sizeof(uint8_t));
     h->slice_table= h->slice_table_base + s->mb_stride*2 + 1;
@@ -2179,21 +2155,15 @@
  * Allocate buffers which are not shared amongst multiple threads.
  */
 static int context_init(H264Context *h){
-    MpegEncContext * const s = &h->s;
-
     CHECKED_ALLOCZ(h->top_borders[0], h->s.mb_width * (16+8+8) * sizeof(uint8_t))
     CHECKED_ALLOCZ(h->top_borders[1], h->s.mb_width * (16+8+8) * sizeof(uint8_t))
 
-    // edge emu needs blocksize + filter length - 1 (=17x17 for halfpel / 21x21 for h264)
-    CHECKED_ALLOCZ(s->allocated_edge_emu_buffer,
-                   (s->width+64)*2*21*2); //(width + edge + align)*interlaced*MBsize*tolerance
-    s->edge_emu_buffer= s->allocated_edge_emu_buffer + (s->width+64)*2*21;
     return 0;
 fail:
     return -1; // free_tables will clean up for us
 }
 
-static void common_init(H264Context *h){
+static av_cold void common_init(H264Context *h){
     MpegEncContext * const s = &h->s;
 
     s->width = s->avctx->width;
@@ -2210,7 +2180,7 @@
     memset(h->pps.scaling_matrix8, 16, 2*64*sizeof(uint8_t));
 }
 
-static int decode_init(AVCodecContext *avctx){
+static av_cold int decode_init(AVCodecContext *avctx){
     H264Context *h= avctx->priv_data;
     MpegEncContext * const s = &h->s;
 
@@ -2226,8 +2196,12 @@
 //    s->decode_mb= ff_h263_decode_mb;
     s->quarter_sample = 1;
     s->low_delay= 1;
-    avctx->pix_fmt= PIX_FMT_YUV420P;
 
+    if(avctx->codec_id == CODEC_ID_SVQ3)
+        avctx->pix_fmt= PIX_FMT_YUVJ420P;
+    else
+        avctx->pix_fmt= PIX_FMT_YUV420P;
+
     decode_init_vlc();
 
     if(avctx->extradata_size > 0 && avctx->extradata &&
@@ -2239,6 +2213,7 @@
     }
 
     h->thread_context[0] = h;
+    h->outputed_poc = INT_MIN;
     return 0;
 }
 
@@ -2252,7 +2227,7 @@
     /*
      * MPV_frame_start uses pict_type to derive key_frame.
      * This is incorrect for H.264; IDR markings must be used.
-     * Zero here; IDR markings per slice in frame or fields are OR'd in later.
+     * Zero here; IDR markings per slice in frame or fields are ORed in later.
      * See decode_nal_units().
      */
     s->current_picture_ptr->key_frame= 0;
@@ -2281,36 +2256,83 @@
         memset(h->slice_table, -1, (s->mb_height*s->mb_stride-1) * sizeof(uint8_t));
 
 //    s->decode= (s->flags&CODEC_FLAG_PSNR) || !s->encoding || s->current_picture.reference /*|| h->contains_intra*/ || 1;
+
+    // We mark the current picture as non-reference after allocating it, so
+    // that if we break out due to an error it can be released automatically
+    // in the next MPV_frame_start().
+    // SVQ3 as well as most other codecs have only last/next/current and thus
+    // get released even with set reference, besides SVQ3 and others do not
+    // mark frames as reference later "naturally".
+    if(s->codec_id != CODEC_ID_SVQ3)
+        s->current_picture_ptr->reference= 0;
+
+    s->current_picture_ptr->field_poc[0]=
+    s->current_picture_ptr->field_poc[1]= INT_MAX;
+    assert(s->current_picture_ptr->long_ref==0);
+
     return 0;
 }
 
 static inline void backup_mb_border(H264Context *h, uint8_t *src_y, uint8_t *src_cb, uint8_t *src_cr, int linesize, int uvlinesize, int simple){
     MpegEncContext * const s = &h->s;
     int i;
+    int step    = 1;
+    int offset  = 1;
+    int uvoffset= 1;
+    int top_idx = 1;
+    int skiplast= 0;
 
     src_y  -=   linesize;
     src_cb -= uvlinesize;
     src_cr -= uvlinesize;
 
+    if(!simple && FRAME_MBAFF){
+        if(s->mb_y&1){
+            offset  = MB_MBAFF ? 1 : 17;
+            uvoffset= MB_MBAFF ? 1 : 9;
+            if(!MB_MBAFF){
+                *(uint64_t*)(h->top_borders[0][s->mb_x]+ 0)= *(uint64_t*)(src_y +  15*linesize);
+                *(uint64_t*)(h->top_borders[0][s->mb_x]+ 8)= *(uint64_t*)(src_y +8+15*linesize);
+                if(simple || !ENABLE_GRAY || !(s->flags&CODEC_FLAG_GRAY)){
+                    *(uint64_t*)(h->top_borders[0][s->mb_x]+16)= *(uint64_t*)(src_cb+7*uvlinesize);
+                    *(uint64_t*)(h->top_borders[0][s->mb_x]+24)= *(uint64_t*)(src_cr+7*uvlinesize);
+                }
+            }
+        }else{
+            if(!MB_MBAFF){
+                h->left_border[0]= h->top_borders[0][s->mb_x][15];
+                if(simple || !ENABLE_GRAY || !(s->flags&CODEC_FLAG_GRAY)){
+                    h->left_border[34   ]= h->top_borders[0][s->mb_x][16+7  ];
+                    h->left_border[34+18]= h->top_borders[0][s->mb_x][16+8+7];
+                }
+                skiplast= 1;
+            }
+            offset  =
+            uvoffset=
+            top_idx = MB_MBAFF ? 0 : 1;
+        }
+        step= MB_MBAFF ? 2 : 1;
+    }
+
     // There are two lines saved, the line above the the top macroblock of a pair,
     // and the line above the bottom macroblock
-    h->left_border[0]= h->top_borders[0][s->mb_x][15];
-    for(i=1; i<17; i++){
-        h->left_border[i]= src_y[15+i*  linesize];
+    h->left_border[offset]= h->top_borders[top_idx][s->mb_x][15];
+    for(i=1; i<17 - skiplast; i++){
+        h->left_border[offset+i*step]= src_y[15+i*  linesize];
     }
 
-    *(uint64_t*)(h->top_borders[0][s->mb_x]+0)= *(uint64_t*)(src_y +  16*linesize);
-    *(uint64_t*)(h->top_borders[0][s->mb_x]+8)= *(uint64_t*)(src_y +8+16*linesize);
+    *(uint64_t*)(h->top_borders[top_idx][s->mb_x]+0)= *(uint64_t*)(src_y +  16*linesize);
+    *(uint64_t*)(h->top_borders[top_idx][s->mb_x]+8)= *(uint64_t*)(src_y +8+16*linesize);
 
     if(simple || !ENABLE_GRAY || !(s->flags&CODEC_FLAG_GRAY)){
-        h->left_border[17  ]= h->top_borders[0][s->mb_x][16+7];
-        h->left_border[17+9]= h->top_borders[0][s->mb_x][24+7];
-        for(i=1; i<9; i++){
-            h->left_border[i+17  ]= src_cb[7+i*uvlinesize];
-            h->left_border[i+17+9]= src_cr[7+i*uvlinesize];
+        h->left_border[uvoffset+34   ]= h->top_borders[top_idx][s->mb_x][16+7];
+        h->left_border[uvoffset+34+18]= h->top_borders[top_idx][s->mb_x][24+7];
+        for(i=1; i<9 - skiplast; i++){
+            h->left_border[uvoffset+34   +i*step]= src_cb[7+i*uvlinesize];
+            h->left_border[uvoffset+34+18+i*step]= src_cr[7+i*uvlinesize];
         }
-        *(uint64_t*)(h->top_borders[0][s->mb_x]+16)= *(uint64_t*)(src_cb+8*uvlinesize);
-        *(uint64_t*)(h->top_borders[0][s->mb_x]+24)= *(uint64_t*)(src_cr+8*uvlinesize);
+        *(uint64_t*)(h->top_borders[top_idx][s->mb_x]+16)= *(uint64_t*)(src_cb+8*uvlinesize);
+        *(uint64_t*)(h->top_borders[top_idx][s->mb_x]+24)= *(uint64_t*)(src_cr+8*uvlinesize);
     }
 }
 
@@ -2321,9 +2343,25 @@
     int deblock_left;
     int deblock_top;
     int mb_xy;
+    int step    = 1;
+    int offset  = 1;
+    int uvoffset= 1;
+    int top_idx = 1;
 
+    if(!simple && FRAME_MBAFF){
+        if(s->mb_y&1){
+            offset  = MB_MBAFF ? 1 : 17;
+            uvoffset= MB_MBAFF ? 1 : 9;
+        }else{
+            offset  =
+            uvoffset=
+            top_idx = MB_MBAFF ? 0 : 1;
+        }
+        step= MB_MBAFF ? 2 : 1;
+    }
+
     if(h->deblocking_filter == 2) {
-        mb_xy = s->mb_x + s->mb_y*s->mb_stride;
+        mb_xy = h->mb_xy;
         deblock_left = h->slice_table[mb_xy] == h->slice_table[mb_xy - 1];
         deblock_top  = h->slice_table[mb_xy] == h->slice_table[h->top_mb_xy];
     } else {
@@ -2342,133 +2380,46 @@
 b= t;
 
     if(deblock_left){
-        for(i = !deblock_top; i<17; i++){
-            XCHG(h->left_border[i     ], src_y [i*  linesize], temp8, xchg);
+        for(i = !deblock_top; i<16; i++){
+            XCHG(h->left_border[offset+i*step], src_y [i*  linesize], temp8, xchg);
         }
+        XCHG(h->left_border[offset+i*step], src_y [i*  linesize], temp8, 1);
     }
 
     if(deblock_top){
-        XCHG(*(uint64_t*)(h->top_borders[0][s->mb_x]+0), *(uint64_t*)(src_y +1), temp64, xchg);
-        XCHG(*(uint64_t*)(h->top_borders[0][s->mb_x]+8), *(uint64_t*)(src_y +9), temp64, 1);
+        XCHG(*(uint64_t*)(h->top_borders[top_idx][s->mb_x]+0), *(uint64_t*)(src_y +1), temp64, xchg);
+        XCHG(*(uint64_t*)(h->top_borders[top_idx][s->mb_x]+8), *(uint64_t*)(src_y +9), temp64, 1);
         if(s->mb_x+1 < s->mb_width){
-            XCHG(*(uint64_t*)(h->top_borders[0][s->mb_x+1]), *(uint64_t*)(src_y +17), temp64, 1);
+            XCHG(*(uint64_t*)(h->top_borders[top_idx][s->mb_x+1]), *(uint64_t*)(src_y +17), temp64, 1);
         }
     }
 
     if(simple || !ENABLE_GRAY || !(s->flags&CODEC_FLAG_GRAY)){
         if(deblock_left){
-            for(i = !deblock_top; i<9; i++){
-                XCHG(h->left_border[i+17  ], src_cb[i*uvlinesize], temp8, xchg);
-                XCHG(h->left_border[i+17+9], src_cr[i*uvlinesize], temp8, xchg);
+            for(i = !deblock_top; i<8; i++){
+                XCHG(h->left_border[uvoffset+34   +i*step], src_cb[i*uvlinesize], temp8, xchg);
+                XCHG(h->left_border[uvoffset+34+18+i*step], src_cr[i*uvlinesize], temp8, xchg);
             }
+            XCHG(h->left_border[uvoffset+34   +i*step], src_cb[i*uvlinesize], temp8, 1);
+            XCHG(h->left_border[uvoffset+34+18+i*step], src_cr[i*uvlinesize], temp8, 1);
         }
         if(deblock_top){
-            XCHG(*(uint64_t*)(h->top_borders[0][s->mb_x]+16), *(uint64_t*)(src_cb+1), temp64, 1);
-            XCHG(*(uint64_t*)(h->top_borders[0][s->mb_x]+24), *(uint64_t*)(src_cr+1), temp64, 1);
+            XCHG(*(uint64_t*)(h->top_borders[top_idx][s->mb_x]+16), *(uint64_t*)(src_cb+1), temp64, 1);
+            XCHG(*(uint64_t*)(h->top_borders[top_idx][s->mb_x]+24), *(uint64_t*)(src_cr+1), temp64, 1);
         }
     }
 }
 
-static inline void backup_pair_border(H264Context *h, uint8_t *src_y, uint8_t *src_cb, uint8_t *src_cr, int linesize, int uvlinesize){
-    MpegEncContext * const s = &h->s;
-    int i;
-
-    src_y  -= 2 *   linesize;
-    src_cb -= 2 * uvlinesize;
-    src_cr -= 2 * uvlinesize;
-
-    // There are two lines saved, the line above the the top macroblock of a pair,
-    // and the line above the bottom macroblock
-    h->left_border[0]= h->top_borders[0][s->mb_x][15];
-    h->left_border[1]= h->top_borders[1][s->mb_x][15];
-    for(i=2; i<34; i++){
-        h->left_border[i]= src_y[15+i*  linesize];
-    }
-
-    *(uint64_t*)(h->top_borders[0][s->mb_x]+0)= *(uint64_t*)(src_y +  32*linesize);
-    *(uint64_t*)(h->top_borders[0][s->mb_x]+8)= *(uint64_t*)(src_y +8+32*linesize);
-    *(uint64_t*)(h->top_borders[1][s->mb_x]+0)= *(uint64_t*)(src_y +  33*linesize);
-    *(uint64_t*)(h->top_borders[1][s->mb_x]+8)= *(uint64_t*)(src_y +8+33*linesize);
-
-    if(!ENABLE_GRAY || !(s->flags&CODEC_FLAG_GRAY)){
-        h->left_border[34     ]= h->top_borders[0][s->mb_x][16+7];
-        h->left_border[34+   1]= h->top_borders[1][s->mb_x][16+7];
-        h->left_border[34+18  ]= h->top_borders[0][s->mb_x][24+7];
-        h->left_border[34+18+1]= h->top_borders[1][s->mb_x][24+7];
-        for(i=2; i<18; i++){
-            h->left_border[i+34   ]= src_cb[7+i*uvlinesize];
-            h->left_border[i+34+18]= src_cr[7+i*uvlinesize];
-        }
-        *(uint64_t*)(h->top_borders[0][s->mb_x]+16)= *(uint64_t*)(src_cb+16*uvlinesize);
-        *(uint64_t*)(h->top_borders[0][s->mb_x]+24)= *(uint64_t*)(src_cr+16*uvlinesize);
-        *(uint64_t*)(h->top_borders[1][s->mb_x]+16)= *(uint64_t*)(src_cb+17*uvlinesize);
-        *(uint64_t*)(h->top_borders[1][s->mb_x]+24)= *(uint64_t*)(src_cr+17*uvlinesize);
-    }
-}
-
-static inline void xchg_pair_border(H264Context *h, uint8_t *src_y, uint8_t *src_cb, uint8_t *src_cr, int linesize, int uvlinesize, int xchg){
-    MpegEncContext * const s = &h->s;
-    int temp8, i;
-    uint64_t temp64;
-    int deblock_left = (s->mb_x > 0);
-    int deblock_top  = (s->mb_y > 1);
-
-    tprintf(s->avctx, "xchg_pair_border: src_y:%p src_cb:%p src_cr:%p ls:%d uvls:%d\n", src_y, src_cb, src_cr, linesize, uvlinesize);
-
-    src_y  -= 2 *   linesize + 1;
-    src_cb -= 2 * uvlinesize + 1;
-    src_cr -= 2 * uvlinesize + 1;
-
-#define XCHG(a,b,t,xchg)\
-t= a;\
-if(xchg)\
-    a= b;\
-b= t;
-
-    if(deblock_left){
-        for(i = (!deblock_top)<<1; i<34; i++){
-            XCHG(h->left_border[i     ], src_y [i*  linesize], temp8, xchg);
-        }
-    }
-
-    if(deblock_top){
-        XCHG(*(uint64_t*)(h->top_borders[0][s->mb_x]+0), *(uint64_t*)(src_y +1), temp64, xchg);
-        XCHG(*(uint64_t*)(h->top_borders[0][s->mb_x]+8), *(uint64_t*)(src_y +9), temp64, 1);
-        XCHG(*(uint64_t*)(h->top_borders[1][s->mb_x]+0), *(uint64_t*)(src_y +1 +linesize), temp64, xchg);
-        XCHG(*(uint64_t*)(h->top_borders[1][s->mb_x]+8), *(uint64_t*)(src_y +9 +linesize), temp64, 1);
-        if(s->mb_x+1 < s->mb_width){
-            XCHG(*(uint64_t*)(h->top_borders[0][s->mb_x+1]), *(uint64_t*)(src_y +17), temp64, 1);
-            XCHG(*(uint64_t*)(h->top_borders[1][s->mb_x+1]), *(uint64_t*)(src_y +17 +linesize), temp64, 1);
-        }
-    }
-
-    if(!ENABLE_GRAY || !(s->flags&CODEC_FLAG_GRAY)){
-        if(deblock_left){
-            for(i = (!deblock_top) << 1; i<18; i++){
-                XCHG(h->left_border[i+34   ], src_cb[i*uvlinesize], temp8, xchg);
-                XCHG(h->left_border[i+34+18], src_cr[i*uvlinesize], temp8, xchg);
-            }
-        }
-        if(deblock_top){
-            XCHG(*(uint64_t*)(h->top_borders[0][s->mb_x]+16), *(uint64_t*)(src_cb+1), temp64, 1);
-            XCHG(*(uint64_t*)(h->top_borders[0][s->mb_x]+24), *(uint64_t*)(src_cr+1), temp64, 1);
-            XCHG(*(uint64_t*)(h->top_borders[1][s->mb_x]+16), *(uint64_t*)(src_cb+1 +uvlinesize), temp64, 1);
-            XCHG(*(uint64_t*)(h->top_borders[1][s->mb_x]+24), *(uint64_t*)(src_cr+1 +uvlinesize), temp64, 1);
-        }
-    }
-}
-
 static av_always_inline void hl_decode_mb_internal(H264Context *h, int simple){
     MpegEncContext * const s = &h->s;
     const int mb_x= s->mb_x;
     const int mb_y= s->mb_y;
-    const int mb_xy= mb_x + mb_y*s->mb_stride;
+    const int mb_xy= h->mb_xy;
     const int mb_type= s->current_picture.mb_type[mb_xy];
     uint8_t  *dest_y, *dest_cb, *dest_cr;
     int linesize, uvlinesize /*dct_offset*/;
     int i;
     int *block_offset = &h->block_offset[0];
-    const unsigned int bottom = mb_y & 1;
     const int transform_bypass = (s->qscale == 0 && h->sps.transform_bypass), is_h264 = (simple || s->codec_id == CODEC_ID_H264);
     void (*idct_add)(uint8_t *dst, DCTELEM *block, int stride);
     void (*idct_dc_add)(uint8_t *dst, DCTELEM *block, int stride);
@@ -2484,7 +2435,7 @@
         linesize   = h->mb_linesize   = s->linesize * 2;
         uvlinesize = h->mb_uvlinesize = s->uvlinesize * 2;
         block_offset = &h->block_offset[24];
-        if(mb_y&1){ //FIXME move out of this func?
+        if(mb_y&1){ //FIXME move out of this function?
             dest_y -= s->linesize*15;
             dest_cb-= s->uvlinesize*7;
             dest_cr-= s->uvlinesize*7;
@@ -2496,13 +2447,13 @@
                     continue;
                 if(IS_16X16(mb_type)){
                     int8_t *ref = &h->ref_cache[list][scan8[0]];
-                    fill_rectangle(ref, 4, 4, 8, 16+*ref^(s->mb_y&1), 1);
+                    fill_rectangle(ref, 4, 4, 8, (16+*ref)^(s->mb_y&1), 1);
                 }else{
                     for(i=0; i<16; i+=4){
                         //FIXME can refs be smaller than 8x8 when !direct_8x8_inference ?
                         int ref = h->ref_cache[list][scan8[i]];
                         if(ref >= 0)
-                            fill_rectangle(&h->ref_cache[list][scan8[i]], 2, 2, 8, 16+ref^(s->mb_y&1), 1);
+                            fill_rectangle(&h->ref_cache[list][scan8[i]], 2, 2, 8, (16+ref)^(s->mb_y&1), 1);
                     }
                 }
             }
@@ -2524,44 +2475,17 @@
         idct_add = s->dsp.h264_idct_add;
     }
 
-    if(!simple && FRAME_MBAFF && h->deblocking_filter && IS_INTRA(mb_type)
-       && (!bottom || !IS_INTRA(s->current_picture.mb_type[mb_xy-s->mb_stride]))){
-        int mbt_y = mb_y&~1;
-        uint8_t *top_y  = s->current_picture.data[0] + (mbt_y * 16* s->linesize  ) + mb_x * 16;
-        uint8_t *top_cb = s->current_picture.data[1] + (mbt_y * 8 * s->uvlinesize) + mb_x * 8;
-        uint8_t *top_cr = s->current_picture.data[2] + (mbt_y * 8 * s->uvlinesize) + mb_x * 8;
-        xchg_pair_border(h, top_y, top_cb, top_cr, s->linesize, s->uvlinesize, 1);
-    }
-
     if (!simple && IS_INTRA_PCM(mb_type)) {
-        unsigned int x, y;
-
-        // The pixels are stored in h->mb array in the same order as levels,
-        // copy them in output in the correct order.
-        for(i=0; i<16; i++) {
-            for (y=0; y<4; y++) {
-                for (x=0; x<4; x++) {
-                    *(dest_y + block_offset[i] + y*linesize + x) = h->mb[i*16+y*4+x];
-                }
-            }
+        for (i=0; i<16; i++) {
+            memcpy(dest_y + i*  linesize, h->mb       + i*8, 16);
         }
-        for(i=16; i<16+4; i++) {
-            for (y=0; y<4; y++) {
-                for (x=0; x<4; x++) {
-                    *(dest_cb + block_offset[i] + y*uvlinesize + x) = h->mb[i*16+y*4+x];
-                }
-            }
+        for (i=0; i<8; i++) {
+            memcpy(dest_cb+ i*uvlinesize, h->mb + 128 + i*4,  8);
+            memcpy(dest_cr+ i*uvlinesize, h->mb + 160 + i*4,  8);
         }
-        for(i=20; i<20+4; i++) {
-            for (y=0; y<4; y++) {
-                for (x=0; x<4; x++) {
-                    *(dest_cr + block_offset[i] + y*uvlinesize + x) = h->mb[i*16+y*4+x];
-                }
-            }
-        }
     } else {
         if(IS_INTRA(mb_type)){
-            if(h->deblocking_filter && (simple || !FRAME_MBAFF))
+            if(h->deblocking_filter)
                 xchg_mb_border(h, dest_y, dest_cb, dest_cr, linesize, uvlinesize, 1, simple);
 
             if(simple || !ENABLE_GRAY || !(s->flags&CODEC_FLAG_GRAY)){
@@ -2624,7 +2548,7 @@
                 }else
                     svq3_luma_dc_dequant_idct_c(h->mb, s->qscale);
             }
-            if(h->deblocking_filter && (simple || !FRAME_MBAFF))
+            if(h->deblocking_filter)
                 xchg_mb_border(h, dest_y, dest_cb, dest_cr, linesize, uvlinesize, 0, simple);
         }else if(is_h264){
             hl_motion(h, dest_y, dest_cb, dest_cr,
@@ -2693,42 +2617,13 @@
         }
     }
     if(h->deblocking_filter) {
+        backup_mb_border(h, dest_y, dest_cb, dest_cr, linesize, uvlinesize, simple);
+        fill_caches(h, mb_type, 1); //FIXME don't fill stuff which isn't used by filter_mb
+        h->chroma_qp[0] = get_chroma_qp(h, 0, s->current_picture.qscale_table[mb_xy]);
+        h->chroma_qp[1] = get_chroma_qp(h, 1, s->current_picture.qscale_table[mb_xy]);
         if (!simple && FRAME_MBAFF) {
-            //FIXME try deblocking one mb at a time?
-            // the reduction in load/storing mvs and such might outweigh the extra backup/xchg_border
-            const int mb_y = s->mb_y - 1;
-            uint8_t  *pair_dest_y, *pair_dest_cb, *pair_dest_cr;
-            const int mb_xy= mb_x + mb_y*s->mb_stride;
-            const int mb_type_top   = s->current_picture.mb_type[mb_xy];
-            const int mb_type_bottom= s->current_picture.mb_type[mb_xy+s->mb_stride];
-            if (!bottom) return;
-            pair_dest_y  = s->current_picture.data[0] + (mb_y * 16* s->linesize  ) + mb_x * 16;
-            pair_dest_cb = s->current_picture.data[1] + (mb_y * 8 * s->uvlinesize) + mb_x * 8;
-            pair_dest_cr = s->current_picture.data[2] + (mb_y * 8 * s->uvlinesize) + mb_x * 8;
-
-            if(IS_INTRA(mb_type_top | mb_type_bottom))
-                xchg_pair_border(h, pair_dest_y, pair_dest_cb, pair_dest_cr, s->linesize, s->uvlinesize, 0);
-
-            backup_pair_border(h, pair_dest_y, pair_dest_cb, pair_dest_cr, s->linesize, s->uvlinesize);
-            // deblock a pair
-            // top
-            s->mb_y--;
-            tprintf(h->s.avctx, "call mbaff filter_mb mb_x:%d mb_y:%d pair_dest_y = %p, dest_y = %p\n", mb_x, mb_y, pair_dest_y, dest_y);
-            fill_caches(h, mb_type_top, 1); //FIXME don't fill stuff which isn't used by filter_mb
-            h->chroma_qp[0] = get_chroma_qp(h, 0, s->current_picture.qscale_table[mb_xy]);
-            h->chroma_qp[1] = get_chroma_qp(h, 1, s->current_picture.qscale_table[mb_xy]);
-            filter_mb(h, mb_x, mb_y, pair_dest_y, pair_dest_cb, pair_dest_cr, linesize, uvlinesize);
-            // bottom
-            s->mb_y++;
-            tprintf(h->s.avctx, "call mbaff filter_mb\n");
-            fill_caches(h, mb_type_bottom, 1); //FIXME don't fill stuff which isn't used by filter_mb
-            h->chroma_qp[0] = get_chroma_qp(h, 0, s->current_picture.qscale_table[mb_xy+s->mb_stride]);
-            h->chroma_qp[1] = get_chroma_qp(h, 1, s->current_picture.qscale_table[mb_xy+s->mb_stride]);
-            filter_mb(h, mb_x, mb_y+1, dest_y, dest_cb, dest_cr, linesize, uvlinesize);
+            filter_mb     (h, mb_x, mb_y, dest_y, dest_cb, dest_cr, linesize, uvlinesize);
         } else {
-            tprintf(h->s.avctx, "call filter_mb\n");
-            backup_mb_border(h, dest_y, dest_cb, dest_cr, linesize, uvlinesize, simple);
-            fill_caches(h, mb_type, 1); //FIXME don't fill stuff which isn't used by filter_mb
             filter_mb_fast(h, mb_x, mb_y, dest_y, dest_cb, dest_cr, linesize, uvlinesize);
         }
     }
@@ -2750,13 +2645,12 @@
 
 static void hl_decode_mb(H264Context *h){
     MpegEncContext * const s = &h->s;
-    const int mb_x= s->mb_x;
-    const int mb_y= s->mb_y;
-    const int mb_xy= mb_x + mb_y*s->mb_stride;
+    const int mb_xy= h->mb_xy;
     const int mb_type= s->current_picture.mb_type[mb_xy];
-    int is_complex = FRAME_MBAFF || MB_FIELD || IS_INTRA_PCM(mb_type) || s->codec_id != CODEC_ID_H264 || (ENABLE_GRAY && (s->flags&CODEC_FLAG_GRAY)) || s->encoding;
+    int is_complex = FRAME_MBAFF || MB_FIELD || IS_INTRA_PCM(mb_type) || s->codec_id != CODEC_ID_H264 ||
+                    (ENABLE_GRAY && (s->flags&CODEC_FLAG_GRAY)) || (ENABLE_H264_ENCODER && s->encoding) || ENABLE_SMALL;
 
-    if(!s->decode)
+    if(ENABLE_H264_ENCODER && !s->decode)
         return;
 
     if (is_complex)
@@ -2772,6 +2666,7 @@
         pic->reference = parity;
         pic->linesize[i] *= 2;
     }
+    pic->poc= pic->field_poc[parity == PICT_BOTTOM_FIELD];
 }
 
 static int split_field_copy(Picture *dest, Picture *src,
@@ -2780,87 +2675,57 @@
 
     if (match) {
         *dest = *src;
-        pic_as_field(dest, parity);
-        dest->pic_id *= 2;
-        dest->pic_id += id_add;
+        if(parity != PICT_FRAME){
+            pic_as_field(dest, parity);
+            dest->pic_id *= 2;
+            dest->pic_id += id_add;
+        }
     }
 
     return match;
 }
 
-/**
- * Split one reference list into field parts, interleaving by parity
- * as per H.264 spec section 8.2.4.2.5. Output fields have their data pointers
- * set to look at the actual start of data for that field.
- *
- * @param dest output list
- * @param dest_len maximum number of fields to put in dest
- * @param src the source reference list containing fields and/or field pairs
- *            (aka short_ref/long_ref, or
- *             refFrameListXShortTerm/refFrameListLongTerm in spec-speak)
- * @param src_len number of Picture's in source (pairs and unmatched fields)
- * @param parity the parity of the picture being decoded/needing
- *        these ref pics (PICT_{TOP,BOTTOM}_FIELD)
- * @return number of fields placed in dest
- */
-static int split_field_half_ref_list(Picture *dest, int dest_len,
-                                     Picture *src,  int src_len,  int parity){
-    int same_parity   = 1;
-    int same_i        = 0;
-    int opp_i         = 0;
-    int out_i;
-    int field_output;
+static int build_def_list(Picture *def, Picture **in, int len, int is_long, int sel){
+    int i[2]={0};
+    int index=0;
 
-    for (out_i = 0; out_i < dest_len; out_i += field_output) {
-        if (same_parity && same_i < src_len) {
-            field_output = split_field_copy(dest + out_i, src + same_i,
-                                            parity, 1);
-            same_parity = !field_output;
-            same_i++;
-
-        } else if (opp_i < src_len) {
-            field_output = split_field_copy(dest + out_i, src + opp_i,
-                                            PICT_FRAME - parity, 0);
-            same_parity = field_output;
-            opp_i++;
-
-        } else {
-            break;
+    while(i[0]<len || i[1]<len){
+        while(i[0]<len && !(in[ i[0] ] && (in[ i[0] ]->reference & sel)))
+            i[0]++;
+        while(i[1]<len && !(in[ i[1] ] && (in[ i[1] ]->reference & (sel^3))))
+            i[1]++;
+        if(i[0] < len){
+            in[ i[0] ]->pic_id= is_long ? i[0] : in[ i[0] ]->frame_num;
+            split_field_copy(&def[index++], in[ i[0]++ ], sel  , 1);
         }
+        if(i[1] < len){
+            in[ i[1] ]->pic_id= is_long ? i[1] : in[ i[1] ]->frame_num;
+            split_field_copy(&def[index++], in[ i[1]++ ], sel^3, 0);
+        }
     }
 
-    return out_i;
+    return index;
 }
 
-/**
- * Split the reference frame list into a reference field list.
- * This implements H.264 spec 8.2.4.2.5 for a combined input list.
- * The input list contains both reference field pairs and
- * unmatched reference fields; it is ordered as spec describes
- * RefPicListX for frames in 8.2.4.2.1 and 8.2.4.2.3, except that
- * unmatched field pairs are also present. Conceptually this is equivalent
- * to concatenation of refFrameListXShortTerm with refFrameListLongTerm.
- *
- * @param dest output reference list where ordered fields are to be placed
- * @param dest_len max number of fields to place at dest
- * @param src source reference list, as described above
- * @param src_len number of pictures (pairs and unmatched fields) in src
- * @param parity parity of field being currently decoded
- *        (one of PICT_{TOP,BOTTOM}_FIELD)
- * @param long_i index into src array that holds first long reference picture,
- *        or src_len if no long refs present.
- */
-static int split_field_ref_list(Picture *dest, int dest_len,
-                                Picture *src,  int src_len,
-                                int parity,    int long_i){
+static int add_sorted(Picture **sorted, Picture **src, int len, int limit, int dir){
+    int i, best_poc;
+    int out_i= 0;
 
-    int i = split_field_half_ref_list(dest, dest_len, src, long_i, parity);
-    dest += i;
-    dest_len -= i;
+    for(;;){
+        best_poc= dir ? INT_MIN : INT_MAX;
 
-    i += split_field_half_ref_list(dest, dest_len, src + long_i,
-                                   src_len - long_i, parity);
-    return i;
+        for(i=0; i<len; i++){
+            const int poc= src[i]->poc;
+            if(((poc > limit) ^ dir) && ((poc < best_poc) ^ dir)){
+                best_poc= poc;
+                sorted[out_i]= src[i];
+            }
+        }
+        if(best_poc == (dir ? INT_MIN : INT_MAX))
+            break;
+        limit= sorted[out_i++]->poc - dir;
+    }
+    return out_i;
 }
 
 /**
@@ -2868,149 +2733,50 @@
  */
 static int fill_default_ref_list(H264Context *h){
     MpegEncContext * const s = &h->s;
-    int i;
-    int smallest_poc_greater_than_current = -1;
-    int structure_sel;
-    Picture sorted_short_ref[32];
-    Picture field_entry_list[2][32];
-    Picture *frame_list[2];
+    int i, len;
 
-    if (FIELD_PICTURE) {
-        structure_sel = PICT_FRAME;
-        frame_list[0] = field_entry_list[0];
-        frame_list[1] = field_entry_list[1];
-    } else {
-        structure_sel = 0;
-        frame_list[0] = h->default_ref_list[0];
-        frame_list[1] = h->default_ref_list[1];
-    }
+    if(h->slice_type_nos==FF_B_TYPE){
+        Picture *sorted[32];
+        int cur_poc, list;
+        int lens[2];
 
-    if(h->slice_type==B_TYPE){
-        int list;
-        int len[2];
-        int short_len[2];
-        int out_i;
-        int limit= INT_MIN;
+        if(FIELD_PICTURE)
+            cur_poc= s->current_picture_ptr->field_poc[ s->picture_structure == PICT_BOTTOM_FIELD ];
+        else
+            cur_poc= s->current_picture_ptr->poc;
 
-        /* sort frame according to poc in B slice */
-        for(out_i=0; out_i<h->short_ref_count; out_i++){
-            int best_i=INT_MIN;
-            int best_poc=INT_MAX;
+        for(list= 0; list<2; list++){
+            len= add_sorted(sorted    , h->short_ref, h->short_ref_count, cur_poc, 1^list);
+            len+=add_sorted(sorted+len, h->short_ref, h->short_ref_count, cur_poc, 0^list);
+            assert(len<=32);
+            len= build_def_list(h->default_ref_list[list]    , sorted     , len, 0, s->picture_structure);
+            len+=build_def_list(h->default_ref_list[list]+len, h->long_ref, 16 , 1, s->picture_structure);
+            assert(len<=32);
 
-            for(i=0; i<h->short_ref_count; i++){
-                const int poc= h->short_ref[i]->poc;
-                if(poc > limit && poc < best_poc){
-                    best_poc= poc;
-                    best_i= i;
-                }
-            }
-
-            assert(best_i != INT_MIN);
-
-            limit= best_poc;
-            sorted_short_ref[out_i]= *h->short_ref[best_i];
-            tprintf(h->s.avctx, "sorted poc: %d->%d poc:%d fn:%d\n", best_i, out_i, sorted_short_ref[out_i].poc, sorted_short_ref[out_i].frame_num);
-            if (-1 == smallest_poc_greater_than_current) {
-                if (h->short_ref[best_i]->poc >= s->current_picture_ptr->poc) {
-                    smallest_poc_greater_than_current = out_i;
-                }
-            }
+            if(len < h->ref_count[list])
+                memset(&h->default_ref_list[list][len], 0, sizeof(Picture)*(h->ref_count[list] - len));
+            lens[list]= len;
         }
 
-        tprintf(h->s.avctx, "current poc: %d, smallest_poc_greater_than_current: %d\n", s->current_picture_ptr->poc, smallest_poc_greater_than_current);
-
-        // find the largest poc
-        for(list=0; list<2; list++){
-            int index = 0;
-            int j= -99;
-            int step= list ? -1 : 1;
-
-            for(i=0; i<h->short_ref_count && index < h->ref_count[list]; i++, j+=step) {
-                int sel;
-                while(j<0 || j>= h->short_ref_count){
-                    if(j != -99 && step == (list ? -1 : 1))
-                        return -1;
-                    step = -step;
-                    j= smallest_poc_greater_than_current + (step>>1);
-                }
-                sel = sorted_short_ref[j].reference | structure_sel;
-                if(sel != PICT_FRAME) continue;
-                frame_list[list][index  ]= sorted_short_ref[j];
-                frame_list[list][index++].pic_id= sorted_short_ref[j].frame_num;
-            }
-            short_len[list] = index;
-
-            for(i = 0; i < 16 && index < h->ref_count[ list ]; i++){
-                int sel;
-                if(h->long_ref[i] == NULL) continue;
-                sel = h->long_ref[i]->reference | structure_sel;
-                if(sel != PICT_FRAME) continue;
-
-                frame_list[ list ][index  ]= *h->long_ref[i];
-                frame_list[ list ][index++].pic_id= i;;
-            }
-            len[list] = index;
-
-            if(list && (smallest_poc_greater_than_current<=0 || smallest_poc_greater_than_current>=h->short_ref_count) && (1 < index)){
-                // swap the two first elements of L1 when
-                // L0 and L1 are identical
-                Picture temp= frame_list[1][0];
-                frame_list[1][0] = frame_list[1][1];
-                frame_list[1][1] = temp;
-            }
-
+        if(lens[0] == lens[1] && lens[1] > 1){
+            for(i=0; h->default_ref_list[0][i].data[0] == h->default_ref_list[1][i].data[0] && i<lens[0]; i++);
+            if(i == lens[0])
+                FFSWAP(Picture, h->default_ref_list[1][0], h->default_ref_list[1][1]);
         }
-
-        for(list=0; list<2; list++){
-            if (FIELD_PICTURE)
-                len[list] = split_field_ref_list(h->default_ref_list[list],
-                                                 h->ref_count[list],
-                                                 frame_list[list],
-                                                 len[list],
-                                                 s->picture_structure,
-                                                 short_len[list]);
-
-            if(len[list] < h->ref_count[ list ])
-                memset(&h->default_ref_list[list][len[list]], 0, sizeof(Picture)*(h->ref_count[ list ] - len[list]));
-        }
-
-
     }else{
-        int index=0;
-        int short_len;
-        for(i=0; i<h->short_ref_count; i++){
-            int sel;
-            sel = h->short_ref[i]->reference | structure_sel;
-            if(sel != PICT_FRAME) continue;
-            frame_list[0][index  ]= *h->short_ref[i];
-            frame_list[0][index++].pic_id= h->short_ref[i]->frame_num;
-        }
-        short_len = index;
-        for(i = 0; i < 16; i++){
-            int sel;
-            if(h->long_ref[i] == NULL) continue;
-            sel = h->long_ref[i]->reference | structure_sel;
-            if(sel != PICT_FRAME) continue;
-            frame_list[0][index  ]= *h->long_ref[i];
-            frame_list[0][index++].pic_id= i;;
-        }
-
-        if (FIELD_PICTURE)
-            index = split_field_ref_list(h->default_ref_list[0],
-                                         h->ref_count[0], frame_list[0],
-                                         index, s->picture_structure,
-                                         short_len);
-
-        if(index < h->ref_count[0])
-            memset(&h->default_ref_list[0][index], 0, sizeof(Picture)*(h->ref_count[0] - index));
+        len = build_def_list(h->default_ref_list[0]    , h->short_ref, h->short_ref_count, 0, s->picture_structure);
+        len+= build_def_list(h->default_ref_list[0]+len, h-> long_ref, 16                , 1, s->picture_structure);
+        assert(len <= 32);
+        if(len < h->ref_count[0])
+            memset(&h->default_ref_list[0][len], 0, sizeof(Picture)*(h->ref_count[0] - len));
     }
 #ifdef TRACE
     for (i=0; i<h->ref_count[0]; i++) {
         tprintf(h->s.avctx, "List0: %s fn:%d 0x%p\n", (h->default_ref_list[0][i].long_ref ? "LT" : "ST"), h->default_ref_list[0][i].pic_id, h->default_ref_list[0][i].data[0]);
     }
-    if(h->slice_type==B_TYPE){
+    if(h->slice_type_nos==FF_B_TYPE){
         for (i=0; i<h->ref_count[1]; i++) {
-            tprintf(h->s.avctx, "List1: %s fn:%d 0x%p\n", (h->default_ref_list[1][i].long_ref ? "LT" : "ST"), h->default_ref_list[1][i].pic_id, h->default_ref_list[0][i].data[0]);
+            tprintf(h->s.avctx, "List1: %s fn:%d 0x%p\n", (h->default_ref_list[1][i].long_ref ? "LT" : "ST"), h->default_ref_list[1][i].pic_id, h->default_ref_list[1][i].data[0]);
         }
     }
 #endif
@@ -3050,7 +2816,6 @@
 
     print_short_term(h);
     print_long_term(h);
-    if(h->slice_type==I_TYPE || h->slice_type==SI_TYPE) return 0; //FIXME move before func
 
     for(list=0; list<h->list_count; list++){
         memcpy(h->ref_list[list], h->default_ref_list[list], sizeof(Picture)*h->ref_count[list]);
@@ -3092,10 +2857,10 @@
                             ref = h->short_ref[i];
                             assert(ref->reference);
                             assert(!ref->long_ref);
-                            if(ref->data[0] != NULL &&
+                            if(
                                    ref->frame_num == frame_num &&
-                                   (ref->reference & pic_structure) &&
-                                   ref->long_ref == 0) // ignore non existing pictures by testing data[0] pointer
+                                   (ref->reference & pic_structure)
+                              )
                                 break;
                         }
                         if(i>=0)
@@ -3146,12 +2911,14 @@
     }
     for(list=0; list<h->list_count; list++){
         for(index= 0; index < h->ref_count[list]; index++){
-            if(!h->ref_list[list][index].data[0])
-                h->ref_list[list][index]= s->current_picture;
+            if(!h->ref_list[list][index].data[0]){
+                av_log(h->s.avctx, AV_LOG_ERROR, "Missing reference picture\n");
+                h->ref_list[list][index]= s->current_picture; //FIXME this is not a sensible solution
+            }
         }
     }
 
-    if(h->slice_type==B_TYPE && !h->direct_spatial_mv_pred)
+    if(h->slice_type_nos==FF_B_TYPE && !h->direct_spatial_mv_pred)
         direct_dist_scale_factor(h);
     direct_ref_list_init(h);
     return 0;
@@ -3216,25 +2983,27 @@
                 h->luma_offset[list][i]= 0;
             }
 
-            chroma_weight_flag= get_bits1(&s->gb);
-            if(chroma_weight_flag){
-                int j;
-                for(j=0; j<2; j++){
-                    h->chroma_weight[list][i][j]= get_se_golomb(&s->gb);
-                    h->chroma_offset[list][i][j]= get_se_golomb(&s->gb);
-                    if(   h->chroma_weight[list][i][j] != chroma_def
-                       || h->chroma_offset[list][i][j] != 0)
-                        h->use_weight_chroma= 1;
+            if(CHROMA){
+                chroma_weight_flag= get_bits1(&s->gb);
+                if(chroma_weight_flag){
+                    int j;
+                    for(j=0; j<2; j++){
+                        h->chroma_weight[list][i][j]= get_se_golomb(&s->gb);
+                        h->chroma_offset[list][i][j]= get_se_golomb(&s->gb);
+                        if(   h->chroma_weight[list][i][j] != chroma_def
+                        || h->chroma_offset[list][i][j] != 0)
+                            h->use_weight_chroma= 1;
+                    }
+                }else{
+                    int j;
+                    for(j=0; j<2; j++){
+                        h->chroma_weight[list][i][j]= chroma_def;
+                        h->chroma_offset[list][i][j]= 0;
+                    }
                 }
-            }else{
-                int j;
-                for(j=0; j<2; j++){
-                    h->chroma_weight[list][i][j]= chroma_def;
-                    h->chroma_offset[list][i][j]= 0;
-                }
             }
         }
-        if(h->slice_type != B_TYPE) break;
+        if(h->slice_type_nos != FF_B_TYPE) break;
     }
     h->use_weight= h->use_weight || h->use_weight_chroma;
     return 0;
@@ -3292,15 +3061,11 @@
     if (pic->reference &= refmask) {
         return 0;
     } else {
-        if(pic == h->delayed_output_pic)
-            pic->reference=DELAYED_PIC_REF;
-        else{
-            for(i = 0; h->delayed_pic[i]; i++)
-                if(pic == h->delayed_pic[i]){
-                    pic->reference=DELAYED_PIC_REF;
-                    break;
-                }
-        }
+        for(i = 0; h->delayed_pic[i]; i++)
+            if(pic == h->delayed_pic[i]){
+                pic->reference=DELAYED_PIC_REF;
+                break;
+            }
         return 1;
     }
 }
@@ -3312,32 +3077,31 @@
     int i;
 
     for(i=0; i<16; i++){
-        if (h->long_ref[i] != NULL) {
-            unreference_pic(h, h->long_ref[i], 0);
-            h->long_ref[i]= NULL;
-        }
+        remove_long(h, i, 0);
     }
-    h->long_ref_count=0;
+    assert(h->long_ref_count==0);
 
     for(i=0; i<h->short_ref_count; i++){
         unreference_pic(h, h->short_ref[i], 0);
         h->short_ref[i]= NULL;
     }
     h->short_ref_count=0;
+    h->prev_frame_num= 0;
+    h->prev_frame_num_offset= 0;
+    h->prev_poc_msb=
+    h->prev_poc_lsb= 0;
 }
 
 /* forget old pics after a seek */
 static void flush_dpb(AVCodecContext *avctx){
     H264Context *h= avctx->priv_data;
     int i;
-    for(i=0; i<16; i++) {
+    for(i=0; i<MAX_DELAYED_PIC_COUNT; i++) {
         if(h->delayed_pic[i])
             h->delayed_pic[i]->reference= 0;
         h->delayed_pic[i]= NULL;
     }
-    if(h->delayed_output_pic)
-        h->delayed_output_pic->reference= 0;
-    h->delayed_output_pic= NULL;
+    h->outputed_poc= INT_MIN;
     idr(h);
     if(h->s.current_picture_ptr)
         h->s.current_picture_ptr->reference= 0;
@@ -3376,7 +3140,7 @@
  * @param i index into h->short_ref of picture to remove.
  */
 static void remove_short_at_index(H264Context *h, int i){
-    assert(i > 0 && i < h->short_ref_count);
+    assert(i >= 0 && i < h->short_ref_count);
     h->short_ref[i]= NULL;
     if (--h->short_ref_count)
         memmove(&h->short_ref[i], &h->short_ref[i+1], (h->short_ref_count - i)*sizeof(Picture*));
@@ -3386,7 +3150,7 @@
  *
  * @return the removed picture or NULL if an error occurs
  */
-static Picture * remove_short(H264Context *h, int frame_num){
+static Picture * remove_short(H264Context *h, int frame_num, int ref_mask){
     MpegEncContext * const s = &h->s;
     Picture *pic;
     int i;
@@ -3395,33 +3159,31 @@
         av_log(h->s.avctx, AV_LOG_DEBUG, "remove short %d count %d\n", frame_num, h->short_ref_count);
 
     pic = find_short(h, frame_num, &i);
-    if (pic)
+    if (pic){
+        if(unreference_pic(h, pic, ref_mask))
         remove_short_at_index(h, i);
+    }
 
     return pic;
 }
 
 /**
  * Remove a picture from the long term reference list by its index in
- * that list.  This does no checking on the provided index; it is assumed
- * to be valid. The removed entry is set to NULL. Other entries are unaffected.
- * @param i index into h->long_ref of picture to remove.
- */
-static void remove_long_at_index(H264Context *h, int i){
-    h->long_ref[i]= NULL;
-    h->long_ref_count--;
-}
-
-/**
- *
+ * that list.
  * @return the removed picture or NULL if an error occurs
  */
-static Picture * remove_long(H264Context *h, int i){
+static Picture * remove_long(H264Context *h, int i, int ref_mask){
     Picture *pic;
 
     pic= h->long_ref[i];
-    if (pic)
-        remove_long_at_index(h, i);
+    if (pic){
+        if(unreference_pic(h, pic, ref_mask)){
+            assert(h->long_ref[i]->long_ref == 1);
+            h->long_ref[i]->long_ref= 0;
+            h->long_ref[i]= NULL;
+            h->long_ref_count--;
+        }
+    }
 
     return pic;
 }
@@ -3469,73 +3231,58 @@
         av_log(h->s.avctx, AV_LOG_DEBUG, "no mmco here\n");
 
     for(i=0; i<mmco_count; i++){
-        int structure, frame_num, unref_pic;
+        int structure, frame_num;
         if(s->avctx->debug&FF_DEBUG_MMCO)
             av_log(h->s.avctx, AV_LOG_DEBUG, "mmco:%d %d %d\n", h->mmco[i].opcode, h->mmco[i].short_pic_num, h->mmco[i].long_arg);
 
+        if(   mmco[i].opcode == MMCO_SHORT2UNUSED
+           || mmco[i].opcode == MMCO_SHORT2LONG){
+            frame_num = pic_num_extract(h, mmco[i].short_pic_num, &structure);
+            pic = find_short(h, frame_num, &j);
+            if(!pic){
+                if(mmco[i].opcode != MMCO_SHORT2LONG || !h->long_ref[mmco[i].long_arg]
+                   || h->long_ref[mmco[i].long_arg]->frame_num != frame_num)
+                av_log(h->s.avctx, AV_LOG_ERROR, "mmco: unref short failure\n");
+                continue;
+            }
+        }
+
         switch(mmco[i].opcode){
         case MMCO_SHORT2UNUSED:
             if(s->avctx->debug&FF_DEBUG_MMCO)
                 av_log(h->s.avctx, AV_LOG_DEBUG, "mmco: unref short %d count %d\n", h->mmco[i].short_pic_num, h->short_ref_count);
-            frame_num = pic_num_extract(h, mmco[i].short_pic_num, &structure);
-            pic = find_short(h, frame_num, &j);
-            if (pic) {
-                if (unreference_pic(h, pic, structure ^ PICT_FRAME))
-                    remove_short_at_index(h, j);
-            } else if(s->avctx->debug&FF_DEBUG_MMCO)
-                av_log(h->s.avctx, AV_LOG_DEBUG, "mmco: unref short failure\n");
+            remove_short(h, frame_num, structure ^ PICT_FRAME);
             break;
         case MMCO_SHORT2LONG:
-            if (FIELD_PICTURE && mmco[i].long_arg < h->long_ref_count &&
-                    h->long_ref[mmco[i].long_arg]->frame_num ==
-                                              mmco[i].short_pic_num / 2) {
-                /* do nothing, we've already moved this field pair. */
-            } else {
-                int frame_num = mmco[i].short_pic_num >> FIELD_PICTURE;
+                if (h->long_ref[mmco[i].long_arg] != pic)
+                    remove_long(h, mmco[i].long_arg, 0);
 
-                pic= remove_long(h, mmco[i].long_arg);
-                if(pic) unreference_pic(h, pic, 0);
-
-                h->long_ref[ mmco[i].long_arg ]= remove_short(h, frame_num);
+                remove_short_at_index(h, j);
+                h->long_ref[ mmco[i].long_arg ]= pic;
                 if (h->long_ref[ mmco[i].long_arg ]){
                     h->long_ref[ mmco[i].long_arg ]->long_ref=1;
                     h->long_ref_count++;
                 }
-            }
             break;
         case MMCO_LONG2UNUSED:
             j = pic_num_extract(h, mmco[i].long_arg, &structure);
             pic = h->long_ref[j];
             if (pic) {
-                if (unreference_pic(h, pic, structure ^ PICT_FRAME))
-                    remove_long_at_index(h, j);
+                remove_long(h, j, structure ^ PICT_FRAME);
             } else if(s->avctx->debug&FF_DEBUG_MMCO)
                 av_log(h->s.avctx, AV_LOG_DEBUG, "mmco: unref long failure\n");
             break;
         case MMCO_LONG:
-            unref_pic = 1;
-            if (FIELD_PICTURE && !s->first_field) {
-                if (h->long_ref[mmco[i].long_arg] == s->current_picture_ptr) {
-                    /* Just mark second field as referenced */
-                    unref_pic = 0;
-                } else if (s->current_picture_ptr->reference) {
+                    // Comment below left from previous code as it is an interresting note.
                     /* First field in pair is in short term list or
                      * at a different long term index.
-                     * This is not allowed; see 7.4.3, notes 2 and 3.
+                     * This is not allowed; see 7.4.3.3, notes 2 and 3.
                      * Report the problem and keep the pair where it is,
                      * and mark this field valid.
                      */
-                    av_log(h->s.avctx, AV_LOG_ERROR,
-                        "illegal long term reference assignment for second "
-                        "field in complementary field pair (first field is "
-                        "short term or has non-matching long index)\n");
-                    unref_pic = 0;
-                }
-            }
 
-            if (unref_pic) {
-                pic= remove_long(h, mmco[i].long_arg);
-                if(pic) unreference_pic(h, pic, 0);
+            if (h->long_ref[mmco[i].long_arg] != s->current_picture_ptr) {
+                remove_long(h, mmco[i].long_arg, 0);
 
                 h->long_ref[ mmco[i].long_arg ]= s->current_picture_ptr;
                 h->long_ref[ mmco[i].long_arg ]->long_ref=1;
@@ -3549,32 +3296,34 @@
             assert(mmco[i].long_arg <= 16);
             // just remove the long term which index is greater than new max
             for(j = mmco[i].long_arg; j<16; j++){
-                pic = remove_long(h, j);
-                if (pic) unreference_pic(h, pic, 0);
+                remove_long(h, j, 0);
             }
             break;
         case MMCO_RESET:
             while(h->short_ref_count){
-                pic= remove_short(h, h->short_ref[0]->frame_num);
-                if(pic) unreference_pic(h, pic, 0);
+                remove_short(h, h->short_ref[0]->frame_num, 0);
             }
             for(j = 0; j < 16; j++) {
-                pic= remove_long(h, j);
-                if(pic) unreference_pic(h, pic, 0);
+                remove_long(h, j, 0);
             }
+            s->current_picture_ptr->poc=
+            s->current_picture_ptr->field_poc[0]=
+            s->current_picture_ptr->field_poc[1]=
+            h->poc_lsb=
+            h->poc_msb=
+            h->frame_num=
+            s->current_picture_ptr->frame_num= 0;
             break;
         default: assert(0);
         }
     }
 
-    if (!current_ref_assigned && FIELD_PICTURE &&
-            !s->first_field && s->current_picture_ptr->reference) {
-
+    if (!current_ref_assigned) {
         /* Second field of complementary field pair; the first field of
          * which is already referenced. If short referenced, it
          * should be first entry in short_ref. If not, it must exist
          * in long_ref; trying to put it on the short list here is an
-         * error in the encoded bit stream (ref: 7.4.3, NOTE 2 and 3).
+         * error in the encoded bit stream (ref: 7.4.3.3, NOTE 2 and 3).
          */
         if (h->short_ref_count && h->short_ref[0] == s->current_picture_ptr) {
             /* Just mark the second field valid */
@@ -3585,30 +3334,41 @@
                                              "in complementary field pair "
                                              "(first field is long term)\n");
         } else {
-            /*
-             * First field in reference, but not in any sensible place on our
-             * reference lists. This shouldn't happen unless reference
-             * handling somewhere else is wrong.
-             */
-            assert(0);
+            pic= remove_short(h, s->current_picture_ptr->frame_num, 0);
+            if(pic){
+                av_log(h->s.avctx, AV_LOG_ERROR, "illegal short term buffer state detected\n");
+            }
+
+            if(h->short_ref_count)
+                memmove(&h->short_ref[1], &h->short_ref[0], h->short_ref_count*sizeof(Picture*));
+
+            h->short_ref[0]= s->current_picture_ptr;
+            h->short_ref_count++;
+            s->current_picture_ptr->reference |= s->picture_structure;
         }
-        current_ref_assigned = 1;
     }
 
-    if(!current_ref_assigned){
-        pic= remove_short(h, s->current_picture_ptr->frame_num);
-        if(pic){
-            unreference_pic(h, pic, 0);
-            av_log(h->s.avctx, AV_LOG_ERROR, "illegal short term buffer state detected\n");
-        }
+    if (h->long_ref_count + h->short_ref_count > h->sps.ref_frame_count){
 
-        if(h->short_ref_count)
-            memmove(&h->short_ref[1], &h->short_ref[0], h->short_ref_count*sizeof(Picture*));
+        /* We have too many reference frames, probably due to corrupted
+         * stream. Need to discard one frame. Prevents overrun of the
+         * short_ref and long_ref buffers.
+         */
+        av_log(h->s.avctx, AV_LOG_ERROR,
+               "number of reference frames exceeds max (probably "
+               "corrupt input), discarding one\n");
 
-        h->short_ref[0]= s->current_picture_ptr;
-        h->short_ref[0]->long_ref=0;
-        h->short_ref_count++;
-        s->current_picture_ptr->reference |= s->picture_structure;
+        if (h->long_ref_count && !h->short_ref_count) {
+            for (i = 0; i < 16; ++i)
+                if (h->long_ref[i])
+                    break;
+
+            assert(i < 16);
+            remove_long(h, i, 0);
+        } else {
+            pic = h->short_ref[h->short_ref_count - 1];
+            remove_short(h, pic->frame_num, 0);
+        }
     }
 
     print_short_term(h);
@@ -3620,13 +3380,12 @@
     MpegEncContext * const s = &h->s;
     int i;
 
+    h->mmco_index= 0;
     if(h->nal_unit_type == NAL_IDR_SLICE){ //FIXME fields
         s->broken_link= get_bits1(gb) -1;
-        h->mmco[0].long_arg= get_bits1(gb) - 1; // current_long_term_idx
-        if(h->mmco[0].long_arg == -1)
-            h->mmco_index= 0;
-        else{
+        if(get_bits1(gb)){
             h->mmco[0].opcode= MMCO_LONG;
+            h->mmco[0].long_arg= 0;
             h->mmco_index= 1;
         }
     }else{
@@ -3662,7 +3421,7 @@
         }else{
             assert(h->long_ref_count + h->short_ref_count <= h->sps.ref_frame_count);
 
-            if(h->long_ref_count + h->short_ref_count == h->sps.ref_frame_count &&
+            if(h->short_ref_count && h->long_ref_count + h->short_ref_count == h->sps.ref_frame_count &&
                     !(FIELD_PICTURE && !s->first_field && s->current_picture_ptr->reference)) {
                 h->mmco[0].opcode= MMCO_SHORT2UNUSED;
                 h->mmco[0].short_pic_num= h->short_ref[ h->short_ref_count - 1 ]->frame_num;
@@ -3673,8 +3432,7 @@
                     h->mmco[1].short_pic_num= h->mmco[0].short_pic_num + 1;
                     h->mmco_index= 2;
                 }
-            }else
-                h->mmco_index= 0;
+            }
         }
     }
 
@@ -3685,24 +3443,15 @@
     MpegEncContext * const s = &h->s;
     const int max_frame_num= 1<<h->sps.log2_max_frame_num;
     int field_poc[2];
+    Picture *cur = s->current_picture_ptr;
 
-    if(h->nal_unit_type == NAL_IDR_SLICE){
-        h->frame_num_offset= 0;
-    }else{
-        if(h->frame_num < h->prev_frame_num)
-            h->frame_num_offset= h->prev_frame_num_offset + max_frame_num;
-        else
-            h->frame_num_offset= h->prev_frame_num_offset;
-    }
+    h->frame_num_offset= h->prev_frame_num_offset;
+    if(h->frame_num < h->prev_frame_num)
+        h->frame_num_offset += max_frame_num;
 
     if(h->sps.poc_type==0){
         const int max_poc_lsb= 1<<h->sps.log2_max_poc_lsb;
 
-        if(h->nal_unit_type == NAL_IDR_SLICE){
-             h->prev_poc_msb=
-             h->prev_poc_lsb= 0;
-        }
-
         if     (h->poc_lsb < h->prev_poc_lsb && h->prev_poc_lsb - h->poc_lsb >= max_poc_lsb/2)
             h->poc_msb = h->prev_poc_msb + max_poc_lsb;
         else if(h->poc_lsb > h->prev_poc_lsb && h->prev_poc_lsb - h->poc_lsb < -max_poc_lsb/2)
@@ -3749,29 +3498,20 @@
         if(s->picture_structure == PICT_FRAME)
             field_poc[1] += h->delta_poc[1];
     }else{
-        int poc;
-        if(h->nal_unit_type == NAL_IDR_SLICE){
-            poc= 0;
-        }else{
-            if(h->nal_ref_idc) poc= 2*(h->frame_num_offset + h->frame_num);
-            else               poc= 2*(h->frame_num_offset + h->frame_num) - 1;
-        }
+        int poc= 2*(h->frame_num_offset + h->frame_num);
+
+        if(!h->nal_ref_idc)
+            poc--;
+
         field_poc[0]= poc;
         field_poc[1]= poc;
     }
 
-    if(s->picture_structure != PICT_BOTTOM_FIELD) {
+    if(s->picture_structure != PICT_BOTTOM_FIELD)
         s->current_picture_ptr->field_poc[0]= field_poc[0];
-        s->current_picture_ptr->poc = field_poc[0];
-    }
-    if(s->picture_structure != PICT_TOP_FIELD) {
+    if(s->picture_structure != PICT_TOP_FIELD)
         s->current_picture_ptr->field_poc[1]= field_poc[1];
-        s->current_picture_ptr->poc = field_poc[1];
-    }
-    if(!FIELD_PICTURE || !s->first_field) {
-        Picture *cur = s->current_picture_ptr;
-        cur->poc= FFMIN(cur->field_poc[0], cur->field_poc[1]);
-    }
+    cur->poc= FFMIN(cur->field_poc[0], cur->field_poc[1]);
 
     return 0;
 }
@@ -3855,7 +3595,7 @@
 
 /**
  * decodes a slice header.
- * this will allso call MPV_common_init() and frame_start() as needed
+ * This will also call MPV_common_init() and frame_start() as needed.
  *
  * @param h h264context
  * @param h0 h264 master context (differs from 'h' when doing sliced based parallel decoding)
@@ -3868,13 +3608,21 @@
     unsigned int first_mb_in_slice;
     unsigned int pps_id;
     int num_ref_idx_active_override_flag;
-    static const uint8_t slice_type_map[5]= {P_TYPE, B_TYPE, I_TYPE, SP_TYPE, SI_TYPE};
-    unsigned int slice_type, tmp, i;
+    static const uint8_t slice_type_map[5]= {FF_P_TYPE, FF_B_TYPE, FF_I_TYPE, FF_SP_TYPE, FF_SI_TYPE};
+    unsigned int slice_type, tmp, i, j;
     int default_ref_list_done = 0;
     int last_pic_structure;
 
     s->dropable= h->nal_ref_idc == 0;
 
+    if((s->avctx->flags2 & CODEC_FLAG2_FAST) && !h->nal_ref_idc){
+        s->me.qpel_put= s->dsp.put_2tap_qpel_pixels_tab;
+        s->me.qpel_avg= s->dsp.avg_2tap_qpel_pixels_tab;
+    }else{
+        s->me.qpel_put= s->dsp.put_h264_qpel_pixels_tab;
+        s->me.qpel_avg= s->dsp.avg_h264_qpel_pixels_tab;
+    }
+
     first_mb_in_slice= get_ue_golomb(&s->gb);
 
     if((s->flags2 & CODEC_FLAG2_CHUNKS) && first_mb_in_slice == 0){
@@ -3895,14 +3643,15 @@
         h->slice_type_fixed=0;
 
     slice_type= slice_type_map[ slice_type ];
-    if (slice_type == I_TYPE
+    if (slice_type == FF_I_TYPE
         || (h0->current_slice != 0 && slice_type == h0->last_slice_type) ) {
         default_ref_list_done = 1;
     }
     h->slice_type= slice_type;
+    h->slice_type_nos= slice_type & 3;
 
-    s->pict_type= h->slice_type; // to make a few old func happy, it's wrong though
-    if (s->pict_type == B_TYPE && s0->last_picture_ptr == NULL) {
+    s->pict_type= h->slice_type; // to make a few old functions happy, it's wrong though
+    if (s->pict_type == FF_B_TYPE && s0->last_picture_ptr == NULL) {
         av_log(h->s.avctx, AV_LOG_ERROR,
                "B picture before any references, skipping\n");
         return -1;
@@ -3914,13 +3663,13 @@
         return -1;
     }
     if(!h0->pps_buffers[pps_id]) {
-        av_log(h->s.avctx, AV_LOG_ERROR, "non existing PPS referenced\n");
+        av_log(h->s.avctx, AV_LOG_ERROR, "non-existing PPS referenced\n");
         return -1;
     }
     h->pps= *h0->pps_buffers[pps_id];
 
     if(!h0->sps_buffers[h->pps.sps_id]) {
-        av_log(h->s.avctx, AV_LOG_ERROR, "non existing SPS referenced\n");
+        av_log(h->s.avctx, AV_LOG_ERROR, "non-existing SPS referenced\n");
         return -1;
     }
     h->sps = *h0->sps_buffers[h->pps.sps_id];
@@ -3936,11 +3685,11 @@
     h->b_stride=  s->mb_width*4;
     h->b8_stride= s->mb_width*2;
 
-    s->width = 16*s->mb_width - 2*(h->sps.crop_left + h->sps.crop_right );
+    s->width = 16*s->mb_width - 2*FFMIN(h->sps.crop_right, 7);
     if(h->sps.frame_mbs_only_flag)
-        s->height= 16*s->mb_height - 2*(h->sps.crop_top  + h->sps.crop_bottom);
+        s->height= 16*s->mb_height - 2*FFMIN(h->sps.crop_bottom, 7);
     else
-        s->height= 16*s->mb_height - 4*(h->sps.crop_top  + h->sps.crop_bottom); //FIXME recheck
+        s->height= 16*s->mb_height - 4*FFMIN(h->sps.crop_bottom, 3);
 
     if (s->context_initialized
         && (   s->width != s->avctx->width || s->height != s->avctx->height)) {
@@ -3962,7 +3711,7 @@
         for(i = 1; i < s->avctx->thread_count; i++) {
             H264Context *c;
             c = h->thread_context[i] = av_malloc(sizeof(H264Context));
-            memcpy(c, h, sizeof(MpegEncContext));
+            memcpy(c, h->s.thread_context[i], sizeof(MpegEncContext));
             memset(&c->s + 1, 0, sizeof(H264Context) - sizeof(MpegEncContext));
             c->sps = h->sps;
             c->pps = h->pps;
@@ -4004,8 +3753,19 @@
             h->mb_aff_frame = h->sps.mb_aff;
         }
     }
+    h->mb_field_decoding_flag= s->picture_structure != PICT_FRAME;
 
     if(h0->current_slice == 0){
+        while(h->frame_num !=  h->prev_frame_num &&
+              h->frame_num != (h->prev_frame_num+1)%(1<<h->sps.log2_max_frame_num)){
+            av_log(NULL, AV_LOG_DEBUG, "Frame num gap %d %d\n", h->frame_num, h->prev_frame_num);
+            frame_start(h);
+            h->prev_frame_num++;
+            h->prev_frame_num %= 1<<h->sps.log2_max_frame_num;
+            s->current_picture_ptr->frame_num= h->prev_frame_num;
+            execute_ref_pic_marking(h, NULL, 0);
+        }
+
         /* See if we have a decoded first field looking for a pair... */
         if (s0->first_field) {
             assert(s0->current_picture_ptr);
@@ -4101,21 +3861,19 @@
         h->redundant_pic_count= get_ue_golomb(&s->gb);
     }
 
-    //set defaults, might be overriden a few line later
+    //set defaults, might be overridden a few lines later
     h->ref_count[0]= h->pps.ref_count[0];
     h->ref_count[1]= h->pps.ref_count[1];
 
-    if(h->slice_type == P_TYPE || h->slice_type == SP_TYPE || h->slice_type == B_TYPE){
-        if(h->slice_type == B_TYPE){
+    if(h->slice_type_nos != FF_I_TYPE){
+        if(h->slice_type_nos == FF_B_TYPE){
             h->direct_spatial_mv_pred= get_bits1(&s->gb);
-            if(FIELD_OR_MBAFF_PICTURE && h->direct_spatial_mv_pred)
-                av_log(h->s.avctx, AV_LOG_ERROR, "Interlaced pictures + spatial direct mode is not implemented\n");
         }
         num_ref_idx_active_override_flag= get_bits1(&s->gb);
 
         if(num_ref_idx_active_override_flag){
             h->ref_count[0]= get_ue_golomb(&s->gb) + 1;
-            if(h->slice_type==B_TYPE)
+            if(h->slice_type_nos==FF_B_TYPE)
                 h->ref_count[1]= get_ue_golomb(&s->gb) + 1;
 
             if(h->ref_count[0]-1 > 32-1 || h->ref_count[1]-1 > 32-1){
@@ -4124,7 +3882,7 @@
                 return -1;
             }
         }
-        if(h->slice_type == B_TYPE)
+        if(h->slice_type_nos == FF_B_TYPE)
             h->list_count= 2;
         else
             h->list_count= 1;
@@ -4135,13 +3893,13 @@
         fill_default_ref_list(h);
     }
 
-    if(decode_ref_pic_list_reordering(h) < 0)
+    if(h->slice_type_nos!=FF_I_TYPE && decode_ref_pic_list_reordering(h) < 0)
         return -1;
 
-    if(   (h->pps.weighted_pred          && (h->slice_type == P_TYPE || h->slice_type == SP_TYPE ))
-       || (h->pps.weighted_bipred_idc==1 && h->slice_type==B_TYPE ) )
+    if(   (h->pps.weighted_pred          && h->slice_type_nos == FF_P_TYPE )
+       ||  (h->pps.weighted_bipred_idc==1 && h->slice_type_nos== FF_B_TYPE ) )
         pred_weight_table(h);
-    else if(h->pps.weighted_bipred_idc==2 && h->slice_type==B_TYPE)
+    else if(h->pps.weighted_bipred_idc==2 && h->slice_type_nos== FF_B_TYPE)
         implicit_weight_table(h);
     else
         h->use_weight = 0;
@@ -4152,7 +3910,7 @@
     if(FRAME_MBAFF)
         fill_mbaff_ref_list(h);
 
-    if( h->slice_type != I_TYPE && h->slice_type != SI_TYPE && h->pps.cabac ){
+    if( h->slice_type_nos != FF_I_TYPE && h->pps.cabac ){
         tmp = get_ue_golomb(&s->gb);
         if(tmp > 2){
             av_log(s->avctx, AV_LOG_ERROR, "cabac_init_idc overflow\n");
@@ -4171,10 +3929,10 @@
     h->chroma_qp[0] = get_chroma_qp(h, 0, s->qscale);
     h->chroma_qp[1] = get_chroma_qp(h, 1, s->qscale);
     //FIXME qscale / qp ... stuff
-    if(h->slice_type == SP_TYPE){
+    if(h->slice_type == FF_SP_TYPE){
         get_bits1(&s->gb); /* sp_for_switch_flag */
     }
-    if(h->slice_type==SP_TYPE || h->slice_type == SI_TYPE){
+    if(h->slice_type==FF_SP_TYPE || h->slice_type == FF_SI_TYPE){
         get_se_golomb(&s->gb); /* slice_qs_delta */
     }
 
@@ -4198,15 +3956,15 @@
     }
 
     if(   s->avctx->skip_loop_filter >= AVDISCARD_ALL
-       ||(s->avctx->skip_loop_filter >= AVDISCARD_NONKEY && h->slice_type != I_TYPE)
-       ||(s->avctx->skip_loop_filter >= AVDISCARD_BIDIR  && h->slice_type == B_TYPE)
+       ||(s->avctx->skip_loop_filter >= AVDISCARD_NONKEY && h->slice_type_nos != FF_I_TYPE)
+       ||(s->avctx->skip_loop_filter >= AVDISCARD_BIDIR  && h->slice_type_nos == FF_B_TYPE)
        ||(s->avctx->skip_loop_filter >= AVDISCARD_NONREF && h->nal_ref_idc == 0))
         h->deblocking_filter= 0;
 
     if(h->deblocking_filter == 1 && h0->max_contexts > 1) {
         if(s->avctx->flags2 & CODEC_FLAG2_FAST) {
             /* Cheat slightly for speed:
-               Dont bother to deblock across slices */
+               Do not bother to deblock across slices. */
             h->deblocking_filter = 2;
         } else {
             h0->max_contexts = 1;
@@ -4227,11 +3985,25 @@
     h0->last_slice_type = slice_type;
     h->slice_num = ++h0->current_slice;
 
+    for(j=0; j<2; j++){
+        int *ref2frm= h->ref2frm[h->slice_num&15][j];
+        ref2frm[0]=
+        ref2frm[1]= -1;
+        for(i=0; i<16; i++)
+            ref2frm[i+2]= 4*h->ref_list[j][i].frame_num
+                          +(h->ref_list[j][i].reference&3);
+        ref2frm[18+0]=
+        ref2frm[18+1]= -1;
+        for(i=16; i<48; i++)
+            ref2frm[i+4]= 4*h->ref_list[j][i].frame_num
+                          +(h->ref_list[j][i].reference&3);
+    }
+
     h->emu_edge_width= (s->flags&CODEC_FLAG_EMU_EDGE) ? 0 : 16;
     h->emu_edge_height= (FRAME_MBAFF || FIELD_PICTURE) ? 0 : h->emu_edge_width;
 
     if(s->avctx->debug&FF_DEBUG_PICT_INFO){
-        av_log(h->s.avctx, AV_LOG_DEBUG, "slice:%d %s mb:%d %c pps:%u frame:%d poc:%d/%d ref:%d/%d qp:%d loop:%d:%d:%d weight:%d%s\n",
+        av_log(h->s.avctx, AV_LOG_DEBUG, "slice:%d %s mb:%d %c pps:%u frame:%d poc:%d/%d ref:%d/%d qp:%d loop:%d:%d:%d weight:%d%s %s\n",
                h->slice_num,
                (s->picture_structure==PICT_FRAME ? "F" : s->picture_structure==PICT_TOP_FIELD ? "T" : "B"),
                first_mb_in_slice,
@@ -4242,18 +4014,11 @@
                s->qscale,
                h->deblocking_filter, h->slice_alpha_c0_offset/2, h->slice_beta_offset/2,
                h->use_weight,
-               h->use_weight==1 && h->use_weight_chroma ? "c" : ""
+               h->use_weight==1 && h->use_weight_chroma ? "c" : "",
+               h->slice_type == FF_B_TYPE ? (h->direct_spatial_mv_pred ? "SPAT" : "TEMP") : ""
                );
     }
 
-    if((s->avctx->flags2 & CODEC_FLAG2_FAST) && !h->nal_ref_idc){
-        s->me.qpel_put= s->dsp.put_2tap_qpel_pixels_tab;
-        s->me.qpel_avg= s->dsp.avg_2tap_qpel_pixels_tab;
-    }else{
-        s->me.qpel_put= s->dsp.put_h264_qpel_pixels_tab;
-        s->me.qpel_avg= s->dsp.avg_h264_qpel_pixels_tab;
-    }
-
     return 0;
 }
 
@@ -4354,12 +4119,11 @@
                 level_code= (prefix<<suffix_length) + get_bits(gb, suffix_length); //part
             else
                 level_code= prefix + get_bits(gb, 4); //part
-        }else if(prefix==15){
-            level_code= (prefix<<suffix_length) + get_bits(gb, 12); //part
-            if(suffix_length==0) level_code+=15; //FIXME doesn't make (much)sense
         }else{
-            av_log(h->s.avctx, AV_LOG_ERROR, "prefix too large at %d %d\n", s->mb_x, s->mb_y);
-            return -1;
+            level_code= (15<<suffix_length) + get_bits(gb, prefix-3); //part
+            if(suffix_length==0) level_code+=15; //FIXME doesn't make (much)sense
+            if(prefix>=16)
+                level_code += (1<<(prefix-3))-4096;
         }
 
         if(trailing_ones < 3) level_code += 2;
@@ -4377,11 +4141,10 @@
             prefix = get_level_prefix(gb);
             if(prefix<15){
                 level_code = (prefix<<suffix_length) + get_bits(gb, suffix_length);
-            }else if(prefix==15){
-                level_code =  (prefix<<suffix_length) + get_bits(gb, 12);
             }else{
-                av_log(h->s.avctx, AV_LOG_ERROR, "prefix too large at %d %d\n", s->mb_x, s->mb_y);
-                return -1;
+                level_code = (15<<suffix_length) + get_bits(gb, prefix-3);
+                if(prefix>=16)
+                    level_code += (1<<(prefix-3))-4096;
             }
             mask= -(level_code&1);
             level[i]= (((2+level_code)>>1) ^ mask) - mask;
@@ -4445,7 +4208,7 @@
 
 static void predict_field_decoding_flag(H264Context *h){
     MpegEncContext * const s = &h->s;
-    const int mb_xy= s->mb_x + s->mb_y*s->mb_stride;
+    const int mb_xy= h->mb_xy;
     int mb_type = (h->slice_table[mb_xy-1] == h->slice_num)
                 ? s->current_picture.mb_type[mb_xy-1]
                 : (h->slice_table[mb_xy-s->mb_stride] == h->slice_num)
@@ -4459,7 +4222,7 @@
  */
 static void decode_mb_skip(H264Context *h){
     MpegEncContext * const s = &h->s;
-    const int mb_xy= s->mb_x + s->mb_y*s->mb_stride;
+    const int mb_xy= h->mb_xy;
     int mb_type=0;
 
     memset(h->non_zero_count[mb_xy], 0, 16);
@@ -4468,10 +4231,10 @@
     if(MB_FIELD)
         mb_type|= MB_TYPE_INTERLACED;
 
-    if( h->slice_type == B_TYPE )
+    if( h->slice_type_nos == FF_B_TYPE )
     {
         // just for fill_caches. pred_direct_motion will set the real mb_type
-        mb_type|= MB_TYPE_16x16|MB_TYPE_P0L0|MB_TYPE_P0L1|MB_TYPE_DIRECT2|MB_TYPE_SKIP;
+        mb_type|= MB_TYPE_P0L0|MB_TYPE_P0L1|MB_TYPE_DIRECT2|MB_TYPE_SKIP;
 
         fill_caches(h, mb_type, 0); //FIXME check what is needed and what not ...
         pred_direct_motion(h, &mb_type);
@@ -4497,21 +4260,23 @@
 
 /**
  * decodes a macroblock
- * @returns 0 if ok, AC_ERROR / DC_ERROR / MV_ERROR if an error is noticed
+ * @returns 0 if OK, AC_ERROR / DC_ERROR / MV_ERROR if an error is noticed
  */
 static int decode_mb_cavlc(H264Context *h){
     MpegEncContext * const s = &h->s;
-    const int mb_xy= s->mb_x + s->mb_y*s->mb_stride;
+    int mb_xy;
     int partition_count;
     unsigned int mb_type, cbp;
     int dct8x8_allowed= h->pps.transform_8x8_mode;
 
+    mb_xy = h->mb_xy = s->mb_x + s->mb_y*s->mb_stride;
+
     s->dsp.clear_blocks(h->mb); //FIXME avoid if already clear (move after skip handlong?
 
     tprintf(s->avctx, "pic:%d mb:%d/%d\n", h->frame_num, s->mb_x, s->mb_y);
     cbp = 0; /* avoid warning. FIXME: find a solution without slowing
                 down the code */
-    if(h->slice_type != I_TYPE && h->slice_type != SI_TYPE){
+    if(h->slice_type_nos != FF_I_TYPE){
         if(s->mb_skip_run==-1)
             s->mb_skip_run= get_ue_golomb(&s->gb);
 
@@ -4529,13 +4294,12 @@
     if(FRAME_MBAFF){
         if( (s->mb_y&1) == 0 )
             h->mb_mbaff = h->mb_field_decoding_flag = get_bits1(&s->gb);
-    }else
-        h->mb_field_decoding_flag= (s->picture_structure!=PICT_FRAME);
+    }
 
     h->prev_mb_skipped= 0;
 
     mb_type= get_ue_golomb(&s->gb);
-    if(h->slice_type == B_TYPE){
+    if(h->slice_type_nos == FF_B_TYPE){
         if(mb_type < 23){
             partition_count= b_mb_type_info[mb_type].partition_count;
             mb_type=         b_mb_type_info[mb_type].type;
@@ -4543,7 +4307,7 @@
             mb_type -= 23;
             goto decode_intra_mb;
         }
-    }else if(h->slice_type == P_TYPE /*|| h->slice_type == SP_TYPE */){
+    }else if(h->slice_type_nos == FF_P_TYPE){
         if(mb_type < 5){
             partition_count= p_mb_type_info[mb_type].partition_count;
             mb_type=         p_mb_type_info[mb_type].type;
@@ -4552,7 +4316,9 @@
             goto decode_intra_mb;
         }
     }else{
-       assert(h->slice_type == I_TYPE);
+       assert(h->slice_type_nos == FF_I_TYPE);
+        if(h->slice_type == FF_SI_TYPE && mb_type)
+            mb_type--;
 decode_intra_mb:
         if(mb_type > 25){
             av_log(h->s.avctx, AV_LOG_ERROR, "mb_type %d in %c slice too large at %d %d\n", mb_type, av_get_pict_type_char(h->slice_type), s->mb_x, s->mb_y);
@@ -4570,38 +4336,18 @@
     h->slice_table[ mb_xy ]= h->slice_num;
 
     if(IS_INTRA_PCM(mb_type)){
-        unsigned int x, y;
+        unsigned int x;
 
         // We assume these blocks are very rare so we do not optimize it.
         align_get_bits(&s->gb);
 
         // The pixels are stored in the same order as levels in h->mb array.
-        for(y=0; y<16; y++){
-            const int index= 4*(y&3) + 32*((y>>2)&1) + 128*(y>>3);
-            for(x=0; x<16; x++){
-                tprintf(s->avctx, "LUMA ICPM LEVEL (%3d)\n", show_bits(&s->gb, 8));
-                h->mb[index + (x&3) + 16*((x>>2)&1) + 64*(x>>3)]= get_bits(&s->gb, 8);
-            }
+        for(x=0; x < (CHROMA ? 384 : 256); x++){
+            ((uint8_t*)h->mb)[x]= get_bits(&s->gb, 8);
         }
-        for(y=0; y<8; y++){
-            const int index= 256 + 4*(y&3) + 32*(y>>2);
-            for(x=0; x<8; x++){
-                tprintf(s->avctx, "CHROMA U ICPM LEVEL (%3d)\n", show_bits(&s->gb, 8));
-                h->mb[index + (x&3) + 16*(x>>2)]= get_bits(&s->gb, 8);
-            }
-        }
-        for(y=0; y<8; y++){
-            const int index= 256 + 64 + 4*(y&3) + 32*(y>>2);
-            for(x=0; x<8; x++){
-                tprintf(s->avctx, "CHROMA V ICPM LEVEL (%3d)\n", show_bits(&s->gb, 8));
-                h->mb[index + (x&3) + 16*(x>>2)]= get_bits(&s->gb, 8);
-            }
-        }
 
         // In deblocking, the quantizer is 0
         s->current_picture.qscale_table[mb_xy]= 0;
-        h->chroma_qp[0] = get_chroma_qp(h, 0, 0);
-        h->chroma_qp[1] = get_chroma_qp(h, 1, 0);
         // All coeffs are present
         memset(h->non_zero_count[mb_xy], 16, 16);
 
@@ -4618,47 +4364,48 @@
 
     //mb_pred
     if(IS_INTRA(mb_type)){
-            int pred_mode;
+        int pred_mode;
 //            init_top_left_availability(h);
-            if(IS_INTRA4x4(mb_type)){
-                int i;
-                int di = 1;
-                if(dct8x8_allowed && get_bits1(&s->gb)){
-                    mb_type |= MB_TYPE_8x8DCT;
-                    di = 4;
-                }
+        if(IS_INTRA4x4(mb_type)){
+            int i;
+            int di = 1;
+            if(dct8x8_allowed && get_bits1(&s->gb)){
+                mb_type |= MB_TYPE_8x8DCT;
+                di = 4;
+            }
 
 //                fill_intra4x4_pred_table(h);
-                for(i=0; i<16; i+=di){
-                    int mode= pred_intra_mode(h, i);
+            for(i=0; i<16; i+=di){
+                int mode= pred_intra_mode(h, i);
 
-                    if(!get_bits1(&s->gb)){
-                        const int rem_mode= get_bits(&s->gb, 3);
-                        mode = rem_mode + (rem_mode >= mode);
-                    }
-
-                    if(di==4)
-                        fill_rectangle( &h->intra4x4_pred_mode_cache[ scan8[i] ], 2, 2, 8, mode, 1 );
-                    else
-                        h->intra4x4_pred_mode_cache[ scan8[i] ] = mode;
+                if(!get_bits1(&s->gb)){
+                    const int rem_mode= get_bits(&s->gb, 3);
+                    mode = rem_mode + (rem_mode >= mode);
                 }
-                write_back_intra_pred_mode(h);
-                if( check_intra4x4_pred_mode(h) < 0)
-                    return -1;
-            }else{
-                h->intra16x16_pred_mode= check_intra_pred_mode(h, h->intra16x16_pred_mode);
-                if(h->intra16x16_pred_mode < 0)
-                    return -1;
-            }
 
+                if(di==4)
+                    fill_rectangle( &h->intra4x4_pred_mode_cache[ scan8[i] ], 2, 2, 8, mode, 1 );
+                else
+                    h->intra4x4_pred_mode_cache[ scan8[i] ] = mode;
+            }
+            write_back_intra_pred_mode(h);
+            if( check_intra4x4_pred_mode(h) < 0)
+                return -1;
+        }else{
+            h->intra16x16_pred_mode= check_intra_pred_mode(h, h->intra16x16_pred_mode);
+            if(h->intra16x16_pred_mode < 0)
+                return -1;
+        }
+        if(CHROMA){
             pred_mode= check_intra_pred_mode(h, get_ue_golomb(&s->gb));
             if(pred_mode < 0)
                 return -1;
             h->chroma_pred_mode= pred_mode;
+        }
     }else if(partition_count==4){
         int i, j, sub_partition_count[4], list, ref[2][4];
 
-        if(h->slice_type == B_TYPE){
+        if(h->slice_type_nos == FF_B_TYPE){
             for(i=0; i<4; i++){
                 h->sub_mb_type[i]= get_ue_golomb(&s->gb);
                 if(h->sub_mb_type[i] >=13){
@@ -4677,7 +4424,7 @@
                 h->ref_cache[1][scan8[12]] = PART_NOT_AVAILABLE;
             }
         }else{
-            assert(h->slice_type == P_TYPE || h->slice_type == SP_TYPE); //FIXME SP correct ?
+            assert(h->slice_type_nos == FF_P_TYPE); //FIXME SP correct ?
             for(i=0; i<4; i++){
                 h->sub_mb_type[i]= get_ue_golomb(&s->gb);
                 if(h->sub_mb_type[i] >=4){
@@ -4860,16 +4607,21 @@
             return -1;
         }
 
-        if(IS_INTRA4x4(mb_type))
-            cbp= golomb_to_intra4x4_cbp[cbp];
-        else
-            cbp= golomb_to_inter_cbp[cbp];
+        if(CHROMA){
+            if(IS_INTRA4x4(mb_type)) cbp= golomb_to_intra4x4_cbp[cbp];
+            else                     cbp= golomb_to_inter_cbp   [cbp];
+        }else{
+            if(IS_INTRA4x4(mb_type)) cbp= golomb_to_intra4x4_cbp_gray[cbp];
+            else                     cbp= golomb_to_inter_cbp_gray[cbp];
+        }
     }
     h->cbp = cbp;
 
     if(dct8x8_allowed && (cbp&15) && !IS_INTRA(mb_type)){
-        if(get_bits1(&s->gb))
+        if(get_bits1(&s->gb)){
             mb_type |= MB_TYPE_8x8DCT;
+            h->cbp_table[mb_xy]= cbp;
+        }
     }
     s->current_picture.mb_type[mb_xy]= mb_type;
 
@@ -5048,9 +4800,9 @@
 static int decode_cabac_mb_type( H264Context *h ) {
     MpegEncContext * const s = &h->s;
 
-    if( h->slice_type == I_TYPE ) {
+    if( h->slice_type_nos == FF_I_TYPE ) {
         return decode_cabac_intra_mb_type(h, 3, 1);
-    } else if( h->slice_type == P_TYPE ) {
+    } else if( h->slice_type_nos == FF_P_TYPE ) {
         if( get_cabac_noinline( &h->cabac, &h->cabac_state[14] ) == 0 ) {
             /* P-type */
             if( get_cabac_noinline( &h->cabac, &h->cabac_state[15] ) == 0 ) {
@@ -5063,7 +4815,7 @@
         } else {
             return decode_cabac_intra_mb_type(h, 17, 0) + 5;
         }
-    } else if( h->slice_type == B_TYPE ) {
+    } else if( h->slice_type_nos == FF_B_TYPE ) {
         const int mba_xy = h->left_mb_xy[0];
         const int mbb_xy = h->top_mb_xy;
         int ctx = 0;
@@ -5123,7 +4875,7 @@
         }else
             mbb_xy = mb_x + (mb_y-1)*s->mb_stride;
     }else{
-        int mb_xy = mb_x + mb_y*s->mb_stride;
+        int mb_xy = h->mb_xy;
         mba_xy = mb_xy - 1;
         mbb_xy = mb_xy - (s->mb_stride << FIELD_PICTURE);
     }
@@ -5133,7 +4885,7 @@
     if( h->slice_table[mbb_xy] == h->slice_num && !IS_SKIP( s->current_picture.mb_type[mbb_xy] ))
         ctx++;
 
-    if( h->slice_type == B_TYPE )
+    if( h->slice_type_nos == FF_B_TYPE )
         ctx += 13;
     return get_cabac_noinline( &h->cabac, &h->cabac_state[11+ctx] );
 }
@@ -5270,7 +5022,7 @@
     int ref  = 0;
     int ctx  = 0;
 
-    if( h->slice_type == B_TYPE) {
+    if( h->slice_type_nos == FF_B_TYPE) {
         if( refa > 0 && !h->direct_cache[scan8[n] - 1] )
             ctx++;
         if( refb > 0 && !h->direct_cache[scan8[n] - 8] )
@@ -5338,23 +5090,27 @@
     return get_cabac_bypass_sign( &h->cabac, -mvd );
 }
 
-static inline int get_cabac_cbf_ctx( H264Context *h, int cat, int idx ) {
+static av_always_inline int get_cabac_cbf_ctx( H264Context *h, int cat, int idx, int is_dc ) {
     int nza, nzb;
     int ctx = 0;
 
-    if( cat == 0 ) {
-        nza = h->left_cbp&0x100;
-        nzb = h-> top_cbp&0x100;
-    } else if( cat == 1 || cat == 2 ) {
-        nza = h->non_zero_count_cache[scan8[idx] - 1];
-        nzb = h->non_zero_count_cache[scan8[idx] - 8];
-    } else if( cat == 3 ) {
-        nza = (h->left_cbp>>(6+idx))&0x01;
-        nzb = (h-> top_cbp>>(6+idx))&0x01;
+    if( is_dc ) {
+        if( cat == 0 ) {
+            nza = h->left_cbp&0x100;
+            nzb = h-> top_cbp&0x100;
+        } else {
+            nza = (h->left_cbp>>(6+idx))&0x01;
+            nzb = (h-> top_cbp>>(6+idx))&0x01;
+        }
     } else {
-        assert(cat == 4);
-        nza = h->non_zero_count_cache[scan8[16+idx] - 1];
-        nzb = h->non_zero_count_cache[scan8[16+idx] - 8];
+        if( cat == 4 ) {
+            nza = h->non_zero_count_cache[scan8[16+idx] - 1];
+            nzb = h->non_zero_count_cache[scan8[16+idx] - 8];
+        } else {
+            assert(cat == 1 || cat == 2);
+            nza = h->non_zero_count_cache[scan8[idx] - 1];
+            nzb = h->non_zero_count_cache[scan8[idx] - 8];
+        }
     }
 
     if( nza > 0 )
@@ -5366,15 +5122,14 @@
     return ctx + 4 * cat;
 }
 
-static const attribute_used uint8_t last_coeff_flag_offset_8x8[63] = {
+DECLARE_ASM_CONST(1, uint8_t, last_coeff_flag_offset_8x8[63]) = {
     0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
     2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
     3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,
     5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7, 8, 8, 8
 };
 
-static void decode_cabac_residual( H264Context *h, DCTELEM *block, int cat, int n, const uint8_t *scantable, const uint32_t *qmul, int max_coeff) {
-    const int mb_xy  = h->s.mb_x + h->s.mb_y*h->s.mb_stride;
+static av_always_inline void decode_cabac_residual_internal( H264Context *h, DCTELEM *block, int cat, int n, const uint8_t *scantable, const uint32_t *qmul, int max_coeff, int is_dc ) {
     static const int significant_coeff_flag_offset[2][6] = {
       { 105+0, 105+15, 105+29, 105+44, 105+47, 402 },
       { 277+0, 277+15, 277+29, 277+44, 277+47, 436 }
@@ -5396,15 +5151,25 @@
         9, 9,10,10, 8,11,12,11, 9, 9,10,10, 8,13,13, 9,
         9,10,10, 8,13,13, 9, 9,10,10,14,14,14,14,14 }
     };
+    /* node ctx: 0..3: abslevel1 (with abslevelgt1 == 0).
+     * 4..7: abslevelgt1 + 3 (and abslevel1 doesn't matter).
+     * map node ctx => cabac ctx for level=1 */
+    static const uint8_t coeff_abs_level1_ctx[8] = { 1, 2, 3, 4, 0, 0, 0, 0 };
+    /* map node ctx => cabac ctx for level>1 */
+    static const uint8_t coeff_abs_levelgt1_ctx[8] = { 5, 5, 5, 5, 6, 7, 8, 9 };
+    static const uint8_t coeff_abs_level_transition[2][8] = {
+    /* update node ctx after decoding a level=1 */
+        { 1, 2, 3, 3, 4, 5, 6, 7 },
+    /* update node ctx after decoding a level>1 */
+        { 4, 4, 4, 4, 5, 6, 7, 7 }
+    };
 
     int index[64];
 
     int av_unused last;
     int coeff_count = 0;
+    int node_ctx = 0;
 
-    int abslevel1 = 1;
-    int abslevelgt1 = 0;
-
     uint8_t *significant_coeff_ctx_base;
     uint8_t *last_coeff_ctx_base;
     uint8_t *abs_level_m1_ctx_base;
@@ -5432,12 +5197,15 @@
      */
 
     /* read coded block flag */
-    if( cat != 5 ) {
-        if( get_cabac( CC, &h->cabac_state[85 + get_cabac_cbf_ctx( h, cat, n ) ] ) == 0 ) {
-            if( cat == 1 || cat == 2 )
-                h->non_zero_count_cache[scan8[n]] = 0;
-            else if( cat == 4 )
-                h->non_zero_count_cache[scan8[16+n]] = 0;
+    if( is_dc || cat != 5 ) {
+        if( get_cabac( CC, &h->cabac_state[85 + get_cabac_cbf_ctx( h, cat, n, is_dc ) ] ) == 0 ) {
+            if( !is_dc ) {
+                if( cat == 4 )
+                    h->non_zero_count_cache[scan8[16+n]] = 0;
+                else
+                    h->non_zero_count_cache[scan8[n]] = 0;
+            }
+
 #ifdef CABAC_ON_STACK
             h->cabac.range     = cc.range     ;
             h->cabac.low       = cc.low       ;
@@ -5454,7 +5222,7 @@
     abs_level_m1_ctx_base = h->cabac_state
         + coeff_abs_level_m1_offset[cat];
 
-    if( cat == 5 ) {
+    if( !is_dc && cat == 5 ) {
 #define DECODE_SIGNIFICANCE( coefs, sig_off, last_off ) \
         for(last= 0; last < coefs; last++) { \
             uint8_t *sig_ctx = significant_coeff_ctx_base + sig_off; \
@@ -5483,34 +5251,39 @@
     }
     assert(coeff_count > 0);
 
-    if( cat == 0 )
-        h->cbp_table[mb_xy] |= 0x100;
-    else if( cat == 1 || cat == 2 )
-        h->non_zero_count_cache[scan8[n]] = coeff_count;
-    else if( cat == 3 )
-        h->cbp_table[mb_xy] |= 0x40 << n;
-    else if( cat == 4 )
-        h->non_zero_count_cache[scan8[16+n]] = coeff_count;
-    else {
-        assert( cat == 5 );
-        fill_rectangle(&h->non_zero_count_cache[scan8[n]], 2, 2, 8, coeff_count, 1);
+    if( is_dc ) {
+        if( cat == 0 )
+            h->cbp_table[h->mb_xy] |= 0x100;
+        else
+            h->cbp_table[h->mb_xy] |= 0x40 << n;
+    } else {
+        if( cat == 5 )
+            fill_rectangle(&h->non_zero_count_cache[scan8[n]], 2, 2, 8, coeff_count, 1);
+        else if( cat == 4 )
+            h->non_zero_count_cache[scan8[16+n]] = coeff_count;
+        else {
+            assert( cat == 1 || cat == 2 );
+            h->non_zero_count_cache[scan8[n]] = coeff_count;
+        }
     }
 
-    for( coeff_count--; coeff_count >= 0; coeff_count-- ) {
-        uint8_t *ctx = (abslevelgt1 != 0 ? 0 : FFMIN( 4, abslevel1 )) + abs_level_m1_ctx_base;
-        int j= scantable[index[coeff_count]];
+    do {
+        uint8_t *ctx = coeff_abs_level1_ctx[node_ctx] + abs_level_m1_ctx_base;
 
+        int j= scantable[index[--coeff_count]];
+
         if( get_cabac( CC, ctx ) == 0 ) {
-            if( !qmul ) {
+            node_ctx = coeff_abs_level_transition[0][node_ctx];
+            if( is_dc ) {
                 block[j] = get_cabac_bypass_sign( CC, -1);
             }else{
-                block[j] = (get_cabac_bypass_sign( CC, -qmul[j]) + 32) >> 6;;
+                block[j] = (get_cabac_bypass_sign( CC, -qmul[j]) + 32) >> 6;
             }
-
-            abslevel1++;
         } else {
             int coeff_abs = 2;
-            ctx = 5 + FFMIN( 4, abslevelgt1 ) + abs_level_m1_ctx_base;
+            ctx = coeff_abs_levelgt1_ctx[node_ctx] + abs_level_m1_ctx_base;
+            node_ctx = coeff_abs_level_transition[1][node_ctx];
+
             while( coeff_abs < 15 && get_cabac( CC, ctx ) ) {
                 coeff_abs++;
             }
@@ -5528,17 +5301,13 @@
                 coeff_abs+= 14;
             }
 
-            if( !qmul ) {
-                if( get_cabac_bypass( CC ) ) block[j] = -coeff_abs;
-                else                                block[j] =  coeff_abs;
+            if( is_dc ) {
+                block[j] = get_cabac_bypass_sign( CC, -coeff_abs );
             }else{
-                if( get_cabac_bypass( CC ) ) block[j] = (-coeff_abs * qmul[j] + 32) >> 6;
-                else                                block[j] = ( coeff_abs * qmul[j] + 32) >> 6;
+                block[j] = (get_cabac_bypass_sign( CC, -coeff_abs ) * qmul[j] + 32) >> 6;
             }
-
-            abslevelgt1++;
         }
-    }
+    } while( coeff_count );
 #ifdef CABAC_ON_STACK
             h->cabac.range     = cc.range     ;
             h->cabac.low       = cc.low       ;
@@ -5547,10 +5316,29 @@
 
 }
 
+#ifndef CONFIG_SMALL
+static void decode_cabac_residual_dc( H264Context *h, DCTELEM *block, int cat, int n, const uint8_t *scantable, const uint32_t *qmul, int max_coeff ) {
+    decode_cabac_residual_internal(h, block, cat, n, scantable, qmul, max_coeff, 1);
+}
+
+static void decode_cabac_residual_nondc( H264Context *h, DCTELEM *block, int cat, int n, const uint8_t *scantable, const uint32_t *qmul, int max_coeff ) {
+    decode_cabac_residual_internal(h, block, cat, n, scantable, qmul, max_coeff, 0);
+}
+#endif
+
+static void decode_cabac_residual( H264Context *h, DCTELEM *block, int cat, int n, const uint8_t *scantable, const uint32_t *qmul, int max_coeff ) {
+#ifdef CONFIG_SMALL
+    decode_cabac_residual_internal(h, block, cat, n, scantable, qmul, max_coeff, cat == 0 || cat == 3);
+#else
+    if( cat == 0 || cat == 3 ) decode_cabac_residual_dc(h, block, cat, n, scantable, qmul, max_coeff);
+    else decode_cabac_residual_nondc(h, block, cat, n, scantable, qmul, max_coeff);
+#endif
+}
+
 static inline void compute_mb_neighbors(H264Context *h)
 {
     MpegEncContext * const s = &h->s;
-    const int mb_xy  = s->mb_x + s->mb_y*s->mb_stride;
+    const int mb_xy  = h->mb_xy;
     h->top_mb_xy     = mb_xy - s->mb_stride;
     h->left_mb_xy[0] = mb_xy - 1;
     if(FRAME_MBAFF){
@@ -5577,18 +5365,20 @@
 
 /**
  * decodes a macroblock
- * @returns 0 if ok, AC_ERROR / DC_ERROR / MV_ERROR if an error is noticed
+ * @returns 0 if OK, AC_ERROR / DC_ERROR / MV_ERROR if an error is noticed
  */
 static int decode_mb_cabac(H264Context *h) {
     MpegEncContext * const s = &h->s;
-    const int mb_xy= s->mb_x + s->mb_y*s->mb_stride;
+    int mb_xy;
     int mb_type, partition_count, cbp = 0;
     int dct8x8_allowed= h->pps.transform_8x8_mode;
 
+    mb_xy = h->mb_xy = s->mb_x + s->mb_y*s->mb_stride;
+
     s->dsp.clear_blocks(h->mb); //FIXME avoid if already clear (move after skip handlong?)
 
     tprintf(s->avctx, "pic:%d mb:%d/%d\n", h->frame_num, s->mb_x, s->mb_y);
-    if( h->slice_type != I_TYPE && h->slice_type != SI_TYPE ) {
+    if( h->slice_type_nos != FF_I_TYPE ) {
         int skip;
         /* a skipped mb needs the aff flag from the following mb */
         if( FRAME_MBAFF && s->mb_x==0 && (s->mb_y&1)==0 )
@@ -5622,8 +5412,7 @@
         if( (s->mb_y&1) == 0 )
             h->mb_mbaff =
             h->mb_field_decoding_flag = decode_cabac_field_decoding_flag(h);
-    }else
-        h->mb_field_decoding_flag= (s->picture_structure!=PICT_FRAME);
+    }
 
     h->prev_mb_skipped = 0;
 
@@ -5633,7 +5422,7 @@
         return -1;
     }
 
-    if( h->slice_type == B_TYPE ) {
+    if( h->slice_type_nos == FF_B_TYPE ) {
         if( mb_type < 23 ){
             partition_count= b_mb_type_info[mb_type].partition_count;
             mb_type=         b_mb_type_info[mb_type].type;
@@ -5641,7 +5430,7 @@
             mb_type -= 23;
             goto decode_intra_mb;
         }
-    } else if( h->slice_type == P_TYPE ) {
+    } else if( h->slice_type_nos == FF_P_TYPE ) {
         if( mb_type < 5) {
             partition_count= p_mb_type_info[mb_type].partition_count;
             mb_type=         p_mb_type_info[mb_type].type;
@@ -5650,7 +5439,9 @@
             goto decode_intra_mb;
         }
     } else {
-       assert(h->slice_type == I_TYPE);
+        if(h->slice_type == FF_SI_TYPE && mb_type)
+            mb_type--;
+        assert(h->slice_type_nos == FF_I_TYPE);
 decode_intra_mb:
         partition_count = 0;
         cbp= i_mb_type_info[mb_type].cbp;
@@ -5664,7 +5455,6 @@
 
     if(IS_INTRA_PCM(mb_type)) {
         const uint8_t *ptr;
-        unsigned int x, y;
 
         // We assume these blocks are very rare so we do not optimize it.
         // FIXME The two following lines get the bitstream position in the cabac
@@ -5676,27 +5466,10 @@
         }
 
         // The pixels are stored in the same order as levels in h->mb array.
-        for(y=0; y<16; y++){
-            const int index= 4*(y&3) + 32*((y>>2)&1) + 128*(y>>3);
-            for(x=0; x<16; x++){
-                tprintf(s->avctx, "LUMA ICPM LEVEL (%3d)\n", *ptr);
-                h->mb[index + (x&3) + 16*((x>>2)&1) + 64*(x>>3)]= *ptr++;
-            }
+        memcpy(h->mb, ptr, 256); ptr+=256;
+        if(CHROMA){
+            memcpy(h->mb+128, ptr, 128); ptr+=128;
         }
-        for(y=0; y<8; y++){
-            const int index= 256 + 4*(y&3) + 32*(y>>2);
-            for(x=0; x<8; x++){
-                tprintf(s->avctx, "CHROMA U ICPM LEVEL (%3d)\n", *ptr);
-                h->mb[index + (x&3) + 16*(x>>2)]= *ptr++;
-            }
-        }
-        for(y=0; y<8; y++){
-            const int index= 256 + 64 + 4*(y&3) + 32*(y>>2);
-            for(x=0; x<8; x++){
-                tprintf(s->avctx, "CHROMA V ICPM LEVEL (%3d)\n", *ptr);
-                h->mb[index + (x&3) + 16*(x>>2)]= *ptr++;
-            }
-        }
 
         ff_init_cabac_decoder(&h->cabac, ptr, h->cabac.bytestream_end - ptr);
 
@@ -5705,11 +5478,10 @@
         h->chroma_pred_mode_table[mb_xy] = 0;
         // In deblocking, the quantizer is 0
         s->current_picture.qscale_table[mb_xy]= 0;
-        h->chroma_qp[0] = get_chroma_qp(h, 0, 0);
-        h->chroma_qp[1] = get_chroma_qp(h, 1, 0);
         // All coeffs are present
         memset(h->non_zero_count[mb_xy], 16, 16);
         s->current_picture.mb_type[mb_xy]= mb_type;
+        h->last_qscale_diff = 0;
         return 0;
     }
 
@@ -5744,16 +5516,18 @@
             h->intra16x16_pred_mode= check_intra_pred_mode( h, h->intra16x16_pred_mode );
             if( h->intra16x16_pred_mode < 0 ) return -1;
         }
-        h->chroma_pred_mode_table[mb_xy] =
-        pred_mode                        = decode_cabac_mb_chroma_pre_mode( h );
+        if(CHROMA){
+            h->chroma_pred_mode_table[mb_xy] =
+            pred_mode                        = decode_cabac_mb_chroma_pre_mode( h );
 
-        pred_mode= check_intra_pred_mode( h, pred_mode );
-        if( pred_mode < 0 ) return -1;
-        h->chroma_pred_mode= pred_mode;
+            pred_mode= check_intra_pred_mode( h, pred_mode );
+            if( pred_mode < 0 ) return -1;
+            h->chroma_pred_mode= pred_mode;
+        }
     } else if( partition_count == 4 ) {
         int i, j, sub_partition_count[4], list, ref[2][4];
 
-        if( h->slice_type == B_TYPE ) {
+        if( h->slice_type_nos == FF_B_TYPE ) {
             for( i = 0; i < 4; i++ ) {
                 h->sub_mb_type[i] = decode_cabac_b_mb_sub_type( h );
                 sub_partition_count[i]= b_sub_mb_type_info[ h->sub_mb_type[i] ].partition_count;
@@ -5951,7 +5725,8 @@
 
     if( !IS_INTRA16x16( mb_type ) ) {
         cbp  = decode_cabac_mb_cbp_luma( h );
-        cbp |= decode_cabac_mb_cbp_chroma( h ) << 4;
+        if(CHROMA)
+            cbp |= decode_cabac_mb_cbp_chroma( h ) << 4;
     }
 
     h->cbp_table[mb_xy] = h->cbp = cbp;
@@ -6381,9 +6156,10 @@
     int mb_xy, mb_type;
     int qp, qp0, qp1, qpc, qpc0, qpc1, qp_thresh;
 
-    mb_xy = mb_x + mb_y*s->mb_stride;
+    mb_xy = h->mb_xy;
 
     if(mb_x==0 || mb_y==mb_y_firstrow || !s->dsp.h264_loop_filter_strength || h->pps.chroma_qp_diff ||
+1 ||
        (h->deblocking_filter == 2 && (h->slice_table[mb_xy] != h->slice_table[h->top_mb_xy] ||
                                       h->slice_table[mb_xy] != h->slice_table[mb_xy - 1]))) {
         filter_mb(h, mb_x, mb_y, img_y, img_cb, img_cr, linesize, uvlinesize);
@@ -6451,7 +6227,7 @@
             int step = IS_8x8DCT(mb_type) ? 2 : 1;
             edges = (mb_type & MB_TYPE_16x16) && !(h->cbp & 15) ? 1 : 4;
             s->dsp.h264_loop_filter_strength( bS, h->non_zero_count_cache, h->ref_cache, h->mv_cache,
-                                              (h->slice_type == B_TYPE), edges, step, mask_edge0, mask_edge1 );
+                                              (h->slice_type_nos == FF_B_TYPE), edges, step, mask_edge0, mask_edge1, FIELD_PICTURE);
         }
         if( IS_INTRA(s->current_picture.mb_type[mb_xy-1]) )
             bSv[0][0] = 0x0004000400040004ULL;
@@ -6495,16 +6271,11 @@
     const int mvy_limit = IS_INTERLACED(mb_type) ? 2 : 4;
     int first_vertical_edge_done = 0;
     int dir;
-    /* FIXME: A given frame may occupy more than one position in
-     * the reference list. So ref2frm should be populated with
-     * frame numbers, not indices. */
-    static const int ref2frm[34] = {-1,-1,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,
-                                    16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31};
 
     //for sufficiently low qp, filtering wouldn't do anything
     //this is a conservative estimate: could also check beta_offset and more accurate chroma_qp
     if(!FRAME_MBAFF){
-        int qp_thresh = 15 - h->slice_alpha_c0_offset - FFMAX(0, FFMAX(h->pps.chroma_qp_index_offset[0], h->pps.chroma_qp_index_offset[1]));
+        int qp_thresh = 15 - h->slice_alpha_c0_offset - FFMAX3(0, h->pps.chroma_qp_index_offset[0], h->pps.chroma_qp_index_offset[1]);
         int qp = s->current_picture.qscale_table[mb_xy];
         if(qp <= qp_thresh
            && (mb_x == 0 || ((qp + s->current_picture.qscale_table[mb_xy-1] + 1)>>1) <= qp_thresh)
@@ -6513,6 +6284,43 @@
         }
     }
 
+    // CAVLC 8x8dct requires NNZ values for residual decoding that differ from what the loop filter needs
+    if(!h->pps.cabac && h->pps.transform_8x8_mode){
+        int top_type, left_type[2];
+        top_type     = s->current_picture.mb_type[h->top_mb_xy]    ;
+        left_type[0] = s->current_picture.mb_type[h->left_mb_xy[0]];
+        left_type[1] = s->current_picture.mb_type[h->left_mb_xy[1]];
+
+        if(IS_8x8DCT(top_type)){
+            h->non_zero_count_cache[4+8*0]=
+            h->non_zero_count_cache[5+8*0]= h->cbp_table[h->top_mb_xy] & 4;
+            h->non_zero_count_cache[6+8*0]=
+            h->non_zero_count_cache[7+8*0]= h->cbp_table[h->top_mb_xy] & 8;
+        }
+        if(IS_8x8DCT(left_type[0])){
+            h->non_zero_count_cache[3+8*1]=
+            h->non_zero_count_cache[3+8*2]= h->cbp_table[h->left_mb_xy[0]]&2; //FIXME check MBAFF
+        }
+        if(IS_8x8DCT(left_type[1])){
+            h->non_zero_count_cache[3+8*3]=
+            h->non_zero_count_cache[3+8*4]= h->cbp_table[h->left_mb_xy[1]]&8; //FIXME check MBAFF
+        }
+
+        if(IS_8x8DCT(mb_type)){
+            h->non_zero_count_cache[scan8[0   ]]= h->non_zero_count_cache[scan8[1   ]]=
+            h->non_zero_count_cache[scan8[2   ]]= h->non_zero_count_cache[scan8[3   ]]= h->cbp_table[mb_xy] & 1;
+
+            h->non_zero_count_cache[scan8[0+ 4]]= h->non_zero_count_cache[scan8[1+ 4]]=
+            h->non_zero_count_cache[scan8[2+ 4]]= h->non_zero_count_cache[scan8[3+ 4]]= h->cbp_table[mb_xy] & 2;
+
+            h->non_zero_count_cache[scan8[0+ 8]]= h->non_zero_count_cache[scan8[1+ 8]]=
+            h->non_zero_count_cache[scan8[2+ 8]]= h->non_zero_count_cache[scan8[3+ 8]]= h->cbp_table[mb_xy] & 4;
+
+            h->non_zero_count_cache[scan8[0+12]]= h->non_zero_count_cache[scan8[1+12]]=
+            h->non_zero_count_cache[scan8[2+12]]= h->non_zero_count_cache[scan8[3+12]]= h->cbp_table[mb_xy] & 8;
+        }
+    }
+
     if (FRAME_MBAFF
             // left mb is in picture
             && h->slice_table[mb_xy-1] != 255
@@ -6577,6 +6385,8 @@
         int edge;
         const int mbm_xy = dir == 0 ? mb_xy -1 : h->top_mb_xy;
         const int mbm_type = s->current_picture.mb_type[mbm_xy];
+        int (*ref2frm) [64] = h->ref2frm[ h->slice_num          &15 ][0] + (MB_MBAFF ? 20 : 2);
+        int (*ref2frmm)[64] = h->ref2frm[ h->slice_table[mbm_xy]&15 ][0] + (MB_MBAFF ? 20 : 2);
         int start = h->slice_table[mbm_xy] == 255 ? 1 : 0;
 
         const int edges = (mb_type & (MB_TYPE_16x16|MB_TYPE_SKIP))
@@ -6645,6 +6455,7 @@
             /* mbn_xy: neighbor macroblock */
             const int mbn_xy = edge > 0 ? mb_xy : mbm_xy;
             const int mbn_type = s->current_picture.mb_type[mbn_xy];
+            int (*ref2frmn)[64] = edge > 0 ? ref2frm : ref2frmm;
             int16_t bS[4];
             int qp;
 
@@ -6682,11 +6493,23 @@
                     int b_idx= 8 + 4 + edge * (dir ? 8:1);
                     int bn_idx= b_idx - (dir ? 8:1);
                     int v = 0;
-                    for( l = 0; !v && l < 1 + (h->slice_type == B_TYPE); l++ ) {
-                        v |= ref2frm[h->ref_cache[l][b_idx]+2] != ref2frm[h->ref_cache[l][bn_idx]+2] ||
+
+                    for( l = 0; !v && l < 1 + (h->slice_type_nos == FF_B_TYPE); l++ ) {
+                        v |= ref2frm[l][h->ref_cache[l][b_idx]] != ref2frmn[l][h->ref_cache[l][bn_idx]] ||
                              FFABS( h->mv_cache[l][b_idx][0] - h->mv_cache[l][bn_idx][0] ) >= 4 ||
                              FFABS( h->mv_cache[l][b_idx][1] - h->mv_cache[l][bn_idx][1] ) >= mvy_limit;
                     }
+
+                    if(h->slice_type_nos == FF_B_TYPE && v){
+                        v=0;
+                        for( l = 0; !v && l < 2; l++ ) {
+                            int ln= 1-l;
+                            v |= ref2frm[l][h->ref_cache[l][b_idx]] != ref2frmn[ln][h->ref_cache[ln][bn_idx]] ||
+                                FFABS( h->mv_cache[l][b_idx][0] - h->mv_cache[ln][bn_idx][0] ) >= 4 ||
+                                FFABS( h->mv_cache[l][b_idx][1] - h->mv_cache[ln][bn_idx][1] ) >= mvy_limit;
+                        }
+                    }
+
                     bS[0] = bS[1] = bS[2] = bS[3] = v;
                     mv_done = 1;
                 }
@@ -6706,14 +6529,27 @@
                     else if(!mv_done)
                     {
                         bS[i] = 0;
-                        for( l = 0; l < 1 + (h->slice_type == B_TYPE); l++ ) {
-                            if( ref2frm[h->ref_cache[l][b_idx]+2] != ref2frm[h->ref_cache[l][bn_idx]+2] ||
+                        for( l = 0; l < 1 + (h->slice_type_nos == FF_B_TYPE); l++ ) {
+                            if( ref2frm[l][h->ref_cache[l][b_idx]] != ref2frmn[l][h->ref_cache[l][bn_idx]] ||
                                 FFABS( h->mv_cache[l][b_idx][0] - h->mv_cache[l][bn_idx][0] ) >= 4 ||
                                 FFABS( h->mv_cache[l][b_idx][1] - h->mv_cache[l][bn_idx][1] ) >= mvy_limit ) {
                                 bS[i] = 1;
                                 break;
                             }
                         }
+
+                        if(h->slice_type_nos == FF_B_TYPE && bS[i]){
+                            bS[i] = 0;
+                            for( l = 0; l < 2; l++ ) {
+                                int ln= 1-l;
+                                if( ref2frm[l][h->ref_cache[l][b_idx]] != ref2frmn[ln][h->ref_cache[ln][bn_idx]] ||
+                                    FFABS( h->mv_cache[l][b_idx][0] - h->mv_cache[ln][bn_idx][0] ) >= 4 ||
+                                    FFABS( h->mv_cache[l][b_idx][1] - h->mv_cache[ln][bn_idx][1] ) >= mvy_limit ) {
+                                    bS[i] = 1;
+                                    break;
+                                }
+                            }
+                        }
                     }
                 }
 
@@ -6769,7 +6605,7 @@
         /* calculate pre-state */
         for( i= 0; i < 460; i++ ) {
             int pre;
-            if( h->slice_type == I_TYPE )
+            if( h->slice_type_nos == FF_I_TYPE )
                 pre = av_clip( ((cabac_context_init_I[i][0] * s->qscale) >>4 ) + cabac_context_init_I[i][1], 1, 126 );
             else
                 pre = av_clip( ((cabac_context_init_PB[h->cabac_init_idc][i][0] * s->qscale) >>4 ) + cabac_context_init_PB[h->cabac_init_idc][i][1], 1, 126 );
@@ -7014,7 +6850,7 @@
         if( aspect_ratio_idc == EXTENDED_SAR ) {
             sps->sar.num= get_bits(&s->gb, 16);
             sps->sar.den= get_bits(&s->gb, 16);
-        }else if(aspect_ratio_idc < 14){
+        }else if(aspect_ratio_idc < sizeof(pixel_aspect)/sizeof(*pixel_aspect)){
             sps->sar=  pixel_aspect[aspect_ratio_idc];
         }else{
             av_log(h->s.avctx, AV_LOG_ERROR, "illegal aspect ratio\n");
@@ -7175,14 +7011,17 @@
     sps->level_idc= level_idc;
 
     if(sps->profile_idc >= 100){ //high profile
-        if(get_ue_golomb(&s->gb) == 3) //chroma_format_idc
+        sps->chroma_format_idc= get_ue_golomb(&s->gb);
+        if(sps->chroma_format_idc == 3)
             get_bits1(&s->gb);  //residual_color_transform_flag
         get_ue_golomb(&s->gb);  //bit_depth_luma_minus8
         get_ue_golomb(&s->gb);  //bit_depth_chroma_minus8
         sps->transform_bypass = get_bits1(&s->gb);
         decode_scaling_matrices(h, sps, NULL, 1, sps->scaling_matrix4, sps->scaling_matrix8);
-    }else
+    }else{
         sps->scaling_matrix_present = 0;
+        sps->chroma_format_idc= 1;
+    }
 
     sps->log2_max_frame_num= get_ue_golomb(&s->gb) + 4;
     sps->poc_type= get_ue_golomb(&s->gb);
@@ -7209,8 +7048,9 @@
     }
 
     tmp= get_ue_golomb(&s->gb);
-    if(tmp > MAX_PICTURE_COUNT-2){
+    if(tmp > MAX_PICTURE_COUNT-2 || tmp >= 32){
         av_log(h->s.avctx, AV_LOG_ERROR, "too many reference frames\n");
+        return -1;
     }
     sps->ref_frame_count= tmp;
     sps->gaps_in_frame_num_allowed_flag= get_bits1(&s->gb);
@@ -7248,6 +7088,9 @@
         if(sps->crop_left || sps->crop_top){
             av_log(h->s.avctx, AV_LOG_ERROR, "insane cropping not completely supported, this could look slightly wrong ...\n");
         }
+        if(sps->crop_right >= 8 || sps->crop_bottom >= (8>> !h->sps.frame_mbs_only_flag)){
+            av_log(h->s.avctx, AV_LOG_ERROR, "brainfart cropping not supported, this could look slightly wrong ...\n");
+        }
     }else{
         sps->crop_left  =
         sps->crop_right =
@@ -7260,7 +7103,7 @@
         decode_vui_parameters(h, sps);
 
     if(s->avctx->debug&FF_DEBUG_PICT_INFO){
-        av_log(h->s.avctx, AV_LOG_DEBUG, "sps:%u profile:%d/%d poc:%d ref:%d %dx%d %s %s crop:%d/%d/%d/%d %s\n",
+        av_log(h->s.avctx, AV_LOG_DEBUG, "sps:%u profile:%d/%d poc:%d ref:%d %dx%d %s %s crop:%d/%d/%d/%d %s %s\n",
                sps_id, sps->profile_idc, sps->level_idc,
                sps->poc_type,
                sps->ref_frame_count,
@@ -7269,7 +7112,8 @@
                sps->direct_8x8_inference_flag ? "8B8" : "",
                sps->crop_left, sps->crop_right,
                sps->crop_top, sps->crop_bottom,
-               sps->vui_parameters_present_flag ? "VUI" : ""
+               sps->vui_parameters_present_flag ? "VUI" : "",
+               ((const char*[]){"Gray","420","422","444"})[sps->chroma_format_idc]
                );
     }
     return 0;
@@ -7279,8 +7123,8 @@
 build_qp_table(PPS *pps, int t, int index)
 {
     int i;
-    for(i = 0; i < 255; i++)
-        pps->chroma_qp_table[t][i & 0xff] = chroma_qp[av_clip(i + index, 0, 51)];
+    for(i = 0; i < 52; i++)
+        pps->chroma_qp_table[t][i] = chroma_qp[av_clip(i + index, 0, 51)];
 }
 
 static inline int decode_picture_parameter_set(H264Context *h, int bit_length){
@@ -7370,11 +7214,9 @@
     }
 
     build_qp_table(pps, 0, pps->chroma_qp_index_offset[0]);
-    if(pps->chroma_qp_index_offset[0] != pps->chroma_qp_index_offset[1]) {
-        build_qp_table(pps, 1, pps->chroma_qp_index_offset[1]);
+    build_qp_table(pps, 1, pps->chroma_qp_index_offset[1]);
+    if(pps->chroma_qp_index_offset[0] != pps->chroma_qp_index_offset[1])
         h->pps.chroma_qp_diff= 1;
-    } else
-        memcpy(pps->chroma_qp_table[1], pps->chroma_qp_table[0], 256);
 
     if(s->avctx->debug&FF_DEBUG_PICT_INFO){
         av_log(h->s.avctx, AV_LOG_DEBUG, "pps:%u sps:%u %s slice_groups:%d ref:%d/%d %s qp:%d/%d/%d/%d %s %s %s %s\n",
@@ -7430,7 +7272,7 @@
 }
 
 
-static int decode_nal_units(H264Context *h, uint8_t *buf, int buf_size){
+static int decode_nal_units(H264Context *h, const uint8_t *buf, int buf_size){
     MpegEncContext * const s = &h->s;
     AVCodecContext * const avctx= s->avctx;
     int buf_index=0;
@@ -7454,7 +7296,7 @@
         int consumed;
         int dst_length;
         int bit_length;
-        uint8_t *ptr;
+        const uint8_t *ptr;
         int i, nalsize = 0;
         int err;
 
@@ -7499,8 +7341,10 @@
             av_log(h->s.avctx, AV_LOG_DEBUG, "NAL %d at %d/%d length %d\n", hx->nal_unit_type, buf_index, buf_size, dst_length);
         }
 
-        if (h->is_avc && (nalsize != consumed))
+        if (h->is_avc && (nalsize != consumed)){
             av_log(h->s.avctx, AV_LOG_ERROR, "AVC: Consumed only %d bytes instead of %d\n", consumed, nalsize);
+            consumed= nalsize;
+        }
 
         buf_index += consumed;
 
@@ -7529,8 +7373,8 @@
             s->current_picture_ptr->key_frame|= (hx->nal_unit_type == NAL_IDR_SLICE);
             if(hx->redundant_pic_count==0 && hx->s.hurry_up < 5
                && (avctx->skip_frame < AVDISCARD_NONREF || hx->nal_ref_idc)
-               && (avctx->skip_frame < AVDISCARD_BIDIR  || hx->slice_type!=B_TYPE)
-               && (avctx->skip_frame < AVDISCARD_NONKEY || hx->slice_type==I_TYPE)
+               && (avctx->skip_frame < AVDISCARD_BIDIR  || hx->slice_type_nos!=FF_B_TYPE)
+               && (avctx->skip_frame < AVDISCARD_NONKEY || hx->slice_type_nos==FF_I_TYPE)
                && avctx->skip_frame < AVDISCARD_ALL)
                 context_count++;
             break;
@@ -7554,8 +7398,8 @@
                && s->context_initialized
                && s->hurry_up < 5
                && (avctx->skip_frame < AVDISCARD_NONREF || hx->nal_ref_idc)
-               && (avctx->skip_frame < AVDISCARD_BIDIR  || hx->slice_type!=B_TYPE)
-               && (avctx->skip_frame < AVDISCARD_NONKEY || hx->slice_type==I_TYPE)
+               && (avctx->skip_frame < AVDISCARD_BIDIR  || hx->slice_type_nos!=FF_B_TYPE)
+               && (avctx->skip_frame < AVDISCARD_NONKEY || hx->slice_type_nos==FF_I_TYPE)
                && avctx->skip_frame < AVDISCARD_ALL)
                 context_count++;
             break;
@@ -7600,7 +7444,7 @@
         else if(err == 1) {
             /* Slice could not be decoded in parallel mode, copy down
              * NAL unit stuff to context 0 and restart. Note that
-             * rbsp_buffer is not transfered, but since we no longer
+             * rbsp_buffer is not transferred, but since we no longer
              * run in parallel mode this should not be an issue. */
             h->nal_unit_type = hx->nal_unit_type;
             h->nal_ref_idc   = hx->nal_ref_idc;
@@ -7617,22 +7461,15 @@
  * returns the number of bytes consumed for building the current frame
  */
 static int get_consumed_bytes(MpegEncContext *s, int pos, int buf_size){
-    if(s->flags&CODEC_FLAG_TRUNCATED){
-        pos -= s->parse_context.last_index;
-        if(pos<0) pos=0; // FIXME remove (unneeded?)
-
-        return pos;
-    }else{
         if(pos==0) pos=1; //avoid infinite loops (i doubt that is needed but ...)
         if(pos+10>buf_size) pos=buf_size; // oops ;)
 
         return pos;
-    }
 }
 
 static int decode_frame(AVCodecContext *avctx,
                              void *data, int *data_size,
-                             uint8_t *buf, int buf_size)
+                             const uint8_t *buf, int buf_size)
 {
     H264Context *h = avctx->priv_data;
     MpegEncContext *s = &h->s;
@@ -7642,7 +7479,7 @@
     s->flags= avctx->flags;
     s->flags2= avctx->flags2;
 
-   /* no supplementary picture */
+   /* end of stream, output what is still in the buffers */
     if (buf_size == 0) {
         Picture *out;
         int i, out_idx;
@@ -7650,7 +7487,7 @@
 //FIXME factorize this with the output code below
         out = h->delayed_pic[0];
         out_idx = 0;
-        for(i=1; h->delayed_pic[i] && !h->delayed_pic[i]->key_frame; i++)
+        for(i=1; h->delayed_pic[i] && h->delayed_pic[i]->poc; i++)
             if(h->delayed_pic[i]->poc < out->poc){
                 out = h->delayed_pic[i];
                 out_idx = i;
@@ -7667,14 +7504,6 @@
         return 0;
     }
 
-    if(s->flags&CODEC_FLAG_TRUNCATED){
-        int next= ff_h264_find_frame_end(h, buf, buf_size);
-
-        if( ff_combine_frame(&s->parse_context, next, (const uint8_t **)&buf, &buf_size) < 0 )
-            return buf_size;
-//printf("next:%d buf_size:%d last_index:%d\n", next, buf_size, s->parse_context.last_index);
-    }
-
     if(h->is_avc && !h->got_avcC) {
         int i, cnt, nalsize;
         unsigned char *p = avctx->extradata;
@@ -7734,7 +7563,6 @@
     if(!(s->flags2 & CODEC_FLAG2_CHUNKS) || (s->mb_y >= s->mb_height && s->mb_height)){
         Picture *out = s->current_picture_ptr;
         Picture *cur = s->current_picture_ptr;
-        Picture *prev = h->delayed_output_pic;
         int i, pics, cross_idr, out_of_order, out_idx;
 
         s->mb_y= 0;
@@ -7742,13 +7570,13 @@
         s->current_picture_ptr->qscale_type= FF_QSCALE_TYPE_H264;
         s->current_picture_ptr->pict_type= s->pict_type;
 
-        h->prev_frame_num_offset= h->frame_num_offset;
-        h->prev_frame_num= h->frame_num;
         if(!s->dropable) {
+            execute_ref_pic_marking(h, h->mmco, h->mmco_index);
             h->prev_poc_msb= h->poc_msb;
             h->prev_poc_lsb= h->poc_lsb;
-            execute_ref_pic_marking(h, h->mmco, h->mmco_index);
         }
+        h->prev_frame_num_offset= h->frame_num_offset;
+        h->prev_frame_num= h->frame_num;
 
         /*
          * FIXME: Error handling code does not seem to support interlaced
@@ -7767,7 +7595,7 @@
 
         MPV_frame_end(s);
 
-        if (s->first_field) {
+        if (cur->field_poc[0]==INT_MAX || cur->field_poc[1]==INT_MAX) {
             /* Wait for second field. */
             *data_size = 0;
 
@@ -7778,9 +7606,6 @@
 
         //FIXME do something with unavailable reference frames
 
-#if 0 //decode order
-            *data_size = sizeof(AVFrame);
-#else
             /* Sort B-frames into display order */
 
             if(h->sps.bitstream_restriction_flag
@@ -7789,63 +7614,56 @@
                 s->low_delay = 0;
             }
 
+            if(   s->avctx->strict_std_compliance >= FF_COMPLIANCE_STRICT
+               && !h->sps.bitstream_restriction_flag){
+                s->avctx->has_b_frames= MAX_DELAYED_PIC_COUNT;
+                s->low_delay= 0;
+            }
+
             pics = 0;
             while(h->delayed_pic[pics]) pics++;
 
-            assert(pics+1 < sizeof(h->delayed_pic) / sizeof(h->delayed_pic[0]));
+            assert(pics <= MAX_DELAYED_PIC_COUNT);
 
             h->delayed_pic[pics++] = cur;
             if(cur->reference == 0)
                 cur->reference = DELAYED_PIC_REF;
 
-            cross_idr = 0;
-            for(i=0; h->delayed_pic[i]; i++)
-                if(h->delayed_pic[i]->key_frame || h->delayed_pic[i]->poc==0)
-                    cross_idr = 1;
-
             out = h->delayed_pic[0];
             out_idx = 0;
-            for(i=1; h->delayed_pic[i] && !h->delayed_pic[i]->key_frame; i++)
+            for(i=1; h->delayed_pic[i] && h->delayed_pic[i]->poc; i++)
                 if(h->delayed_pic[i]->poc < out->poc){
                     out = h->delayed_pic[i];
                     out_idx = i;
                 }
+            cross_idr = !h->delayed_pic[0]->poc || !!h->delayed_pic[i];
 
-            out_of_order = !cross_idr && prev && out->poc < prev->poc;
+            out_of_order = !cross_idr && out->poc < h->outputed_poc;
+
             if(h->sps.bitstream_restriction_flag && s->avctx->has_b_frames >= h->sps.num_reorder_frames)
                 { }
-            else if(prev && pics <= s->avctx->has_b_frames)
-                out = prev;
-            else if((out_of_order && pics-1 == s->avctx->has_b_frames && pics < 15)
+            else if((out_of_order && pics-1 == s->avctx->has_b_frames && s->avctx->has_b_frames < MAX_DELAYED_PIC_COUNT)
                || (s->low_delay &&
-                ((!cross_idr && prev && out->poc > prev->poc + 2)
-                 || cur->pict_type == B_TYPE)))
+                ((!cross_idr && out->poc > h->outputed_poc + 2)
+                 || cur->pict_type == FF_B_TYPE)))
             {
                 s->low_delay = 0;
                 s->avctx->has_b_frames++;
-                out = prev;
             }
-            else if(out_of_order)
-                out = prev;
 
             if(out_of_order || pics > s->avctx->has_b_frames){
+                out->reference &= ~DELAYED_PIC_REF;
                 for(i=out_idx; h->delayed_pic[i]; i++)
                     h->delayed_pic[i] = h->delayed_pic[i+1];
             }
-
-            if(prev == out)
-                *data_size = 0;
-            else
+            if(!out_of_order && pics > s->avctx->has_b_frames){
                 *data_size = sizeof(AVFrame);
-            if(prev && prev != out && prev->reference == DELAYED_PIC_REF)
-                prev->reference = 0;
-            h->delayed_output_pic = out;
-#endif
 
-            if(out)
+                h->outputed_poc = out->poc;
                 *pict= *(AVFrame*)out;
-            else
+            }else{
                 av_log(avctx, AV_LOG_DEBUG, "no picture\n");
+            }
         }
     }
 
@@ -7855,7 +7673,7 @@
 #if 0 //?
 
     /* Return the Picture timestamp as the frame number */
-    /* we substract 1 because it is added on utils.c    */
+    /* we subtract 1 because it is added on utils.c     */
     avctx->frame_number = s->picture_number - 1;
 #endif
     return get_consumed_bytes(s, buf_index, buf_size);
@@ -7880,11 +7698,12 @@
 }
 #endif
 
-#if 0 //selftest
+#ifdef TEST
+#undef printf
 #undef random
 #define COUNT 8000
 #define SIZE (COUNT*40)
-int main(){
+int main(void){
     int i;
     uint8_t temp[SIZE];
     PutBitContext pb;
@@ -7944,6 +7763,7 @@
         STOP_TIMER("get_se_golomb");
     }
 
+#if 0
     printf("testing 4x4 (I)DCT\n");
 
     DCTELEM block[16];
@@ -7983,14 +7803,12 @@
         }
     }
     printf("error=%f max_error=%d\n", ((float)error)/COUNT/16, (int)max_error );
-#if 0
     printf("testing quantizer\n");
     for(qp=0; qp<52; qp++){
         for(i=0; i<16; i++)
             src1_block[i]= src2_block[i]= random()%255;
 
     }
-#endif
     printf("Testing NAL layer\n");
 
     uint8_t bitstream[COUNT];
@@ -8046,16 +7864,17 @@
             return -1;
         }
     }
+#endif
 
     printf("Testing RBSP\n");
 
 
     return 0;
 }
-#endif
+#endif /* TEST */
 
 
-static int decode_end(AVCodecContext *avctx)
+static av_cold int decode_end(AVCodecContext *avctx)
 {
     H264Context *h = avctx->priv_data;
     MpegEncContext *s = &h->s;
@@ -8080,7 +7899,7 @@
     NULL,
     decode_end,
     decode_frame,
-    /*CODEC_CAP_DRAW_HORIZ_BAND |*/ CODEC_CAP_DR1 | CODEC_CAP_TRUNCATED | CODEC_CAP_DELAY,
+    /*CODEC_CAP_DRAW_HORIZ_BAND |*/ CODEC_CAP_DR1 | CODEC_CAP_DELAY,
     .flush= flush_dpb,
 };
 
Index: mythtv/libs/libavcodec/tiertexseqv.c
===================================================================
--- mythtv/libs/libavcodec/tiertexseqv.c	(revision 18209)
+++ mythtv/libs/libavcodec/tiertexseqv.c	(working copy)
@@ -173,7 +173,7 @@
     }
 }
 
-static int seqvideo_decode_init(AVCodecContext *avctx)
+static av_cold int seqvideo_decode_init(AVCodecContext *avctx)
 {
     SeqVideoContext *seq = avctx->priv_data;
 
@@ -185,7 +185,7 @@
     return 0;
 }
 
-static int seqvideo_decode_frame(AVCodecContext *avctx,
+static av_cold int seqvideo_decode_frame(AVCodecContext *avctx,
                                  void *data, int *data_size,
                                  uint8_t *buf, int buf_size)
 {
Index: mythtv/libs/libavcodec/h264.h
===================================================================
--- mythtv/libs/libavcodec/h264.h	(revision 18209)
+++ mythtv/libs/libavcodec/h264.h	(working copy)
@@ -51,10 +51,14 @@
 
 #define MAX_MMCO_COUNT 66
 
+#define MAX_DELAYED_PIC_COUNT 16
+
 /* Compiling in interlaced support reduces the speed
  * of progressive decoding by about 2%. */
 #define ALLOW_INTERLACE
 
+#define ALLOW_NOCHROMA
+
 #ifdef ALLOW_INTERLACE
 #define MB_MBAFF h->mb_mbaff
 #define MB_FIELD h->mb_field_decoding_flag
@@ -70,6 +74,16 @@
 #endif
 #define FIELD_OR_MBAFF_PICTURE (FRAME_MBAFF || FIELD_PICTURE)
 
+#ifdef ALLOW_NOCHROMA
+#define CHROMA h->sps.chroma_format_idc
+#else
+#define CHROMA 1
+#endif
+
+#ifndef ENABLE_H264_ENCODER
+#define ENABLE_H264_ENCODER 0
+#endif
+
 /**
  * Sequence parameter set
  */
@@ -77,6 +91,7 @@
 
     int profile_idc;
     int level_idc;
+    int chroma_format_idc;
     int transform_bypass;              ///< qpprime_y_zero_transform_bypass_flag
     int log2_max_frame_num;            ///< log2_max_frame_num_minus4 + 4
     int poc_type;                      ///< pic_order_cnt_type
@@ -132,7 +147,7 @@
     int transform_8x8_mode;     ///< transform_8x8_mode_flag
     uint8_t scaling_matrix4[6][16];
     uint8_t scaling_matrix8[2][64];
-    uint8_t chroma_qp_table[2][256];  ///< pre-scaled (with chroma_qp_index_offset) version of qp_table
+    uint8_t chroma_qp_table[2][64];  ///< pre-scaled (with chroma_qp_index_offset) version of qp_table
     int chroma_qp_diff;
 }PPS;
 
@@ -264,6 +279,7 @@
     uint8_t *slice_table_base;
     uint8_t *slice_table;      ///< slice_table_base + 2*mb_stride + 1
     int slice_type;
+    int slice_type_nos;        ///< S free slice type (SI/SP are remapped to I/P)
     int slice_type_fixed;
 
     //interlacing specific flags
@@ -330,8 +346,9 @@
     Picture ref_list[2][48];         /**< 0..15: frame refs, 16..47: mbaff field refs.
                                           Reordered version of default_ref_list
                                           according to picture reordering in slice header */
-    Picture *delayed_pic[18]; //FIXME size?
-    Picture *delayed_output_pic;
+    int ref2frm[16][2][64];          ///< reference to frame number lists, used in the loop filter, the first 2 are for -2,-1
+    Picture *delayed_pic[MAX_DELAYED_PIC_COUNT+2]; //FIXME size?
+    int outputed_poc;
 
     /**
      * memory management control operations buffer.
@@ -414,6 +431,8 @@
     int last_slice_type;
     /** @} */
 
+    int mb_xy;
+
 }H264Context;
 
 #endif /* FFMPEG_H264_H */
Index: mythtv/libs/libavcodec/mpegvideo_enc.c
===================================================================
--- mythtv/libs/libavcodec/mpegvideo_enc.c	(revision 18209)
+++ mythtv/libs/libavcodec/mpegvideo_enc.c	(working copy)
@@ -231,7 +231,7 @@
 }
 
 /* init video encoder */
-int MPV_encode_init(AVCodecContext *avctx)
+av_cold int MPV_encode_init(AVCodecContext *avctx)
 {
     MpegEncContext *s = avctx->priv_data;
     int i;
@@ -728,7 +728,7 @@
     return 0;
 }
 
-int MPV_encode_end(AVCodecContext *avctx)
+av_cold int MPV_encode_end(AVCodecContext *avctx)
 {
     MpegEncContext *s = avctx->priv_data;
 
@@ -930,8 +930,8 @@
     assert(scale>=0 && scale <=3);
 
 //    emms_c();
-    p_lambda= s->last_lambda_for[P_TYPE]; //s->next_picture_ptr->quality;
-    b_lambda= s->last_lambda_for[B_TYPE]; //p_lambda *FFABS(s->avctx->b_quant_factor) + s->avctx->b_quant_offset;
+    p_lambda= s->last_lambda_for[FF_P_TYPE]; //s->next_picture_ptr->quality;
+    b_lambda= s->last_lambda_for[FF_B_TYPE]; //p_lambda *FFABS(s->avctx->b_quant_factor) + s->avctx->b_quant_offset;
     if(!b_lambda) b_lambda= p_lambda; //FIXME we should do this somewhere else
     lambda2= (b_lambda*b_lambda + (1<<FF_LAMBDA_SHIFT)/2 ) >> FF_LAMBDA_SHIFT;
 
@@ -986,7 +986,7 @@
 
         c->error[0]= c->error[1]= c->error[2]= 0;
 
-        input[0].pict_type= I_TYPE;
+        input[0].pict_type= FF_I_TYPE;
         input[0].quality= 1 * FF_QP2LAMBDA;
         out_size = avcodec_encode_video(c, outbuf, outbuf_size, &input[0]);
 //        rd += (out_size * lambda2) >> FF_LAMBDA_SHIFT;
@@ -994,7 +994,7 @@
         for(i=0; i<s->max_b_frames+1; i++){
             int is_p= i % (j+1) == j || i==s->max_b_frames;
 
-            input[i+1].pict_type= is_p ? P_TYPE : B_TYPE;
+            input[i+1].pict_type= is_p ? FF_P_TYPE : FF_B_TYPE;
             input[i+1].quality= is_p ? p_lambda : b_lambda;
             out_size = avcodec_encode_video(c, outbuf, outbuf_size, &input[i+1]);
             rd += (out_size * lambda2) >> (FF_LAMBDA_SHIFT - 3);
@@ -1036,7 +1036,7 @@
     if(s->reordered_input_picture[0]==NULL && s->input_picture[0]){
         if(/*s->picture_in_gop_number >= s->gop_size ||*/ s->next_picture_ptr==NULL || s->intra_only){
             s->reordered_input_picture[0]= s->input_picture[0];
-            s->reordered_input_picture[0]->pict_type= I_TYPE;
+            s->reordered_input_picture[0]->pict_type= FF_I_TYPE;
             s->reordered_input_picture[0]->coded_picture_number= s->coded_picture_number++;
         }else{
             int b_frames;
@@ -1071,7 +1071,7 @@
                     if(pict_num >= s->rc_context.num_entries)
                         break;
                     if(!s->input_picture[i]){
-                        s->rc_context.entry[pict_num-1].new_pict_type = P_TYPE;
+                        s->rc_context.entry[pict_num-1].new_pict_type = FF_P_TYPE;
                         break;
                     }
 
@@ -1115,10 +1115,10 @@
 
             for(i= b_frames - 1; i>=0; i--){
                 int type= s->input_picture[i]->pict_type;
-                if(type && type != B_TYPE)
+                if(type && type != FF_B_TYPE)
                     b_frames= i;
             }
-            if(s->input_picture[b_frames]->pict_type == B_TYPE && b_frames == s->max_b_frames){
+            if(s->input_picture[b_frames]->pict_type == FF_B_TYPE && b_frames == s->max_b_frames){
                 av_log(s->avctx, AV_LOG_ERROR, "warning, too many b frames in a row\n");
             }
 
@@ -1128,29 +1128,29 @@
               }else{
                 if(s->flags & CODEC_FLAG_CLOSED_GOP)
                     b_frames=0;
-                s->input_picture[b_frames]->pict_type= I_TYPE;
+                s->input_picture[b_frames]->pict_type= FF_I_TYPE;
               }
             }
 
             if(   (s->flags & CODEC_FLAG_CLOSED_GOP)
                && b_frames
-               && s->input_picture[b_frames]->pict_type== I_TYPE)
+               && s->input_picture[b_frames]->pict_type== FF_I_TYPE)
                 b_frames--;
 
             s->reordered_input_picture[0]= s->input_picture[b_frames];
-            if(s->reordered_input_picture[0]->pict_type != I_TYPE)
-                s->reordered_input_picture[0]->pict_type= P_TYPE;
+            if(s->reordered_input_picture[0]->pict_type != FF_I_TYPE)
+                s->reordered_input_picture[0]->pict_type= FF_P_TYPE;
             s->reordered_input_picture[0]->coded_picture_number= s->coded_picture_number++;
             for(i=0; i<b_frames; i++){
                 s->reordered_input_picture[i+1]= s->input_picture[i];
-                s->reordered_input_picture[i+1]->pict_type= B_TYPE;
+                s->reordered_input_picture[i+1]->pict_type= FF_B_TYPE;
                 s->reordered_input_picture[i+1]->coded_picture_number= s->coded_picture_number++;
             }
         }
     }
 no_output_pic:
     if(s->reordered_input_picture[0]){
-        s->reordered_input_picture[0]->reference= s->reordered_input_picture[0]->pict_type!=B_TYPE ? 3 : 0;
+        s->reordered_input_picture[0]->reference= s->reordered_input_picture[0]->pict_type!=FF_B_TYPE ? 3 : 0;
 
         copy_picture(&s->new_picture, s->reordered_input_picture[0]);
 
@@ -1254,11 +1254,11 @@
                         s->lambda_table[i]= FFMAX(s->lambda_table[i]+1, s->lambda_table[i]*(s->qscale+1) / s->qscale);
                 }
                 s->mb_skipped = 0;        //done in MPV_frame_start()
-                if(s->pict_type==P_TYPE){ //done in encode_picture() so we must undo it
+                if(s->pict_type==FF_P_TYPE){ //done in encode_picture() so we must undo it
                     if(s->flipflop_rounding || s->codec_id == CODEC_ID_H263P || s->codec_id == CODEC_ID_MPEG4)
                         s->no_rounding ^= 1;
                 }
-                if(s->pict_type!=B_TYPE){
+                if(s->pict_type!=FF_B_TYPE){
                     s->time_base= s->last_time_base;
                     s->last_non_b_time= s->time - s->pp_time;
                 }
@@ -1475,7 +1475,7 @@
 
                 if(s->codec_id==CODEC_ID_MPEG4){
                     if(!s->mb_intra){
-                        if(s->pict_type == B_TYPE){
+                        if(s->pict_type == FF_B_TYPE){
                             if(s->dquant&1 || s->mv_dir&MV_DIRECT)
                                 s->dquant= 0;
                         }
@@ -1552,7 +1552,7 @@
         dest_cb = s->dest[1];
         dest_cr = s->dest[2];
 
-        if ((!s->no_rounding) || s->pict_type==B_TYPE){
+        if ((!s->no_rounding) || s->pict_type==FF_B_TYPE){
             op_pix = s->dsp.put_pixels_tab;
             op_qpix= s->dsp.put_qpel_pixels_tab;
         }else{
@@ -1939,7 +1939,7 @@
             s->block_index[3]+=2;
 
             /* compute motion vector & mb_type and store in context */
-            if(s->pict_type==B_TYPE)
+            if(s->pict_type==FF_B_TYPE)
                 ff_estimate_b_frame_motion(s, s->mb_x, s->mb_y);
             else
                 ff_estimate_p_frame_motion(s, s->mb_x, s->mb_y);
@@ -2336,7 +2336,7 @@
                         s->mv[1][0][0] = best_s.mv[1][0][0];
                         s->mv[1][0][1] = best_s.mv[1][0][1];
 
-                        qpi = s->pict_type == B_TYPE ? 2 : 0;
+                        qpi = s->pict_type == FF_B_TYPE ? 2 : 0;
                         for(; qpi<4; qpi++){
                             int dquant= dquant_tab[qpi];
                             qp= last_qp + dquant;
@@ -2438,7 +2438,7 @@
                 s->last_bits= put_bits_count(&s->pb);
 
                 if (ENABLE_ANY_H263_ENCODER &&
-                    s->out_format == FMT_H263 && s->pict_type!=B_TYPE)
+                    s->out_format == FMT_H263 && s->pict_type!=FF_B_TYPE)
                     ff_h263_update_motion_val(s);
 
                 if(next_block==0){ //FIXME 16 vs linesize16
@@ -2565,7 +2565,7 @@
                 s->last_mv_dir = s->mv_dir;
 
                 if (ENABLE_ANY_H263_ENCODER &&
-                    s->out_format == FMT_H263 && s->pict_type!=B_TYPE)
+                    s->out_format == FMT_H263 && s->pict_type!=FF_B_TYPE)
                     ff_h263_update_motion_val(s);
 
                 MPV_decode_mb(s, s->block);
@@ -2603,7 +2603,7 @@
     }
 
     //not beautiful here but we must write it before flushing so it has to be here
-    if (ENABLE_MSMPEG4_ENCODER && s->msmpeg4_version && s->msmpeg4_version<4 && s->pict_type == I_TYPE)
+    if (ENABLE_MSMPEG4_ENCODER && s->msmpeg4_version && s->msmpeg4_version<4 && s->pict_type == FF_I_TYPE)
         msmpeg4_encode_ext_header(s);
 
     write_slice_end(s);
@@ -2699,7 +2699,7 @@
     assert(s->current_picture_ptr->pts != AV_NOPTS_VALUE);
     s->time= s->current_picture_ptr->pts*s->avctx->time_base.num;
 
-    if(s->pict_type==B_TYPE){
+    if(s->pict_type==FF_B_TYPE){
         s->pb_time= s->pp_time - (s->last_non_b_time - s->time);
         assert(s->pb_time > 0 && s->pb_time < s->pp_time);
     }else{
@@ -2731,10 +2731,10 @@
 
 //    s->lambda= s->current_picture_ptr->quality; //FIXME qscale / ... stuff for ME ratedistoration
 
-    if(s->pict_type==I_TYPE){
+    if(s->pict_type==FF_I_TYPE){
         if(s->msmpeg4_version >= 3) s->no_rounding=1;
         else                        s->no_rounding=0;
-    }else if(s->pict_type!=B_TYPE){
+    }else if(s->pict_type!=FF_B_TYPE){
         if(s->flipflop_rounding || s->codec_id == CODEC_ID_H263P || s->codec_id == CODEC_ID_MPEG4)
             s->no_rounding ^= 1;
     }
@@ -2744,7 +2744,7 @@
             return -1;
         ff_get_2pass_fcode(s);
     }else if(!(s->flags & CODEC_FLAG_QSCALE)){
-        if(s->pict_type==B_TYPE)
+        if(s->pict_type==FF_B_TYPE)
             s->lambda= s->last_lambda_for[s->pict_type];
         else
             s->lambda= s->last_lambda_for[s->last_non_b_pict_type];
@@ -2759,17 +2759,17 @@
     ff_init_me(s);
 
     /* Estimate motion for every MB */
-    if(s->pict_type != I_TYPE){
+    if(s->pict_type != FF_I_TYPE){
         s->lambda = (s->lambda * s->avctx->me_penalty_compensation + 128)>>8;
         s->lambda2= (s->lambda2* (int64_t)s->avctx->me_penalty_compensation + 128)>>8;
-        if(s->pict_type != B_TYPE && s->avctx->me_threshold==0){
-            if((s->avctx->pre_me && s->last_non_b_pict_type==I_TYPE) || s->avctx->pre_me==2){
+        if(s->pict_type != FF_B_TYPE && s->avctx->me_threshold==0){
+            if((s->avctx->pre_me && s->last_non_b_pict_type==FF_I_TYPE) || s->avctx->pre_me==2){
                 s->avctx->execute(s->avctx, pre_estimate_motion_thread, (void**)&(s->thread_context[0]), NULL, s->avctx->thread_count);
             }
         }
 
         s->avctx->execute(s->avctx, estimate_motion_thread, (void**)&(s->thread_context[0]), NULL, s->avctx->thread_count);
-    }else /* if(s->pict_type == I_TYPE) */{
+    }else /* if(s->pict_type == FF_I_TYPE) */{
         /* I-Frame */
         for(i=0; i<s->mb_stride*s->mb_height; i++)
             s->mb_type[i]= CANDIDATE_MB_TYPE_INTRA;
@@ -2786,22 +2786,22 @@
     s->current_picture.   mb_var_sum= s->current_picture_ptr->   mb_var_sum= s->me.   mb_var_sum_temp;
     emms_c();
 
-    if(s->me.scene_change_score > s->avctx->scenechange_threshold && s->pict_type == P_TYPE){
-        s->pict_type= I_TYPE;
+    if(s->me.scene_change_score > s->avctx->scenechange_threshold && s->pict_type == FF_P_TYPE){
+        s->pict_type= FF_I_TYPE;
         for(i=0; i<s->mb_stride*s->mb_height; i++)
             s->mb_type[i]= CANDIDATE_MB_TYPE_INTRA;
 //printf("Scene change detected, encoding as I Frame %d %d\n", s->current_picture.mb_var_sum, s->current_picture.mc_mb_var_sum);
     }
 
     if(!s->umvplus){
-        if(s->pict_type==P_TYPE || s->pict_type==S_TYPE) {
+        if(s->pict_type==FF_P_TYPE || s->pict_type==FF_S_TYPE) {
             s->f_code= ff_get_best_fcode(s, s->p_mv_table, CANDIDATE_MB_TYPE_INTER);
 
             if(s->flags & CODEC_FLAG_INTERLACED_ME){
                 int a,b;
                 a= ff_get_best_fcode(s, s->p_field_mv_table[0][0], CANDIDATE_MB_TYPE_INTER_I); //FIXME field_select
                 b= ff_get_best_fcode(s, s->p_field_mv_table[1][1], CANDIDATE_MB_TYPE_INTER_I);
-                s->f_code= FFMAX(s->f_code, FFMAX(a,b));
+                s->f_code= FFMAX3(s->f_code, a, b);
             }
 
             ff_fix_long_p_mvs(s);
@@ -2816,7 +2816,7 @@
             }
         }
 
-        if(s->pict_type==B_TYPE){
+        if(s->pict_type==FF_B_TYPE){
             int a, b;
 
             a = ff_get_best_fcode(s, s->b_forw_mv_table, CANDIDATE_MB_TYPE_FORWARD);
@@ -2850,7 +2850,7 @@
     if (estimate_qp(s, 0) < 0)
         return -1;
 
-    if(s->qscale < 3 && s->max_qcoeff<=128 && s->pict_type==I_TYPE && !(s->flags & CODEC_FLAG_QSCALE))
+    if(s->qscale < 3 && s->max_qcoeff<=128 && s->pict_type==FF_I_TYPE && !(s->flags & CODEC_FLAG_QSCALE))
         s->qscale= 3; //reduce clipping problems
 
     if (s->out_format == FMT_MJPEG) {
@@ -2868,7 +2868,7 @@
 
     //FIXME var duplication
     s->current_picture_ptr->key_frame=
-    s->current_picture.key_frame= s->pict_type == I_TYPE; //FIXME pic_ptr
+    s->current_picture.key_frame= s->pict_type == FF_I_TYPE; //FIXME pic_ptr
     s->current_picture_ptr->pict_type=
     s->current_picture.pict_type= s->pict_type;
 
Index: mythtv/libs/libavcodec/mdec.c
===================================================================
--- mythtv/libs/libavcodec/mdec.c	(revision 18209)
+++ mythtv/libs/libavcodec/mdec.c	(working copy)
@@ -173,7 +173,7 @@
         av_log(avctx, AV_LOG_ERROR, "get_buffer() failed\n");
         return -1;
     }
-    p->pict_type= I_TYPE;
+    p->pict_type= FF_I_TYPE;
     p->key_frame= 1;
     a->last_dc[0]=
     a->last_dc[1]=
@@ -214,7 +214,7 @@
     return (get_bits_count(&a->gb)+31)/32*4;
 }
 
-static void mdec_common_init(AVCodecContext *avctx){
+static av_cold void mdec_common_init(AVCodecContext *avctx){
     MDECContext * const a = avctx->priv_data;
 
     dsputil_init(&a->dsp, avctx);
@@ -226,7 +226,7 @@
     a->avctx= avctx;
 }
 
-static int decode_init(AVCodecContext *avctx){
+static av_cold int decode_init(AVCodecContext *avctx){
     MDECContext * const a = avctx->priv_data;
     AVFrame *p= (AVFrame*)&a->picture;
 
@@ -246,7 +246,7 @@
     return 0;
 }
 
-static int decode_end(AVCodecContext *avctx){
+static av_cold int decode_end(AVCodecContext *avctx){
     MDECContext * const a = avctx->priv_data;
 
     av_freep(&a->bitstream_buffer);
Index: mythtv/libs/libavcodec/smc.c
===================================================================
--- mythtv/libs/libavcodec/smc.c	(revision 18209)
+++ mythtv/libs/libavcodec/smc.c	(working copy)
@@ -428,7 +428,7 @@
     }
 }
 
-static int smc_decode_init(AVCodecContext *avctx)
+static av_cold int smc_decode_init(AVCodecContext *avctx)
 {
     SmcContext *s = avctx->priv_data;
 
@@ -467,7 +467,7 @@
     return buf_size;
 }
 
-static int smc_decode_end(AVCodecContext *avctx)
+static av_cold int smc_decode_end(AVCodecContext *avctx)
 {
     SmcContext *s = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/tiff.c
===================================================================
--- mythtv/libs/libavcodec/tiff.c	(revision 18209)
+++ mythtv/libs/libavcodec/tiff.c	(working copy)
@@ -459,7 +459,7 @@
     return buf_size;
 }
 
-static int tiff_init(AVCodecContext *avctx){
+static av_cold int tiff_init(AVCodecContext *avctx){
     TiffContext *s = avctx->priv_data;
 
     s->width = 0;
@@ -473,7 +473,7 @@
     return 0;
 }
 
-static int tiff_end(AVCodecContext *avctx)
+static av_cold int tiff_end(AVCodecContext *avctx)
 {
     TiffContext * const s = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/flacenc.c
===================================================================
--- mythtv/libs/libavcodec/flacenc.c	(revision 18209)
+++ mythtv/libs/libavcodec/flacenc.c	(working copy)
@@ -169,7 +169,7 @@
     return blocksize;
 }
 
-static int flac_encode_init(AVCodecContext *avctx)
+static av_cold int flac_encode_init(AVCodecContext *avctx)
 {
     int freq = avctx->sample_rate;
     int channels = avctx->channels;
@@ -1478,7 +1478,7 @@
     return out_bytes;
 }
 
-static int flac_encode_close(AVCodecContext *avctx)
+static av_cold int flac_encode_close(AVCodecContext *avctx)
 {
     av_freep(&avctx->extradata);
     avctx->extradata_size = 0;
Index: mythtv/libs/libavcodec/ratecontrol.c
===================================================================
--- mythtv/libs/libavcodec/ratecontrol.c	(revision 18209)
+++ mythtv/libs/libavcodec/ratecontrol.c	(working copy)
@@ -144,7 +144,7 @@
         /* init all to skipped p frames (with b frames we might have a not encoded frame at the end FIXME) */
         for(i=0; i<rcc->num_entries; i++){
             RateControlEntry *rce= &rcc->entry[i];
-            rce->pict_type= rce->new_pict_type=P_TYPE;
+            rce->pict_type= rce->new_pict_type=FF_P_TYPE;
             rce->qscale= rce->new_qscale=FF_QP2LAMBDA * 2;
             rce->misc_bits= s->mb_num + 10;
             rce->mb_var_sum= s->mb_num*100;
@@ -212,9 +212,9 @@
                 RateControlEntry rce;
                 double q;
 
-                if     (i%((s->gop_size+3)/4)==0) rce.pict_type= I_TYPE;
-                else if(i%(s->max_b_frames+1))    rce.pict_type= B_TYPE;
-                else                              rce.pict_type= P_TYPE;
+                if     (i%((s->gop_size+3)/4)==0) rce.pict_type= FF_I_TYPE;
+                else if(i%(s->max_b_frames+1))    rce.pict_type= FF_B_TYPE;
+                else                              rce.pict_type= FF_P_TYPE;
 
                 rce.new_pict_type= rce.pict_type;
                 rce.mc_mb_var_sum= bits*s->mb_num/100000;
@@ -224,7 +224,7 @@
                 rce.b_code   = 1;
                 rce.misc_bits= 1;
 
-                if(s->pict_type== I_TYPE){
+                if(s->pict_type== FF_I_TYPE){
                     rce.i_count   = s->mb_num;
                     rce.i_tex_bits= bits;
                     rce.p_tex_bits= 0;
@@ -320,23 +320,23 @@
         rce->p_tex_bits*rce->qscale,
         (rce->i_tex_bits + rce->p_tex_bits)*(double)rce->qscale,
         rce->mv_bits/mb_num,
-        rce->pict_type == B_TYPE ? (rce->f_code + rce->b_code)*0.5 : rce->f_code,
+        rce->pict_type == FF_B_TYPE ? (rce->f_code + rce->b_code)*0.5 : rce->f_code,
         rce->i_count/mb_num,
         rce->mc_mb_var_sum/mb_num,
         rce->mb_var_sum/mb_num,
-        rce->pict_type == I_TYPE,
-        rce->pict_type == P_TYPE,
-        rce->pict_type == B_TYPE,
+        rce->pict_type == FF_I_TYPE,
+        rce->pict_type == FF_P_TYPE,
+        rce->pict_type == FF_B_TYPE,
         rcc->qscale_sum[pict_type] / (double)rcc->frame_count[pict_type],
         a->qcompress,
-/*        rcc->last_qscale_for[I_TYPE],
-        rcc->last_qscale_for[P_TYPE],
-        rcc->last_qscale_for[B_TYPE],
+/*        rcc->last_qscale_for[FF_I_TYPE],
+        rcc->last_qscale_for[FF_P_TYPE],
+        rcc->last_qscale_for[FF_B_TYPE],
         rcc->next_non_b_qscale,*/
-        rcc->i_cplx_sum[I_TYPE] / (double)rcc->frame_count[I_TYPE],
-        rcc->i_cplx_sum[P_TYPE] / (double)rcc->frame_count[P_TYPE],
-        rcc->p_cplx_sum[P_TYPE] / (double)rcc->frame_count[P_TYPE],
-        rcc->p_cplx_sum[B_TYPE] / (double)rcc->frame_count[B_TYPE],
+        rcc->i_cplx_sum[FF_I_TYPE] / (double)rcc->frame_count[FF_I_TYPE],
+        rcc->i_cplx_sum[FF_P_TYPE] / (double)rcc->frame_count[FF_P_TYPE],
+        rcc->p_cplx_sum[FF_P_TYPE] / (double)rcc->frame_count[FF_P_TYPE],
+        rcc->p_cplx_sum[FF_B_TYPE] / (double)rcc->frame_count[FF_B_TYPE],
         (rcc->i_cplx_sum[pict_type] + rcc->p_cplx_sum[pict_type]) / (double)rcc->frame_count[pict_type],
         0
     };
@@ -367,9 +367,9 @@
     q= bits2qp(rce, bits);
 
     /* I/B difference */
-    if     (pict_type==I_TYPE && s->avctx->i_quant_factor<0.0)
+    if     (pict_type==FF_I_TYPE && s->avctx->i_quant_factor<0.0)
         q= -q*s->avctx->i_quant_factor + s->avctx->i_quant_offset;
-    else if(pict_type==B_TYPE && s->avctx->b_quant_factor<0.0)
+    else if(pict_type==FF_B_TYPE && s->avctx->b_quant_factor<0.0)
         q= -q*s->avctx->b_quant_factor + s->avctx->b_quant_offset;
     if(q<1) q=1;
 
@@ -380,17 +380,17 @@
     RateControlContext *rcc= &s->rc_context;
     AVCodecContext *a= s->avctx;
     const int pict_type= rce->new_pict_type;
-    const double last_p_q    = rcc->last_qscale_for[P_TYPE];
+    const double last_p_q    = rcc->last_qscale_for[FF_P_TYPE];
     const double last_non_b_q= rcc->last_qscale_for[rcc->last_non_b_pict_type];
 
-    if     (pict_type==I_TYPE && (a->i_quant_factor>0.0 || rcc->last_non_b_pict_type==P_TYPE))
+    if     (pict_type==FF_I_TYPE && (a->i_quant_factor>0.0 || rcc->last_non_b_pict_type==FF_P_TYPE))
         q= last_p_q    *FFABS(a->i_quant_factor) + a->i_quant_offset;
-    else if(pict_type==B_TYPE && a->b_quant_factor>0.0)
+    else if(pict_type==FF_B_TYPE && a->b_quant_factor>0.0)
         q= last_non_b_q*    a->b_quant_factor  + a->b_quant_offset;
     if(q<1) q=1;
 
     /* last qscale / qdiff stuff */
-    if(rcc->last_non_b_pict_type==pict_type || pict_type!=I_TYPE){
+    if(rcc->last_non_b_pict_type==pict_type || pict_type!=FF_I_TYPE){
         double last_q= rcc->last_qscale_for[pict_type];
         const int maxdiff= FF_QP2LAMBDA * a->max_qdiff;
 
@@ -400,7 +400,7 @@
 
     rcc->last_qscale_for[pict_type]= q; //Note we cannot do that after blurring
 
-    if(pict_type!=B_TYPE)
+    if(pict_type!=FF_B_TYPE)
         rcc->last_non_b_pict_type= pict_type;
 
     return q;
@@ -415,10 +415,10 @@
 
     assert(qmin <= qmax);
 
-    if(pict_type==B_TYPE){
+    if(pict_type==FF_B_TYPE){
         qmin= (int)(qmin*FFABS(s->avctx->b_quant_factor)+s->avctx->b_quant_offset + 0.5);
         qmax= (int)(qmax*FFABS(s->avctx->b_quant_factor)+s->avctx->b_quant_offset + 0.5);
-    }else if(pict_type==I_TYPE){
+    }else if(pict_type==FF_I_TYPE){
         qmin= (int)(qmin*FFABS(s->avctx->i_quant_factor)+s->avctx->i_quant_offset + 0.5);
         qmax= (int)(qmax*FFABS(s->avctx->i_quant_factor)+s->avctx->i_quant_offset + 0.5);
     }
@@ -445,7 +445,7 @@
     get_qminmax(&qmin, &qmax, s, pict_type);
 
     /* modulation */
-    if(s->avctx->rc_qmod_freq && frame_num%s->avctx->rc_qmod_freq==0 && pict_type==P_TYPE)
+    if(s->avctx->rc_qmod_freq && frame_num%s->avctx->rc_qmod_freq==0 && pict_type==FF_P_TYPE)
         q*= s->avctx->rc_qmod_amp;
 
     bits= qp2bits(rce, q);
@@ -689,7 +689,7 @@
 //printf("input_pic_num:%d pic_num:%d frame_rate:%d\n", s->input_picture_number, s->picture_number, s->frame_rate);
         /* update predictors */
     if(picture_number>2 && !dry_run){
-        const int last_var= s->last_pict_type == I_TYPE ? rcc->last_mb_var_sum : rcc->last_mc_mb_var_sum;
+        const int last_var= s->last_pict_type == FF_I_TYPE ? rcc->last_mb_var_sum : rcc->last_mc_mb_var_sum;
         update_predictor(&rcc->pred[s->last_pict_type], rcc->last_qscale, sqrt(last_var), s->frame_bits);
     }
 
@@ -704,7 +704,7 @@
 
         //FIXME add a dts field to AVFrame and ensure its set and use it here instead of reordering
         //but the reordering is simpler for now until h.264 b pyramid must be handeld
-        if(s->pict_type == B_TYPE || s->low_delay)
+        if(s->pict_type == FF_B_TYPE || s->low_delay)
             dts_pic= s->current_picture_ptr;
         else
             dts_pic= s->last_picture_ptr;
@@ -726,11 +726,11 @@
     br_compensation= (a->bit_rate_tolerance - diff)/a->bit_rate_tolerance;
     if(br_compensation<=0.0) br_compensation=0.001;
 
-    var= pict_type == I_TYPE ? pic->mb_var_sum : pic->mc_mb_var_sum;
+    var= pict_type == FF_I_TYPE ? pic->mb_var_sum : pic->mc_mb_var_sum;
 
     short_term_q = 0; /* avoid warning */
     if(s->flags&CODEC_FLAG_PASS2){
-        if(pict_type!=I_TYPE)
+        if(pict_type!=FF_I_TYPE)
             assert(pict_type == rce->new_pict_type);
 
         q= rce->new_qscale / br_compensation;
@@ -746,7 +746,7 @@
         rce->misc_bits= 1;
 
         bits= predict_size(&rcc->pred[pict_type], rce->qscale, sqrt(var));
-        if(pict_type== I_TYPE){
+        if(pict_type== FF_I_TYPE){
             rce->i_count   = s->mb_num;
             rce->i_tex_bits= bits;
             rce->p_tex_bits= 0;
@@ -776,7 +776,7 @@
 //printf("%f ", q);
         assert(q>0.0);
 
-        if(pict_type==P_TYPE || s->intra_only){ //FIXME type dependent blur like in 2-pass
+        if(pict_type==FF_P_TYPE || s->intra_only){ //FIXME type dependent blur like in 2-pass
             rcc->short_term_qsum*=a->qblur;
             rcc->short_term_qcount*=a->qblur;
 
@@ -859,7 +859,7 @@
         complexity[rce->new_pict_type]+= (rce->i_tex_bits+ rce->p_tex_bits)*(double)rce->qscale;
         const_bits[rce->new_pict_type]+= rce->mv_bits + rce->misc_bits;
     }
-    all_const_bits= const_bits[I_TYPE] + const_bits[P_TYPE] + const_bits[B_TYPE];
+    all_const_bits= const_bits[FF_I_TYPE] + const_bits[FF_P_TYPE] + const_bits[FF_B_TYPE];
 
     if(all_available_bits < all_const_bits){
         av_log(s->avctx, AV_LOG_ERROR, "requested bitrate is too low\n");
Index: mythtv/libs/libavcodec/mpegvideo_common.h
===================================================================
--- mythtv/libs/libavcodec/mpegvideo_common.h	(revision 18209)
+++ mythtv/libs/libavcodec/mpegvideo_common.h	(working copy)
@@ -608,7 +608,7 @@
 
     prefetch_motion(s, ref_picture, dir);
 
-    if(s->obmc && s->pict_type != B_TYPE){
+    if(s->obmc && s->pict_type != FF_B_TYPE){
         int16_t mv_cache[4][4][2];
         const int xy= s->mb_x + s->mb_y*s->mb_stride;
         const int mot_stride= s->b8_stride;
@@ -770,7 +770,7 @@
                             s->mv[dir][1][0], s->mv[dir][1][1], 8);
             }
         } else {
-            if(s->picture_structure != s->field_select[dir][0] + 1 && s->pict_type != B_TYPE && !s->first_field){
+            if(s->picture_structure != s->field_select[dir][0] + 1 && s->pict_type != FF_B_TYPE && !s->first_field){
                 ref_picture= s->current_picture_ptr->data;
             }
 
@@ -784,7 +784,7 @@
         for(i=0; i<2; i++){
             uint8_t ** ref2picture;
 
-            if(s->picture_structure == s->field_select[dir][i] + 1 || s->pict_type == B_TYPE || s->first_field){
+            if(s->picture_structure == s->field_select[dir][i] + 1 || s->pict_type == FF_B_TYPE || s->first_field){
                 ref2picture= ref_picture;
             }else{
                 ref2picture= s->current_picture_ptr->data;
Index: mythtv/libs/libavcodec/parser.c
===================================================================
--- mythtv/libs/libavcodec/parser.c	(revision 18209)
+++ mythtv/libs/libavcodec/parser.c	(working copy)
@@ -192,7 +192,7 @@
     *poutbuf_size= buf_size;
     if(avctx->extradata){
         if(  (keyframe && (avctx->flags2 & CODEC_FLAG2_LOCAL_HEADER))
-            /*||(s->pict_type != I_TYPE && (s->flags & PARSER_FLAG_DUMP_EXTRADATA_AT_NOKEY))*/
+            /*||(s->pict_type != FF_I_TYPE && (s->flags & PARSER_FLAG_DUMP_EXTRADATA_AT_NOKEY))*/
             /*||(? && (s->flags & PARSER_FLAG_DUMP_EXTRADATA_AT_BEGIN)*/){
             int size= buf_size + avctx->extradata_size;
             *poutbuf_size= size;
Index: mythtv/libs/libavcodec/c93.c
===================================================================
--- mythtv/libs/libavcodec/c93.c	(revision 18209)
+++ mythtv/libs/libavcodec/c93.c	(working copy)
@@ -45,13 +45,13 @@
 #define C93_HAS_PALETTE 0x01
 #define C93_FIRST_FRAME 0x02
 
-static int decode_init(AVCodecContext *avctx)
+static av_cold int decode_init(AVCodecContext *avctx)
 {
     avctx->pix_fmt = PIX_FMT_PAL8;
     return 0;
 }
 
-static int decode_end(AVCodecContext *avctx)
+static av_cold int decode_end(AVCodecContext *avctx)
 {
     C93DecoderContext * const c93 = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/vp56.c
===================================================================
--- mythtv/libs/libavcodec/vp56.c	(revision 18209)
+++ mythtv/libs/libavcodec/vp56.c	(working copy)
@@ -643,7 +643,7 @@
     return buf_size;
 }
 
-void vp56_init(AVCodecContext *avctx, int flip, int has_alpha)
+av_cold void vp56_init(AVCodecContext *avctx, int flip, int has_alpha)
 {
     vp56_context_t *s = avctx->priv_data;
     int i;
@@ -683,7 +683,7 @@
     }
 }
 
-int vp56_free(AVCodecContext *avctx)
+av_cold int vp56_free(AVCodecContext *avctx)
 {
     vp56_context_t *s = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/roqvideodec.c
===================================================================
--- mythtv/libs/libavcodec/roqvideodec.c	(revision 18209)
+++ mythtv/libs/libavcodec/roqvideodec.c	(working copy)
@@ -154,7 +154,7 @@
 }
 
 
-static int roq_decode_init(AVCodecContext *avctx)
+static av_cold int roq_decode_init(AVCodecContext *avctx)
 {
     RoqContext *s = avctx->priv_data;
 
@@ -198,7 +198,7 @@
     return buf_size;
 }
 
-static int roq_decode_end(AVCodecContext *avctx)
+static av_cold int roq_decode_end(AVCodecContext *avctx)
 {
     RoqContext *s = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/bmpenc.c
===================================================================
--- mythtv/libs/libavcodec/bmpenc.c	(revision 18209)
+++ mythtv/libs/libavcodec/bmpenc.c	(working copy)
@@ -23,7 +23,7 @@
 #include "bytestream.h"
 #include "bmp.h"
 
-static int bmp_encode_init(AVCodecContext *avctx){
+static av_cold int bmp_encode_init(AVCodecContext *avctx){
     BMPContext *s = avctx->priv_data;
 
     avcodec_get_frame_defaults((AVFrame*)&s->picture);
Index: mythtv/libs/libavcodec/flac.c
===================================================================
--- mythtv/libs/libavcodec/flac.c	(revision 18209)
+++ mythtv/libs/libavcodec/flac.c	(working copy)
@@ -98,7 +98,7 @@
 static void allocate_buffers(FLACContext *s);
 static int metadata_parse(FLACContext *s);
 
-static int flac_decode_init(AVCodecContext * avctx)
+static av_cold int flac_decode_init(AVCodecContext * avctx)
 {
     FLACContext *s = avctx->priv_data;
     s->avctx = avctx;
@@ -720,7 +720,7 @@
 
 //    s->last_blocksize = s->blocksize;
 end:
-    i= (get_bits_count(&s->gb)+7)/8;;
+    i= (get_bits_count(&s->gb)+7)/8;
     if(i > buf_size){
         av_log(s->avctx, AV_LOG_ERROR, "overread: %d\n", i - buf_size);
         s->bitstream_size=0;
@@ -736,7 +736,7 @@
         return i;
 }
 
-static int flac_decode_close(AVCodecContext *avctx)
+static av_cold int flac_decode_close(AVCodecContext *avctx)
 {
     FLACContext *s = avctx->priv_data;
     int i;
Index: mythtv/libs/libavcodec/mpc7.c
===================================================================
--- mythtv/libs/libavcodec/mpc7.c	(revision 18209)
+++ mythtv/libs/libavcodec/mpc7.c	(working copy)
@@ -44,7 +44,7 @@
 
 static VLC scfi_vlc, dscf_vlc, hdr_vlc, quant_vlc[MPC7_QUANT_VLC_TABLES][2];
 
-static int mpc7_decode_init(AVCodecContext * avctx)
+static av_cold int mpc7_decode_init(AVCodecContext * avctx)
 {
     int i, j;
     MPCContext *c = avctx->priv_data;
Index: mythtv/libs/libavcodec/sgienc.c
===================================================================
--- mythtv/libs/libavcodec/sgienc.c	(revision 18209)
+++ mythtv/libs/libavcodec/sgienc.c	(working copy)
@@ -31,7 +31,7 @@
     AVFrame picture;
 } SgiContext;
 
-static int encode_init(AVCodecContext *avctx){
+static av_cold int encode_init(AVCodecContext *avctx){
     SgiContext *s = avctx->priv_data;
 
     avcodec_get_frame_defaults(&s->picture);
Index: mythtv/libs/libavcodec/cinepak.c
===================================================================
--- mythtv/libs/libavcodec/cinepak.c	(revision 18209)
+++ mythtv/libs/libavcodec/cinepak.c	(working copy)
@@ -387,7 +387,7 @@
     return 0;
 }
 
-static int cinepak_decode_init(AVCodecContext *avctx)
+static av_cold int cinepak_decode_init(AVCodecContext *avctx)
 {
     CinepakContext *s = avctx->priv_data;
 
@@ -447,7 +447,7 @@
     return buf_size;
 }
 
-static int cinepak_decode_end(AVCodecContext *avctx)
+static av_cold int cinepak_decode_end(AVCodecContext *avctx)
 {
     CinepakContext *s = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/dxa.c
===================================================================
--- mythtv/libs/libavcodec/dxa.c	(revision 18209)
+++ mythtv/libs/libavcodec/dxa.c	(working copy)
@@ -285,7 +285,7 @@
     return orig_buf_size;
 }
 
-static int decode_init(AVCodecContext *avctx)
+static av_cold int decode_init(AVCodecContext *avctx)
 {
     DxaDecContext * const c = avctx->priv_data;
 
@@ -305,7 +305,7 @@
     return 0;
 }
 
-static int decode_end(AVCodecContext *avctx)
+static av_cold int decode_end(AVCodecContext *avctx)
 {
     DxaDecContext * const c = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/msrle.c
===================================================================
--- mythtv/libs/libavcodec/msrle.c	(revision 18209)
+++ mythtv/libs/libavcodec/msrle.c	(working copy)
@@ -236,7 +236,7 @@
             stream_ptr, s->size);
 }
 
-static int msrle_decode_init(AVCodecContext *avctx)
+static av_cold int msrle_decode_init(AVCodecContext *avctx)
 {
     MsrleContext *s = avctx->priv_data;
 
@@ -283,7 +283,7 @@
     return buf_size;
 }
 
-static int msrle_decode_end(AVCodecContext *avctx)
+static av_cold int msrle_decode_end(AVCodecContext *avctx)
 {
     MsrleContext *s = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/dpcm.c
===================================================================
--- mythtv/libs/libavcodec/dpcm.c	(revision 18209)
+++ mythtv/libs/libavcodec/dpcm.c	(working copy)
@@ -110,7 +110,7 @@
 
 
 
-static int dpcm_decode_init(AVCodecContext *avctx)
+static av_cold int dpcm_decode_init(AVCodecContext *avctx)
 {
     DPCMContext *s = avctx->priv_data;
     int i;
Index: mythtv/libs/libavcodec/armv4l/mpegvideo_arm.c
===================================================================
--- mythtv/libs/libavcodec/armv4l/mpegvideo_arm.c	(revision 18209)
+++ mythtv/libs/libavcodec/armv4l/mpegvideo_arm.c	(working copy)
@@ -28,7 +28,7 @@
 void MPV_common_init_armv4l(MpegEncContext *s)
 {
     /* IWMMXT support is a superset of armv5te, so
-     * allow optimised functions for armv5te unless
+     * allow optimized functions for armv5te unless
      * a better iwmmxt function exists
      */
 #ifdef HAVE_ARMV5TE
Index: mythtv/libs/libavcodec/dca.c
===================================================================
--- mythtv/libs/libavcodec/dca.c	(revision 18209)
+++ mythtv/libs/libavcodec/dca.c	(working copy)
@@ -177,7 +177,7 @@
     DSPContext dsp;
 } DCAContext;
 
-static void dca_init_vlcs(void)
+static av_cold void dca_init_vlcs(void)
 {
     static int vlcs_inited = 0;
     int i, j;
@@ -1208,7 +1208,7 @@
  * @param s     pointer to the DCAContext
  */
 
-static void pre_calc_cosmod(DCAContext * s)
+static av_cold void pre_calc_cosmod(DCAContext * s)
 {
     int i, j, k;
     static int cosmod_inited = 0;
@@ -1238,7 +1238,7 @@
  * @param avctx     pointer to the AVCodecContext
  */
 
-static int dca_decode_init(AVCodecContext * avctx)
+static av_cold int dca_decode_init(AVCodecContext * avctx)
 {
     DCAContext *s = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/mjpegenc.c
===================================================================
--- mythtv/libs/libavcodec/mjpegenc.c	(revision 18209)
+++ mythtv/libs/libavcodec/mjpegenc.c	(working copy)
@@ -44,7 +44,7 @@
 #undef TWOMATRIXES
 
 
-int ff_mjpeg_encode_init(MpegEncContext *s)
+av_cold int ff_mjpeg_encode_init(MpegEncContext *s)
 {
     MJpegContext *m;
 
Index: mythtv/libs/libavcodec/ws-snd1.c
===================================================================
--- mythtv/libs/libavcodec/ws-snd1.c	(revision 18209)
+++ mythtv/libs/libavcodec/ws-snd1.c	(working copy)
@@ -36,7 +36,7 @@
 
 #define CLIP8(a) if(a>127)a=127;if(a<-128)a=-128;
 
-static int ws_snd_decode_init(AVCodecContext * avctx)
+static av_cold int ws_snd_decode_init(AVCodecContext * avctx)
 {
 //    WSSNDContext *c = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/sgidec.c
===================================================================
--- mythtv/libs/libavcodec/sgidec.c	(revision 18209)
+++ mythtv/libs/libavcodec/sgidec.c	(working copy)
@@ -235,7 +235,7 @@
     }
 }
 
-static int sgi_init(AVCodecContext *avctx){
+static av_cold int sgi_init(AVCodecContext *avctx){
     SgiState *s = avctx->priv_data;
 
     avcodec_get_frame_defaults(&s->picture);
@@ -244,7 +244,7 @@
     return 0;
 }
 
-static int sgi_end(AVCodecContext *avctx)
+static av_cold int sgi_end(AVCodecContext *avctx)
 {
     SgiState * const s = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/mace.c
===================================================================
--- mythtv/libs/libavcodec/mace.c	(revision 18209)
+++ mythtv/libs/libavcodec/mace.c	(working copy)
@@ -392,7 +392,7 @@
 }
 /* \\\ */
 
-static int mace_decode_init(AVCodecContext * avctx)
+static av_cold int mace_decode_init(AVCodecContext * avctx)
 {
     if (avctx->channels > 2)
         return -1;
Index: mythtv/libs/libavcodec/aasc.c
===================================================================
--- mythtv/libs/libavcodec/aasc.c	(revision 18209)
+++ mythtv/libs/libavcodec/aasc.c	(working copy)
@@ -44,7 +44,7 @@
     } \
     stream_byte = buf[stream_ptr++];
 
-static int aasc_decode_init(AVCodecContext *avctx)
+static av_cold int aasc_decode_init(AVCodecContext *avctx)
 {
     AascContext *s = avctx->priv_data;
 
@@ -150,7 +150,7 @@
     return buf_size;
 }
 
-static int aasc_decode_end(AVCodecContext *avctx)
+static av_cold int aasc_decode_end(AVCodecContext *avctx)
 {
     AascContext *s = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/vmdav.c
===================================================================
--- mythtv/libs/libavcodec/vmdav.c	(revision 18209)
+++ mythtv/libs/libavcodec/vmdav.c	(working copy)
@@ -324,7 +324,7 @@
     }
 }
 
-static int vmdvideo_decode_init(AVCodecContext *avctx)
+static av_cold int vmdvideo_decode_init(AVCodecContext *avctx)
 {
     VmdVideoContext *s = avctx->priv_data;
     int i;
@@ -401,7 +401,7 @@
     return buf_size;
 }
 
-static int vmdvideo_decode_end(AVCodecContext *avctx)
+static av_cold int vmdvideo_decode_end(AVCodecContext *avctx)
 {
     VmdVideoContext *s = avctx->priv_data;
 
@@ -441,7 +441,7 @@
     0xF00, 0x1000, 0x1400, 0x1800, 0x1C00, 0x2000, 0x3000, 0x4000
 };
 
-static int vmdaudio_decode_init(AVCodecContext *avctx)
+static av_cold int vmdaudio_decode_init(AVCodecContext *avctx)
 {
     VmdAudioContext *s = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/ulti.c
===================================================================
--- mythtv/libs/libavcodec/ulti.c	(revision 18209)
+++ mythtv/libs/libavcodec/ulti.c	(working copy)
@@ -41,7 +41,7 @@
     const uint8_t *ulti_codebook;
 } UltimotionDecodeContext;
 
-static int ulti_decode_init(AVCodecContext *avctx)
+static av_cold int ulti_decode_init(AVCodecContext *avctx)
 {
     UltimotionDecodeContext *s = avctx->priv_data;
 
@@ -393,7 +393,7 @@
     return buf_size;
 }
 
-static int ulti_decode_end(AVCodecContext *avctx)
+static av_cold int ulti_decode_end(AVCodecContext *avctx)
 {
 /*    UltimotionDecodeContext *s = avctx->priv_data;*/
 
Index: mythtv/libs/libavcodec/mjpegdec.c
===================================================================
--- mythtv/libs/libavcodec/mjpegdec.c	(revision 18209)
+++ mythtv/libs/libavcodec/mjpegdec.c	(working copy)
@@ -73,7 +73,7 @@
               ff_mjpeg_val_ac_chrominance, 251, 0, 1);
 }
 
-int ff_mjpeg_decode_init(AVCodecContext *avctx)
+av_cold int ff_mjpeg_decode_init(AVCodecContext *avctx)
 {
     MJpegDecodeContext *s = avctx->priv_data;
 
@@ -1284,7 +1284,7 @@
                         *data_size = sizeof(AVFrame);
 
                         if(!s->lossless){
-                            picture->quality= FFMAX(FFMAX(s->qscale[0], s->qscale[1]), s->qscale[2]);
+                            picture->quality= FFMAX3(s->qscale[0], s->qscale[1], s->qscale[2]);
                             picture->qstride= 0;
                             picture->qscale_table= s->qscale_table;
                             memset(picture->qscale_table, picture->quality, (s->width+15)/16);
@@ -1338,7 +1338,7 @@
     return buf_ptr - buf;
 }
 
-int ff_mjpeg_decode_end(AVCodecContext *avctx)
+av_cold int ff_mjpeg_decode_end(AVCodecContext *avctx)
 {
     MJpegDecodeContext *s = avctx->priv_data;
     int i, j;
Index: mythtv/libs/libavcodec/mjpegbdec.c
===================================================================
--- mythtv/libs/libavcodec/mjpegbdec.c	(revision 18209)
+++ mythtv/libs/libavcodec/mjpegbdec.c	(working copy)
@@ -123,7 +123,7 @@
     *data_size = sizeof(AVFrame);
 
     if(!s->lossless){
-        picture->quality= FFMAX(FFMAX(s->qscale[0], s->qscale[1]), s->qscale[2]);
+        picture->quality= FFMAX3(s->qscale[0], s->qscale[1], s->qscale[2]);
         picture->qstride= 0;
         picture->qscale_table= s->qscale_table;
         memset(picture->qscale_table, picture->quality, (s->width+15)/16);
Index: mythtv/libs/libavcodec/h264data.h
===================================================================
--- mythtv/libs/libavcodec/h264data.h	(revision 18209)
+++ mythtv/libs/libavcodec/h264data.h	(working copy)
@@ -54,7 +54,7 @@
 NAL_AUXILIARY_SLICE=19
 };
 
-static const AVRational pixel_aspect[14]={
+static const AVRational pixel_aspect[17]={
  {0, 1},
  {1, 1},
  {12, 11},
@@ -69,10 +69,13 @@
  {15, 11},
  {64, 33},
  {160,99},
+ {4, 3},
+ {3, 2},
+ {2, 1},
 };
 
 static const uint8_t golomb_to_pict_type[5]=
-{P_TYPE, B_TYPE, I_TYPE, SP_TYPE, SI_TYPE};
+{FF_P_TYPE, FF_B_TYPE, FF_I_TYPE, FF_SP_TYPE, FF_SI_TYPE};
 
 static const uint8_t pict_type_to_golomb[7]=
 {-1, 2, 0, 1, -1, 4, 3};
@@ -109,6 +112,14 @@
   6, 24, 25, 20, 26, 21, 46, 28, 27, 47, 22, 29, 23, 30, 31, 12
 };
 
+static const uint8_t golomb_to_inter_cbp_gray[16]={
+ 0, 1, 2, 4, 8, 3, 5,10,12,15, 7,11,13,14, 6, 9,
+};
+
+static const uint8_t golomb_to_intra4x4_cbp_gray[16]={
+15, 0, 7,11,13,14, 3, 5,10,12, 1, 2, 4, 8, 6, 9,
+};
+
 static const uint8_t chroma_dc_coeff_token_len[4*5]={
  2, 0, 0, 0,
  6, 1, 0, 0,
Index: mythtv/libs/libavcodec/dvbsub_parser.c
===================================================================
--- mythtv/libs/libavcodec/dvbsub_parser.c	(revision 18209)
+++ mythtv/libs/libavcodec/dvbsub_parser.c	(working copy)
@@ -38,7 +38,7 @@
     int in_packet;
 } DVBSubParseContext;
 
-static int dvbsub_parse_init(AVCodecParserContext *s)
+static av_cold int dvbsub_parse_init(AVCodecParserContext *s)
 {
     DVBSubParseContext *pc = s->priv_data;
     pc->packet_buf = av_malloc(PARSE_BUF_SIZE);
@@ -181,7 +181,7 @@
     return buf_size;
 }
 
-static void dvbsub_parse_close(AVCodecParserContext *s)
+static av_cold void dvbsub_parse_close(AVCodecParserContext *s)
 {
     DVBSubParseContext *pc = s->priv_data;
     av_freep(&pc->packet_buf);
Index: mythtv/libs/libavcodec/ffv1.c
===================================================================
--- mythtv/libs/libavcodec/ffv1.c	(revision 18209)
+++ mythtv/libs/libavcodec/ffv1.c	(working copy)
@@ -530,7 +530,7 @@
 }
 #endif /* CONFIG_ENCODERS */
 
-static int common_init(AVCodecContext *avctx){
+static av_cold int common_init(AVCodecContext *avctx){
     FFV1Context *s = avctx->priv_data;
     int width, height;
 
@@ -548,7 +548,7 @@
 }
 
 #ifdef CONFIG_ENCODERS
-static int encode_init(AVCodecContext *avctx)
+static av_cold int encode_init(AVCodecContext *avctx)
 {
     FFV1Context *s = avctx->priv_data;
     int i;
@@ -694,7 +694,7 @@
 }
 #endif /* CONFIG_ENCODERS */
 
-static int common_end(AVCodecContext *avctx){
+static av_cold int common_end(AVCodecContext *avctx){
     FFV1Context *s = avctx->priv_data;
     int i;
 
@@ -927,7 +927,7 @@
     return 0;
 }
 
-static int decode_init(AVCodecContext *avctx)
+static av_cold int decode_init(AVCodecContext *avctx)
 {
 //    FFV1Context *s = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/flashsv.c
===================================================================
--- mythtv/libs/libavcodec/flashsv.c	(revision 18209)
+++ mythtv/libs/libavcodec/flashsv.c	(working copy)
@@ -79,7 +79,7 @@
 }
 
 
-static int flashsv_decode_init(AVCodecContext *avctx)
+static av_cold int flashsv_decode_init(AVCodecContext *avctx)
 {
     FlashSVContext *s = avctx->priv_data;
     int zret; // Zlib return code
@@ -228,7 +228,7 @@
 }
 
 
-static int flashsv_decode_end(AVCodecContext *avctx)
+static av_cold int flashsv_decode_end(AVCodecContext *avctx)
 {
     FlashSVContext *s = avctx->priv_data;
     inflateEnd(&(s->zstream));
Index: mythtv/libs/libavcodec/mpc8.c
===================================================================
--- mythtv/libs/libavcodec/mpc8.c	(revision 18209)
+++ mythtv/libs/libavcodec/mpc8.c	(working copy)
@@ -92,7 +92,7 @@
     return mask;
 }
 
-static int mpc8_decode_init(AVCodecContext * avctx)
+static av_cold int mpc8_decode_init(AVCodecContext * avctx)
 {
     int i;
     MPCContext *c = avctx->priv_data;
Index: mythtv/libs/libavcodec/jpeglsenc.c
===================================================================
--- mythtv/libs/libavcodec/jpeglsenc.c	(revision 18209)
+++ mythtv/libs/libavcodec/jpeglsenc.c	(working copy)
@@ -368,7 +368,7 @@
     return put_bits_count(&pb) >> 3;
 }
 
-static int encode_init_ls(AVCodecContext *ctx) {
+static av_cold int encode_init_ls(AVCodecContext *ctx) {
     JpeglsContext *c = (JpeglsContext*)ctx->priv_data;
 
     c->avctx = ctx;
Index: mythtv/libs/libavcodec/zmbv.c
===================================================================
--- mythtv/libs/libavcodec/zmbv.c	(revision 18209)
+++ mythtv/libs/libavcodec/zmbv.c	(working copy)
@@ -588,7 +588,7 @@
  * Init zmbv decoder
  *
  */
-static int decode_init(AVCodecContext *avctx)
+static av_cold int decode_init(AVCodecContext *avctx)
 {
     ZmbvContext * const c = avctx->priv_data;
     int zret; // Zlib return code
@@ -637,7 +637,7 @@
  * Uninit zmbv decoder
  *
  */
-static int decode_end(AVCodecContext *avctx)
+static av_cold int decode_end(AVCodecContext *avctx)
 {
     ZmbvContext * const c = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/avs.c
===================================================================
--- mythtv/libs/libavcodec/avs.c	(revision 18209)
+++ mythtv/libs/libavcodec/avs.c	(working copy)
@@ -141,7 +141,7 @@
     return buf_size;
 }
 
-static int avs_decode_init(AVCodecContext * avctx)
+static av_cold int avs_decode_init(AVCodecContext * avctx)
 {
     avctx->pix_fmt = PIX_FMT_PAL8;
     return 0;
Index: mythtv/libs/libavcodec/vp3.c
===================================================================
--- mythtv/libs/libavcodec/vp3.c	(revision 18209)
+++ mythtv/libs/libavcodec/vp3.c	(working copy)
@@ -269,7 +269,7 @@
     uint8_t qr_size [2][3][64];
     uint16_t qr_base[2][3][64];
 
-    /* this is a list of indices into the all_fragments array indicating
+    /* this is a list of indexes into the all_fragments array indicating
      * which of the fragments are coded */
     int *coded_fragment_list;
     int coded_fragment_list_index;
@@ -291,19 +291,19 @@
     DECLARE_ALIGNED_16(int16_t, qmat[2][4][64]);        //<qmat[is_inter][plane]
 
     /* This table contains superblock_count * 16 entries. Each set of 16
-     * numbers corresponds to the fragment indices 0..15 of the superblock.
+     * numbers corresponds to the fragment indexes 0..15 of the superblock.
      * An entry will be -1 to indicate that no entry corresponds to that
      * index. */
     int *superblock_fragments;
 
     /* This table contains superblock_count * 4 entries. Each set of 4
-     * numbers corresponds to the macroblock indices 0..3 of the superblock.
+     * numbers corresponds to the macroblock indexes 0..3 of the superblock.
      * An entry will be -1 to indicate that no entry corresponds to that
      * index. */
     int *superblock_macroblocks;
 
     /* This table contains macroblock_count * 6 entries. Each set of 6
-     * numbers corresponds to the fragment indices 0..5 which comprise
+     * numbers corresponds to the fragment indexes 0..5 which comprise
      * the macroblock (4 Y fragments and 2 C fragments). */
     int *macroblock_fragments;
     /* This is an array that indicates how a particular macroblock
@@ -473,7 +473,7 @@
     current_width = -1;
     current_height = 0;
     superblock_row_inc = s->macroblock_width -
-        (s->y_superblock_width * 2 - s->macroblock_width);;
+        (s->y_superblock_width * 2 - s->macroblock_width);
     hilbert = hilbert_walk_mb;
     mapping_index = 0;
     current_macroblock = -1;
@@ -1223,7 +1223,7 @@
     int ac_c_table;
     int residual_eob_run = 0;
 
-    /* fetch the DC table indices */
+    /* fetch the DC table indexes */
     dc_y_table = get_bits(gb, 4);
     dc_c_table = get_bits(gb, 4);
 
@@ -1239,7 +1239,7 @@
     residual_eob_run = unpack_vlcs(s, gb, &s->dc_vlc[dc_c_table], 0,
         s->first_coded_c_fragment, s->last_coded_c_fragment, residual_eob_run);
 
-    /* fetch the AC table indices */
+    /* fetch the AC table indexes */
     ac_y_table = get_bits(gb, 4);
     ac_c_table = get_bits(gb, 4);
 
@@ -1331,7 +1331,7 @@
     /* DC values for the left, up-left, up, and up-right fragments */
     int vl, vul, vu, vur;
 
-    /* indices for the left, up-left, up, and up-right fragments */
+    /* indexes for the left, up-left, up, and up-right fragments */
     int l, ul, u, ur;
 
     /*
@@ -1933,7 +1933,7 @@
 /*
  * This is the ffmpeg/libavcodec API init function.
  */
-static int vp3_decode_init(AVCodecContext *avctx)
+static av_cold int vp3_decode_init(AVCodecContext *avctx)
 {
     Vp3DecodeContext *s = avctx->priv_data;
     int i, inter, plane;
@@ -2310,7 +2310,7 @@
 /*
  * This is the ffmpeg/libavcodec API module cleanup function.
  */
-static int vp3_decode_end(AVCodecContext *avctx)
+static av_cold int vp3_decode_end(AVCodecContext *avctx)
 {
     Vp3DecodeContext *s = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/sonic.c
===================================================================
--- mythtv/libs/libavcodec/sonic.c	(revision 18209)
+++ mythtv/libs/libavcodec/sonic.c	(working copy)
@@ -503,7 +503,7 @@
     return -1;
 }
 
-static int sonic_encode_init(AVCodecContext *avctx)
+static av_cold int sonic_encode_init(AVCodecContext *avctx)
 {
     SonicContext *s = avctx->priv_data;
     PutBitContext pb;
@@ -608,7 +608,7 @@
     return 0;
 }
 
-static int sonic_encode_close(AVCodecContext *avctx)
+static av_cold int sonic_encode_close(AVCodecContext *avctx)
 {
     SonicContext *s = avctx->priv_data;
     int i;
@@ -751,7 +751,7 @@
 #endif //CONFIG_ENCODERS
 
 #ifdef CONFIG_DECODERS
-static int sonic_decode_init(AVCodecContext *avctx)
+static av_cold int sonic_decode_init(AVCodecContext *avctx)
 {
     SonicContext *s = avctx->priv_data;
     GetBitContext gb;
@@ -831,7 +831,7 @@
     return 0;
 }
 
-static int sonic_decode_close(AVCodecContext *avctx)
+static av_cold int sonic_decode_close(AVCodecContext *avctx)
 {
     SonicContext *s = avctx->priv_data;
     int i;
Index: mythtv/libs/libavcodec/ptx.c
===================================================================
--- mythtv/libs/libavcodec/ptx.c	(revision 18209)
+++ mythtv/libs/libavcodec/ptx.c	(working copy)
@@ -25,7 +25,7 @@
     AVFrame picture;
 } PTXContext;
 
-static int ptx_init(AVCodecContext *avctx) {
+static av_cold int ptx_init(AVCodecContext *avctx) {
     PTXContext *s = avctx->priv_data;
 
     avcodec_get_frame_defaults((AVFrame*)&s->picture);
@@ -95,7 +95,7 @@
     return offset + w*h*bytes_per_pixel;
 }
 
-static int ptx_end(AVCodecContext *avctx) {
+static av_cold int ptx_end(AVCodecContext *avctx) {
     PTXContext *s = avctx->priv_data;
 
     if(s->picture.data[0])
Index: mythtv/libs/libavcodec/lzw.c
===================================================================
--- mythtv/libs/libavcodec/lzw.c	(revision 18209)
+++ mythtv/libs/libavcodec/lzw.c	(working copy)
@@ -109,12 +109,12 @@
         s->pbuf= s->ebuf;
 }
 
-void ff_lzw_decode_open(LZWState **p)
+av_cold void ff_lzw_decode_open(LZWState **p)
 {
     *p = av_mallocz(sizeof(struct LZWState));
 }
 
-void ff_lzw_decode_close(LZWState **p)
+av_cold void ff_lzw_decode_close(LZWState **p)
 {
     av_freep(p);
 }
Index: mythtv/libs/libavcodec/qtrleenc.c
===================================================================
--- mythtv/libs/libavcodec/qtrleenc.c	(revision 18209)
+++ mythtv/libs/libavcodec/qtrleenc.c	(working copy)
@@ -57,7 +57,7 @@
     uint8_t* skip_table;
 } QtrleEncContext;
 
-static int qtrle_encode_init(AVCodecContext *avctx)
+static av_cold int qtrle_encode_init(AVCodecContext *avctx)
 {
     QtrleEncContext *s = avctx->priv_data;
 
@@ -303,7 +303,7 @@
     return chunksize;
 }
 
-static int qtrle_encode_end(AVCodecContext *avctx)
+static av_cold int qtrle_encode_end(AVCodecContext *avctx)
 {
     QtrleEncContext *s = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/qdrw.c
===================================================================
--- mythtv/libs/libavcodec/qdrw.c	(revision 18209)
+++ mythtv/libs/libavcodec/qdrw.c	(working copy)
@@ -130,7 +130,7 @@
     return buf_size;
 }
 
-static int decode_init(AVCodecContext *avctx){
+static av_cold int decode_init(AVCodecContext *avctx){
 //    QdrawContext * const a = avctx->priv_data;
 
     if (avcodec_check_dimensions(avctx, avctx->width, avctx->height) < 0) {
Index: mythtv/libs/libavcodec/libgsm.c
===================================================================
--- mythtv/libs/libavcodec/libgsm.c	(revision 18209)
+++ mythtv/libs/libavcodec/libgsm.c	(working copy)
@@ -35,7 +35,7 @@
 #define GSM_MS_BLOCK_SIZE 65
 #define GSM_FRAME_SIZE 160
 
-static int libgsm_init(AVCodecContext *avctx) {
+static av_cold int libgsm_init(AVCodecContext *avctx) {
     if (avctx->channels > 1 || avctx->sample_rate != 8000 || avctx->bit_rate != 13000)
         return -1;
 
@@ -60,7 +60,7 @@
     return 0;
 }
 
-static int libgsm_close(AVCodecContext *avctx) {
+static av_cold int libgsm_close(AVCodecContext *avctx) {
     gsm_destroy(avctx->priv_data);
     avctx->priv_data = NULL;
     return 0;
Index: mythtv/libs/libavcodec/mpegvideo.c
===================================================================
--- mythtv/libs/libavcodec/mpegvideo.c	(revision 18209)
+++ mythtv/libs/libavcodec/mpegvideo.c	(working copy)
@@ -261,7 +261,7 @@
      * but it would require an API change. */
     memmove(s->prev_pict_types+1, s->prev_pict_types, PREV_PICT_TYPES_BUFFER_SIZE-1);
     s->prev_pict_types[0]= s->pict_type;
-    if(pic->age < PREV_PICT_TYPES_BUFFER_SIZE && s->prev_pict_types[pic->age] == B_TYPE)
+    if(pic->age < PREV_PICT_TYPES_BUFFER_SIZE && s->prev_pict_types[pic->age] == FF_B_TYPE)
         pic->age= INT_MAX; // Skipped MBs in B-frames are quite rare in MPEG-1/2 and it is a bit tricky to skip them anyway.
 
     return 0;
@@ -591,9 +591,7 @@
     s->context_initialized = 1;
 
     s->thread_context[0]= s;
-    /* h264 does thread context setup itself, but it needs context[0]
-     * to be fully initialized for the error resilience code */
-    threads = s->codec_id == CODEC_ID_H264 ? 1 : s->avctx->thread_count;
+    threads = s->avctx->thread_count;
 
     for(i=1; i<threads; i++){
         s->thread_context[i]= av_malloc(sizeof(MpegEncContext));
@@ -891,7 +889,7 @@
     assert(s->last_picture_ptr==NULL || s->out_format != FMT_H264 || s->codec_id == CODEC_ID_SVQ3);
 
     /* mark&release old frames */
-    if (s->pict_type != B_TYPE && s->last_picture_ptr && s->last_picture_ptr != s->next_picture_ptr && s->last_picture_ptr->data[0]) {
+    if (s->pict_type != FF_B_TYPE && s->last_picture_ptr && s->last_picture_ptr != s->next_picture_ptr && s->last_picture_ptr->data[0]) {
       if(s->out_format != FMT_H264 || s->codec_id == CODEC_ID_SVQ3){
         avctx->release_buffer(avctx, (AVFrame*)s->last_picture_ptr);
 
@@ -927,7 +925,7 @@
         if (!s->dropable){
             if (s->codec_id == CODEC_ID_H264)
                 pic->reference = s->picture_structure;
-            else if (s->pict_type != B_TYPE)
+            else if (s->pict_type != FF_B_TYPE)
                 pic->reference = 3;
         }
 
@@ -955,11 +953,11 @@
     s->current_picture_ptr->pict_type= s->pict_type;
 //    if(s->flags && CODEC_FLAG_QSCALE)
   //      s->current_picture_ptr->quality= s->new_picture_ptr->quality;
-    s->current_picture_ptr->key_frame= s->pict_type == I_TYPE;
+    s->current_picture_ptr->key_frame= s->pict_type == FF_I_TYPE;
 
     copy_picture(&s->current_picture, s->current_picture_ptr);
 
-    if (s->pict_type != B_TYPE) {
+    if (s->pict_type != FF_B_TYPE) {
         s->last_picture_ptr= s->next_picture_ptr;
         if(!s->dropable)
             s->next_picture_ptr= s->current_picture_ptr;
@@ -973,13 +971,13 @@
     if(s->last_picture_ptr) copy_picture(&s->last_picture, s->last_picture_ptr);
     if(s->next_picture_ptr) copy_picture(&s->next_picture, s->next_picture_ptr);
 
-    if(s->pict_type != I_TYPE && (s->last_picture_ptr==NULL || s->last_picture_ptr->data[0]==NULL) && !s->dropable){
+    if(s->pict_type != FF_I_TYPE && (s->last_picture_ptr==NULL || s->last_picture_ptr->data[0]==NULL) && !s->dropable){
         av_log(avctx, AV_LOG_ERROR, "warning: first frame is no keyframe\n");
-        assert(s->pict_type != B_TYPE); //these should have been dropped if we don't have a reference
+        assert(s->pict_type != FF_B_TYPE); //these should have been dropped if we don't have a reference
         goto alloc;
     }
 
-    assert(s->pict_type == I_TYPE || (s->last_picture_ptr && s->last_picture_ptr->data[0]));
+    assert(s->pict_type == FF_I_TYPE || (s->last_picture_ptr && s->last_picture_ptr->data[0]));
 
     if(s->picture_structure!=PICT_FRAME && s->out_format != FMT_H264){
         int i;
@@ -1042,7 +1040,7 @@
 
     s->last_pict_type    = s->pict_type;
     s->last_lambda_for[s->pict_type]= s->current_picture_ptr->quality;
-    if(s->pict_type!=B_TYPE){
+    if(s->pict_type!=FF_B_TYPE){
         s->last_non_b_pict_type= s->pict_type;
     }
 #if 0
@@ -1116,8 +1114,8 @@
         for(y= 0; y <= ey; y++){
             x = (y*f)>>16;
             fr= (y*f)&0xFFFF;
-            buf[y*stride + x  ]+= (color*(0x10000-fr))>>16;;
-            buf[y*stride + x+1]+= (color*         fr )>>16;;
+            buf[y*stride + x  ]+= (color*(0x10000-fr))>>16;
+            buf[y*stride + x+1]+= (color*         fr )>>16;
         }
     }
 }
@@ -1739,7 +1737,7 @@
                         ref_picture, pix_op,
                         s->mv[dir][1][0], s->mv[dir][1][1], block_s);
         } else {
-            if(s->picture_structure != s->field_select[dir][0] + 1 && s->pict_type != B_TYPE && !s->first_field){
+            if(s->picture_structure != s->field_select[dir][0] + 1 && s->pict_type != FF_B_TYPE && !s->first_field){
                 ref_picture= s->current_picture_ptr->data;
             }
 
@@ -1753,7 +1751,7 @@
         for(i=0; i<2; i++){
             uint8_t ** ref2picture;
 
-            if(s->picture_structure == s->field_select[dir][i] + 1 || s->pict_type == B_TYPE || s->first_field){
+            if(s->picture_structure == s->field_select[dir][i] + 1 || s->pict_type == FF_B_TYPE || s->first_field){
                 ref2picture= ref_picture;
             }else{
                 ref2picture= s->current_picture_ptr->data;
@@ -1911,14 +1909,14 @@
     else if (s->h263_pred || s->h263_aic)
         s->mbintra_table[mb_xy]=1;
 
-    if ((s->flags&CODEC_FLAG_PSNR) || !(s->encoding && (s->intra_only || s->pict_type==B_TYPE) && s->avctx->mb_decision != FF_MB_DECISION_RD)) { //FIXME precalc
+    if ((s->flags&CODEC_FLAG_PSNR) || !(s->encoding && (s->intra_only || s->pict_type==FF_B_TYPE) && s->avctx->mb_decision != FF_MB_DECISION_RD)) { //FIXME precalc
         uint8_t *dest_y, *dest_cb, *dest_cr;
         int dct_linesize, dct_offset;
         op_pixels_func (*op_pix)[4];
         qpel_mc_func (*op_qpix)[16];
         const int linesize= s->current_picture.linesize[0]; //not s->linesize as this would be wrong for field pics
         const int uvlinesize= s->current_picture.linesize[1];
-        const int readable= s->pict_type != B_TYPE || s->encoding || s->avctx->draw_horiz_band || lowres_flag;
+        const int readable= s->pict_type != FF_B_TYPE || s->encoding || s->avctx->draw_horiz_band || lowres_flag;
         const int block_size= lowres_flag ? 8>>s->avctx->lowres : 8;
 
         /* avoid copy if macroblock skipped in last frame too */
@@ -1931,7 +1929,7 @@
 
             if (s->mb_skipped) {
                 s->mb_skipped= 0;
-                assert(s->pict_type!=I_TYPE);
+                assert(s->pict_type!=FF_I_TYPE);
 
                 (*mbskip_ptr) ++; /* indicate that this time we skipped it */
                 if(*mbskip_ptr >99) *mbskip_ptr= 99;
@@ -1977,7 +1975,7 @@
                     }
                 }else{
                     op_qpix= s->me.qpel_put;
-                    if ((!s->no_rounding) || s->pict_type==B_TYPE){
+                    if ((!s->no_rounding) || s->pict_type==FF_B_TYPE){
                         op_pix = s->dsp.put_pixels_tab;
                     }else{
                         op_pix = s->dsp.put_no_rnd_pixels_tab;
@@ -1996,8 +1994,8 @@
             /* skip dequant / idct if we are really late ;) */
             if(s->hurry_up>1) goto skip_idct;
             if(s->avctx->skip_idct){
-                if(  (s->avctx->skip_idct >= AVDISCARD_NONREF && s->pict_type == B_TYPE)
-                   ||(s->avctx->skip_idct >= AVDISCARD_NONKEY && s->pict_type != I_TYPE)
+                if(  (s->avctx->skip_idct >= AVDISCARD_NONREF && s->pict_type == FF_B_TYPE)
+                   ||(s->avctx->skip_idct >= AVDISCARD_NONKEY && s->pict_type != FF_I_TYPE)
                    || s->avctx->skip_idct >= AVDISCARD_ALL)
                     goto skip_idct;
             }
@@ -2135,20 +2133,20 @@
 
         h= FFMIN(h, s->avctx->height - y);
 
-        if(s->pict_type==B_TYPE || s->low_delay || (s->avctx->slice_flags&SLICE_FLAG_CODED_ORDER))
+        if(s->pict_type==FF_B_TYPE || s->low_delay || (s->avctx->slice_flags&SLICE_FLAG_CODED_ORDER))
             src= (AVFrame*)s->current_picture_ptr;
         else if(s->last_picture_ptr)
             src= (AVFrame*)s->last_picture_ptr;
         else
             return;
 
-        if(s->pict_type==B_TYPE && s->picture_structure == PICT_FRAME && s->out_format != FMT_H264){
+        if(s->pict_type==FF_B_TYPE && s->picture_structure == PICT_FRAME && s->out_format != FMT_H264){
             offset[0]=
             offset[1]=
             offset[2]=
             offset[3]= 0;
         }else{
-            offset[0]= y * s->linesize;;
+            offset[0]= y * s->linesize;
             offset[1]=
             offset[2]= (y >> s->chroma_y_shift) * s->uvlinesize;
             offset[3]= 0;
@@ -2178,7 +2176,7 @@
     s->dest[1] = s->current_picture.data[1] + ((s->mb_x - 1) << (mb_size - s->chroma_x_shift));
     s->dest[2] = s->current_picture.data[2] + ((s->mb_x - 1) << (mb_size - s->chroma_x_shift));
 
-    if(!(s->pict_type==B_TYPE && s->avctx->draw_horiz_band && s->picture_structure==PICT_FRAME))
+    if(!(s->pict_type==FF_B_TYPE && s->avctx->draw_horiz_band && s->picture_structure==PICT_FRAME))
     {
         s->dest[0] += s->mb_y *   linesize << mb_size;
         s->dest[1] += s->mb_y * uvlinesize << (mb_size - s->chroma_y_shift);
Index: mythtv/libs/libavcodec/svq1enc.c
===================================================================
--- mythtv/libs/libavcodec/svq1enc.c	(revision 18209)
+++ mythtv/libs/libavcodec/svq1enc.c	(working copy)
@@ -82,7 +82,7 @@
     /* frame type */
     put_bits(&s->pb, 2, frame_type - 1);
 
-    if (frame_type == I_TYPE) {
+    if (frame_type == FF_I_TYPE) {
 
         /* no checksum since frame code is 0x20 */
 
@@ -283,7 +283,7 @@
     block_width = (width + 15) / 16;
     block_height = (height + 15) / 16;
 
-    if(s->picture.pict_type == P_TYPE){
+    if(s->picture.pict_type == FF_P_TYPE){
         s->m.avctx= s->avctx;
         s->m.current_picture_ptr= &s->m.current_picture;
         s->m.last_picture_ptr   = &s->m.last_picture;
@@ -389,11 +389,11 @@
             ff_init_block_index(&s->m);
             ff_update_block_index(&s->m);
 
-            if(s->picture.pict_type == I_TYPE || (s->m.mb_type[x + y*s->m.mb_stride]&CANDIDATE_MB_TYPE_INTRA)){
+            if(s->picture.pict_type == FF_I_TYPE || (s->m.mb_type[x + y*s->m.mb_stride]&CANDIDATE_MB_TYPE_INTRA)){
                 for(i=0; i<6; i++){
                     init_put_bits(&s->reorder_pb[i], reorder_buffer[0][i], 7*32);
                 }
-                if(s->picture.pict_type == P_TYPE){
+                if(s->picture.pict_type == FF_P_TYPE){
                     const uint8_t *vlc= ff_svq1_block_type_vlc[SVQ1_BLOCK_INTRA];
                     put_bits(&s->reorder_pb[5], vlc[1], vlc[0]);
                     score[0]= vlc[1]*lambda;
@@ -408,7 +408,7 @@
 
             best=0;
 
-            if(s->picture.pict_type == P_TYPE){
+            if(s->picture.pict_type == FF_P_TYPE){
                 const uint8_t *vlc= ff_svq1_block_type_vlc[SVQ1_BLOCK_INTER];
                 int mx, my, pred_x, pred_y, dxy;
                 int16_t *motion_ptr;
@@ -479,7 +479,7 @@
     return 0;
 }
 
-static int svq1_encode_init(AVCodecContext *avctx)
+static av_cold int svq1_encode_init(AVCodecContext *avctx)
 {
     SVQ1Context * const s = avctx->priv_data;
 
@@ -533,8 +533,8 @@
     init_put_bits(&s->pb, buf, buf_size);
 
     *p = *pict;
-    p->pict_type = avctx->gop_size && avctx->frame_number % avctx->gop_size ? P_TYPE : I_TYPE;
-    p->key_frame = p->pict_type == I_TYPE;
+    p->pict_type = avctx->gop_size && avctx->frame_number % avctx->gop_size ? FF_P_TYPE : FF_I_TYPE;
+    p->key_frame = p->pict_type == FF_I_TYPE;
 
     svq1_write_header(s, p->pict_type);
     for(i=0; i<3; i++){
@@ -554,7 +554,7 @@
     return (put_bits_count(&s->pb) / 8);
 }
 
-static int svq1_encode_end(AVCodecContext *avctx)
+static av_cold int svq1_encode_end(AVCodecContext *avctx)
 {
     SVQ1Context * const s = avctx->priv_data;
     int i;
Index: mythtv/libs/libavcodec/shorten.c
===================================================================
--- mythtv/libs/libavcodec/shorten.c	(revision 18209)
+++ mythtv/libs/libavcodec/shorten.c	(working copy)
@@ -100,7 +100,7 @@
     int32_t lpcqoffset;
 } ShortenContext;
 
-static int shorten_decode_init(AVCodecContext * avctx)
+static av_cold int shorten_decode_init(AVCodecContext * avctx)
 {
     ShortenContext *s = avctx->priv_data;
     s->avctx = avctx;
@@ -501,7 +501,7 @@
         return i;
 }
 
-static int shorten_decode_close(AVCodecContext *avctx)
+static av_cold int shorten_decode_close(AVCodecContext *avctx)
 {
     ShortenContext *s = avctx->priv_data;
     int i;
Index: mythtv/libs/libavcodec/xl.c
===================================================================
--- mythtv/libs/libavcodec/xl.c	(revision 18209)
+++ mythtv/libs/libavcodec/xl.c	(working copy)
@@ -118,7 +118,7 @@
     return buf_size;
 }
 
-static int decode_init(AVCodecContext *avctx){
+static av_cold int decode_init(AVCodecContext *avctx){
 //    VideoXLContext * const a = avctx->priv_data;
 
     avctx->pix_fmt= PIX_FMT_YUV411P;
Index: mythtv/libs/libavcodec/targaenc.c
===================================================================
--- mythtv/libs/libavcodec/targaenc.c	(revision 18209)
+++ mythtv/libs/libavcodec/targaenc.c	(working copy)
@@ -133,7 +133,7 @@
     return out + 26 - outbuf;
 }
 
-static int targa_encode_init(AVCodecContext *avctx)
+static av_cold int targa_encode_init(AVCodecContext *avctx)
 {
     return 0;
 }
Index: mythtv/libs/libavcodec/mpegvideo.h
===================================================================
--- mythtv/libs/libavcodec/mpegvideo.h	(revision 18209)
+++ mythtv/libs/libavcodec/mpegvideo.h	(working copy)
@@ -94,7 +94,7 @@
     uint8_t permutated[64];
     uint8_t raster_end[64];
 #ifdef ARCH_POWERPC
-                /** Used by dct_quantise_alitvec to find last-non-zero */
+                /** Used by dct_quantize_alitvec to find last-non-zero */
     DECLARE_ALIGNED_8(uint8_t, inverse[64]);
 #endif
 } ScanTable;
@@ -142,8 +142,8 @@
     int pic_id;                 /**< h264 pic_num (short -> no wrap version of pic_num,
                                      pic_num & max_pic_num; long -> long_pic_num) */
     int long_ref;               ///< 1->long term reference 0->short term reference
-    int ref_poc[2][16];         ///< h264 POCs of the frames used as reference
-    int ref_count[2];           ///< number of entries in ref_poc
+    int ref_poc[2][2][16];      ///< h264 POCs of the frames used as reference (FIXME need per slice)
+    int ref_count[2][2];        ///< number of entries in ref_poc              (FIXME need per slice)
 
     int mb_var_sum;             ///< sum of MB variance for current frame
     int mc_mb_var_sum;          ///< motion compensated MB variance for current frame
@@ -333,7 +333,7 @@
     int *lambda_table;
     int adaptive_quant;         ///< use adaptive quantization
     int dquant;                 ///< qscale difference to prev qscale
-    int pict_type;              ///< I_TYPE, P_TYPE, B_TYPE, ...
+    int pict_type;              ///< FF_I_TYPE, FF_P_TYPE, FF_B_TYPE, ...
     int last_pict_type; //FIXME removes
     int last_non_b_pict_type;   ///< used for mpeg4 gmc b-frames & ratecontrol
     int dropable;
Index: mythtv/libs/libavcodec/truemotion1.c
===================================================================
--- mythtv/libs/libavcodec/truemotion1.c	(revision 18209)
+++ mythtv/libs/libavcodec/truemotion1.c	(working copy)
@@ -461,7 +461,7 @@
     return header.header_size;
 }
 
-static int truemotion1_decode_init(AVCodecContext *avctx)
+static av_cold int truemotion1_decode_init(AVCodecContext *avctx)
 {
     TrueMotion1Context *s = avctx->priv_data;
 
@@ -877,7 +877,7 @@
     return buf_size;
 }
 
-static int truemotion1_decode_end(AVCodecContext *avctx)
+static av_cold int truemotion1_decode_end(AVCodecContext *avctx)
 {
     TrueMotion1Context *s = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/cabac.c
===================================================================
--- mythtv/libs/libavcodec/cabac.c	(revision 18209)
+++ mythtv/libs/libavcodec/cabac.c	(working copy)
@@ -178,13 +178,13 @@
     }
 }
 
-#if 0 //selftest
+#ifdef TEST
 #undef random
 #define SIZE 10240
 
 #include "avcodec.h"
 
-int main(){
+int main(void){
     CABACContext c;
     uint8_t b[9*SIZE];
     uint8_t r[9*SIZE];
@@ -262,4 +262,4 @@
     return 0;
 }
 
-#endif
+#endif /* TEST */
Index: mythtv/libs/libavcodec/libx264.c
===================================================================
--- mythtv/libs/libavcodec/libx264.c	(revision 18209)
+++ mythtv/libs/libavcodec/libx264.c	(working copy)
@@ -119,7 +119,7 @@
     return bufsize;
 }
 
-static int
+static av_cold int
 X264_close(AVCodecContext *avctx)
 {
     X264Context *x4 = avctx->priv_data;
@@ -130,7 +130,7 @@
     return 0;
 }
 
-static int
+static av_cold int
 X264_init(AVCodecContext *avctx)
 {
     X264Context *x4 = avctx->priv_data;
Index: mythtv/libs/libavcodec/mpeg12.c
===================================================================
--- mythtv/libs/libavcodec/mpeg12.c	(revision 18209)
+++ mythtv/libs/libavcodec/mpeg12.c	(working copy)
@@ -236,7 +236,7 @@
     assert(s->mb_skipped==0);
 
     if (s->mb_skip_run-- != 0) {
-        if (s->pict_type == P_TYPE) {
+        if (s->pict_type == FF_P_TYPE) {
             s->mb_skipped = 1;
             s->current_picture.mb_type[ s->mb_x + s->mb_y*s->mb_stride ]= MB_TYPE_SKIP | MB_TYPE_L0 | MB_TYPE_16x16;
         } else {
@@ -267,7 +267,7 @@
 
     switch(s->pict_type) {
     default:
-    case I_TYPE:
+    case FF_I_TYPE:
         if (get_bits1(&s->gb) == 0) {
             if (get_bits1(&s->gb) == 0){
                 av_log(s->avctx, AV_LOG_ERROR, "invalid mb type in I Frame at %d %d\n", s->mb_x, s->mb_y);
@@ -278,7 +278,7 @@
             mb_type = MB_TYPE_INTRA;
         }
         break;
-    case P_TYPE:
+    case FF_P_TYPE:
         mb_type = get_vlc2(&s->gb, mb_ptype_vlc.table, MB_PTYPE_VLC_BITS, 1);
         if (mb_type < 0){
             av_log(s->avctx, AV_LOG_ERROR, "invalid mb type in P Frame at %d %d\n", s->mb_x, s->mb_y);
@@ -286,7 +286,7 @@
         }
         mb_type = ptype2mb_type[ mb_type ];
         break;
-    case B_TYPE:
+    case FF_B_TYPE:
         mb_type = get_vlc2(&s->gb, mb_btype_vlc.table, MB_BTYPE_VLC_BITS, 1);
         if (mb_type < 0){
             av_log(s->avctx, AV_LOG_ERROR, "invalid mb type in B Frame at %d %d\n", s->mb_x, s->mb_y);
@@ -1339,7 +1339,7 @@
 
 } Mpeg1Context;
 
-static int mpeg_decode_init(AVCodecContext *avctx)
+static av_cold int mpeg_decode_init(AVCodecContext *avctx)
 {
     Mpeg1Context *s = avctx->priv_data;
     MpegEncContext *s2 = &s->mpeg_enc_ctx;
@@ -1510,7 +1510,7 @@
         return -1;
 
     vbv_delay= get_bits(&s->gb, 16);
-    if (s->pict_type == P_TYPE || s->pict_type == B_TYPE) {
+    if (s->pict_type == FF_P_TYPE || s->pict_type == FF_B_TYPE) {
         s->full_pel[0] = get_bits1(&s->gb);
         f_code = get_bits(&s->gb, 3);
         if (f_code == 0 && avctx->error_resilience >= FF_ER_COMPLIANT)
@@ -1518,7 +1518,7 @@
         s->mpeg_f_code[0][0] = f_code;
         s->mpeg_f_code[0][1] = f_code;
     }
-    if (s->pict_type == B_TYPE) {
+    if (s->pict_type == FF_B_TYPE) {
         s->full_pel[1] = get_bits1(&s->gb);
         f_code = get_bits(&s->gb, 3);
         if (f_code == 0 && avctx->error_resilience >= FF_ER_COMPLIANT)
@@ -1527,7 +1527,7 @@
         s->mpeg_f_code[1][1] = f_code;
     }
     s->current_picture.pict_type= s->pict_type;
-    s->current_picture.key_frame= s->pict_type == I_TYPE;
+    s->current_picture.key_frame= s->pict_type == FF_I_TYPE;
 
     if(avctx->debug & FF_DEBUG_PICT_INFO)
         av_log(avctx, AV_LOG_DEBUG, "vbv_delay %d, ref %d type:%d\n", vbv_delay, ref, s->pict_type);
@@ -1897,7 +1897,7 @@
         if(s->avctx->debug&FF_DEBUG_PICT_INFO){
              av_log(s->avctx, AV_LOG_DEBUG, "qp:%d fc:%2d%2d%2d%2d %s %s %s %s %s dc:%d pstruct:%d fdct:%d cmv:%d qtype:%d ivlc:%d rff:%d %s\n",
                  s->qscale, s->mpeg_f_code[0][0],s->mpeg_f_code[0][1],s->mpeg_f_code[1][0],s->mpeg_f_code[1][1],
-                 s->pict_type == I_TYPE ? "I" : (s->pict_type == P_TYPE ? "P" : (s->pict_type == B_TYPE ? "B" : "S")),
+                 s->pict_type == FF_I_TYPE ? "I" : (s->pict_type == FF_P_TYPE ? "P" : (s->pict_type == FF_B_TYPE ? "B" : "S")),
                  s->progressive_sequence ? "ps" :"", s->progressive_frame ? "pf" : "", s->alternate_scan ? "alt" :"", s->top_field_first ? "top" :"",
                  s->intra_dc_precision, s->picture_structure, s->frame_pred_frame_dct, s->concealment_motion_vectors,
                  s->q_scale_type, s->intra_vlc_format, s->repeat_first_field, s->chroma_420_type ? "420" :"");
@@ -1927,7 +1927,7 @@
 
             for(i=0; i<2; i++){
                 for(dir=0; dir<2; dir++){
-                    if (s->mb_intra || (dir==1 && s->pict_type != B_TYPE)) {
+                    if (s->mb_intra || (dir==1 && s->pict_type != FF_B_TYPE)) {
                         motion_x = motion_y = 0;
                     }else if (s->mv_type == MV_TYPE_16X16 || (s->mv_type == MV_TYPE_FIELD && field_pic)){
                         motion_x = s->mv[dir][0][0];
@@ -1972,7 +1972,7 @@
 
             if(s->mb_y<<field_pic >= s->mb_height){
                 int left= s->gb.size_in_bits - get_bits_count(&s->gb);
-                int is_d10= s->chroma_format==2 && s->pict_type==I_TYPE && avctx->profile==0 && avctx->level==5
+                int is_d10= s->chroma_format==2 && s->pict_type==FF_I_TYPE && avctx->profile==0 && avctx->level==5
                             && s->intra_dc_precision == 2 && s->q_scale_type == 1 && s->alternate_scan == 0
                             && s->progressive_frame == 0 /* vbv_delay == 0xBBB || 0xE10*/;
 
@@ -2015,7 +2015,7 @@
             }
             if(s->mb_skip_run){
                 int i;
-                if(s->pict_type == I_TYPE){
+                if(s->pict_type == FF_I_TYPE){
                     av_log(s->avctx, AV_LOG_ERROR, "skipped MB in I frame at %d %d\n", s->mb_x, s->mb_y);
                     return -1;
                 }
@@ -2028,7 +2028,7 @@
                     s->mv_type = MV_TYPE_16X16;
                 else
                     s->mv_type = MV_TYPE_FIELD;
-                if (s->pict_type == P_TYPE) {
+                if (s->pict_type == FF_P_TYPE) {
                     /* if P type, zero motion vector is implied */
                     s->mv_dir = MV_DIR_FORWARD;
                     s->mv[0][0][0] = s->mv[0][0][1] = 0;
@@ -2117,7 +2117,7 @@
 
         MPV_frame_end(s);
 
-        if (s->pict_type == B_TYPE || s->low_delay) {
+        if (s->pict_type == FF_B_TYPE || s->low_delay) {
             *pict= *(AVFrame*)s->current_picture_ptr;
             ff_print_debug_info(s, pict);
         } else {
@@ -2547,7 +2547,7 @@
         start_code = -1;
         buf_ptr = ff_find_start_code(buf_ptr,buf_end, &start_code);
         if (start_code > 0x1ff){
-            if(s2->pict_type != B_TYPE || avctx->skip_frame <= AVDISCARD_DEFAULT){
+            if(s2->pict_type != FF_B_TYPE || avctx->skip_frame <= AVDISCARD_DEFAULT){
                 if(avctx->thread_count > 1){
                     int i;
 
@@ -2601,14 +2601,14 @@
 
                 if(s2->last_picture_ptr==NULL){
                 /* Skip B-frames if we do not have reference frames. */
-                    if(s2->pict_type==B_TYPE) break;
+                    if(s2->pict_type==FF_B_TYPE) break;
                 /* Skip P-frames if we do not have reference frame no valid header. */
-//                    if(s2->pict_type==P_TYPE && s2->first_field && !s2->first_slice) break;
+//                    if(s2->pict_type==FF_P_TYPE && s2->first_field && !s2->first_slice) break;
                 }
                 /* Skip B-frames if we are in a hurry. */
-                if(avctx->hurry_up && s2->pict_type==B_TYPE) break;
-                if(  (avctx->skip_frame >= AVDISCARD_NONREF && s2->pict_type==B_TYPE)
-                    ||(avctx->skip_frame >= AVDISCARD_NONKEY && s2->pict_type!=I_TYPE)
+                if(avctx->hurry_up && s2->pict_type==FF_B_TYPE) break;
+                if(  (avctx->skip_frame >= AVDISCARD_NONREF && s2->pict_type==FF_B_TYPE)
+                    ||(avctx->skip_frame >= AVDISCARD_NONKEY && s2->pict_type!=FF_I_TYPE)
                     || avctx->skip_frame >= AVDISCARD_ALL)
                     break;
                 /* Skip everything if we are in a hurry>=5. */
@@ -2713,7 +2713,7 @@
 };
 
 #ifdef HAVE_XVMC
-static int mpeg_mc_decode_init(AVCodecContext *avctx){
+static av_cold int mpeg_mc_decode_init(AVCodecContext *avctx){
     Mpeg1Context *s;
 
     if( avctx->thread_count > 1)
Index: mythtv/libs/libavcodec/h263dec.c
===================================================================
--- mythtv/libs/libavcodec/h263dec.c	(revision 18209)
+++ mythtv/libs/libavcodec/h263dec.c	(working copy)
@@ -35,7 +35,7 @@
 //#define DEBUG
 //#define PRINT_FRAME_TIME
 
-int ff_h263_decode_init(AVCodecContext *avctx)
+av_cold int ff_h263_decode_init(AVCodecContext *avctx)
 {
     MpegEncContext *s = avctx->priv_data;
 
@@ -119,7 +119,7 @@
     return 0;
 }
 
-int ff_h263_decode_end(AVCodecContext *avctx)
+av_cold int ff_h263_decode_end(AVCodecContext *avctx)
 {
     MpegEncContext *s = avctx->priv_data;
 
@@ -208,7 +208,7 @@
 //printf("%d %d %06X\n", ret, get_bits_count(&s->gb), show_bits(&s->gb, 24));
             ret= s->decode_mb(s, s->block);
 
-            if (s->pict_type!=B_TYPE)
+            if (s->pict_type!=FF_B_TYPE)
                 ff_h263_update_motion_val(s);
 
             if(ret<0){
@@ -291,7 +291,7 @@
         int max_extra=7;
 
         /* no markers in M$ crap */
-        if(s->msmpeg4_version && s->pict_type==I_TYPE)
+        if(s->msmpeg4_version && s->pict_type==FF_I_TYPE)
             max_extra+= 17;
 
         /* buggy padding but the frame should still end approximately at the bitstream end */
@@ -581,30 +581,30 @@
 
     // for hurry_up==5
     s->current_picture.pict_type= s->pict_type;
-    s->current_picture.key_frame= s->pict_type == I_TYPE;
+    s->current_picture.key_frame= s->pict_type == FF_I_TYPE;
 
     /* skip B-frames if we don't have reference frames */
-    if(s->last_picture_ptr==NULL && (s->pict_type==B_TYPE || s->dropable)) return get_consumed_bytes(s, buf_size);
+    if(s->last_picture_ptr==NULL && (s->pict_type==FF_B_TYPE || s->dropable)) return get_consumed_bytes(s, buf_size);
     /* skip b frames if we are in a hurry */
-    if(avctx->hurry_up && s->pict_type==B_TYPE) return get_consumed_bytes(s, buf_size);
-    if(   (avctx->skip_frame >= AVDISCARD_NONREF && s->pict_type==B_TYPE)
-       || (avctx->skip_frame >= AVDISCARD_NONKEY && s->pict_type!=I_TYPE)
+    if(avctx->hurry_up && s->pict_type==FF_B_TYPE) return get_consumed_bytes(s, buf_size);
+    if(   (avctx->skip_frame >= AVDISCARD_NONREF && s->pict_type==FF_B_TYPE)
+       || (avctx->skip_frame >= AVDISCARD_NONKEY && s->pict_type!=FF_I_TYPE)
        ||  avctx->skip_frame >= AVDISCARD_ALL)
         return get_consumed_bytes(s, buf_size);
     /* skip everything if we are in a hurry>=5 */
     if(avctx->hurry_up>=5) return get_consumed_bytes(s, buf_size);
 
     if(s->next_p_frame_damaged){
-        if(s->pict_type==B_TYPE)
+        if(s->pict_type==FF_B_TYPE)
             return get_consumed_bytes(s, buf_size);
         else
             s->next_p_frame_damaged=0;
     }
 
-    if((s->avctx->flags2 & CODEC_FLAG2_FAST) && s->pict_type==B_TYPE){
+    if((s->avctx->flags2 & CODEC_FLAG2_FAST) && s->pict_type==FF_B_TYPE){
         s->me.qpel_put= s->dsp.put_2tap_qpel_pixels_tab;
         s->me.qpel_avg= s->dsp.avg_2tap_qpel_pixels_tab;
-    }else if((!s->no_rounding) || s->pict_type==B_TYPE){
+    }else if((!s->no_rounding) || s->pict_type==FF_B_TYPE){
         s->me.qpel_put= s->dsp.put_qpel_pixels_tab;
         s->me.qpel_avg= s->dsp.avg_qpel_pixels_tab;
     }else{
@@ -649,7 +649,7 @@
         decode_slice(s);
     }
 
-    if (s->h263_msmpeg4 && s->msmpeg4_version<4 && s->pict_type==I_TYPE)
+    if (s->h263_msmpeg4 && s->msmpeg4_version<4 && s->pict_type==FF_I_TYPE)
         if(!ENABLE_MSMPEG4_DECODER || msmpeg4_decode_ext_header(s, buf_size) < 0){
             s->error_status_table[s->mb_num-1]= AC_ERROR|DC_ERROR|MV_ERROR;
         }
@@ -690,7 +690,7 @@
 
 assert(s->current_picture.pict_type == s->current_picture_ptr->pict_type);
 assert(s->current_picture.pict_type == s->pict_type);
-    if (s->pict_type == B_TYPE || s->low_delay) {
+    if (s->pict_type == FF_B_TYPE || s->low_delay) {
         *pict= *(AVFrame*)s->current_picture_ptr;
     } else if (s->last_picture_ptr != NULL) {
         *pict= *(AVFrame*)s->last_picture_ptr;
@@ -702,7 +702,7 @@
     }
 
     /* Return the Picture timestamp as the frame number */
-    /* we substract 1 because it is added on utils.c    */
+    /* we subtract 1 because it is added on utils.c     */
     avctx->frame_number = s->picture_number - 1;
 
 #ifdef PRINT_FRAME_TIME
Index: mythtv/libs/libavcodec/cabac.h
===================================================================
--- mythtv/libs/libavcodec/cabac.h	(revision 18209)
+++ mythtv/libs/libavcodec/cabac.h	(working copy)
@@ -685,116 +685,6 @@
 #endif
 }
 
-//FIXME the x86 code from this file should be moved into i386/h264 or cabac something.c/h (note ill kill you if you move my code away from under my fingers before iam finished with it!)
-//FIXME use some macros to avoid duplicatin get_cabac (cannot be done yet as that would make optimization work hard)
-#if defined(ARCH_X86) && defined(HAVE_7REGS) && defined(HAVE_EBX_AVAILABLE) && !defined(BROKEN_RELOCATIONS)
-static int decode_significance_x86(CABACContext *c, int max_coeff, uint8_t *significant_coeff_ctx_base, int *index){
-    void *end= significant_coeff_ctx_base + max_coeff - 1;
-    int minusstart= -(int)significant_coeff_ctx_base;
-    int minusindex= 4-(int)index;
-    int coeff_count;
-    asm volatile(
-        "movl "RANGE    "(%3), %%esi            \n\t"
-        "movl "LOW      "(%3), %%ebx            \n\t"
-
-        "2:                                     \n\t"
-
-        BRANCHLESS_GET_CABAC("%%edx", "%3", "(%1)", "%%ebx", "%%bx", "%%esi", "%%eax", "%%al")
-
-        "test $1, %%edx                         \n\t"
-        " jz 3f                                 \n\t"
-
-        BRANCHLESS_GET_CABAC("%%edx", "%3", "61(%1)", "%%ebx", "%%bx", "%%esi", "%%eax", "%%al")
-
-        "mov  %2, %%"REG_a"                     \n\t"
-        "movl %4, %%ecx                         \n\t"
-        "add  %1, %%"REG_c"                     \n\t"
-        "movl %%ecx, (%%"REG_a")                \n\t"
-
-        "test $1, %%edx                         \n\t"
-        " jnz 4f                                \n\t"
-
-        "add  $4, %%"REG_a"                     \n\t"
-        "mov  %%"REG_a", %2                     \n\t"
-
-        "3:                                     \n\t"
-        "add  $1, %1                            \n\t"
-        "cmp  %5, %1                            \n\t"
-        " jb 2b                                 \n\t"
-        "mov  %2, %%"REG_a"                     \n\t"
-        "movl %4, %%ecx                         \n\t"
-        "add  %1, %%"REG_c"                     \n\t"
-        "movl %%ecx, (%%"REG_a")                \n\t"
-        "4:                                     \n\t"
-        "add  %6, %%eax                         \n\t"
-        "shr $2, %%eax                          \n\t"
-
-        "movl %%esi, "RANGE    "(%3)            \n\t"
-        "movl %%ebx, "LOW      "(%3)            \n\t"
-        :"=&a"(coeff_count), "+r"(significant_coeff_ctx_base), "+m"(index)\
-        :"r"(c), "m"(minusstart), "m"(end), "m"(minusindex)\
-        : "%"REG_c, "%ebx", "%edx", "%esi", "memory"\
-    );
-    return coeff_count;
-}
-
-static int decode_significance_8x8_x86(CABACContext *c, uint8_t *significant_coeff_ctx_base, int *index, uint8_t *sig_off){
-    int minusindex= 4-(int)index;
-    int coeff_count;
-    long last=0;
-    asm volatile(
-        "movl "RANGE    "(%3), %%esi            \n\t"
-        "movl "LOW      "(%3), %%ebx            \n\t"
-
-        "mov %1, %%"REG_D"                      \n\t"
-        "2:                                     \n\t"
-
-        "mov %6, %%"REG_a"                      \n\t"
-        "movzbl (%%"REG_a", %%"REG_D"), %%edi   \n\t"
-        "add %5, %%"REG_D"                      \n\t"
-
-        BRANCHLESS_GET_CABAC("%%edx", "%3", "(%%"REG_D")", "%%ebx", "%%bx", "%%esi", "%%eax", "%%al")
-
-        "mov %1, %%edi                          \n\t"
-        "test $1, %%edx                         \n\t"
-        " jz 3f                                 \n\t"
-
-        "movzbl "MANGLE(last_coeff_flag_offset_8x8)"(%%edi), %%edi\n\t"
-        "add %5, %%"REG_D"                      \n\t"
-
-        BRANCHLESS_GET_CABAC("%%edx", "%3", "15(%%"REG_D")", "%%ebx", "%%bx", "%%esi", "%%eax", "%%al")
-
-        "mov %2, %%"REG_a"                      \n\t"
-        "mov %1, %%edi                          \n\t"
-        "movl %%edi, (%%"REG_a")                \n\t"
-
-        "test $1, %%edx                         \n\t"
-        " jnz 4f                                \n\t"
-
-        "add $4, %%"REG_a"                      \n\t"
-        "mov %%"REG_a", %2                      \n\t"
-
-        "3:                                     \n\t"
-        "addl $1, %%edi                         \n\t"
-        "mov %%edi, %1                          \n\t"
-        "cmpl $63, %%edi                        \n\t"
-        " jb 2b                                 \n\t"
-        "mov %2, %%"REG_a"                      \n\t"
-        "movl %%edi, (%%"REG_a")                \n\t"
-        "4:                                     \n\t"
-        "addl %4, %%eax                         \n\t"
-        "shr $2, %%eax                          \n\t"
-
-        "movl %%esi, "RANGE    "(%3)            \n\t"
-        "movl %%ebx, "LOW      "(%3)            \n\t"
-        :"=&a"(coeff_count),"+m"(last), "+m"(index)\
-        :"r"(c), "m"(minusindex), "m"(significant_coeff_ctx_base), "m"(sig_off)\
-        : "%"REG_c, "%ebx", "%edx", "%esi", "%"REG_D, "memory"\
-    );
-    return coeff_count;
-}
-#endif /* defined(ARCH_X86) && && defined(HAVE_7REGS) && defined(HAVE_EBX_AVAILABLE) && !defined(BROKEN_RELOCATIONS) */
-
 /**
  *
  * @return the number of bytes read or 0 if no end
Index: mythtv/libs/libavcodec/aac_parser.c
===================================================================
--- mythtv/libs/libavcodec/aac_parser.c	(revision 18209)
+++ mythtv/libs/libavcodec/aac_parser.c	(working copy)
@@ -81,7 +81,7 @@
     return size;
 }
 
-static int aac_parse_init(AVCodecParserContext *s1)
+static av_cold int aac_parse_init(AVCodecParserContext *s1)
 {
     AACAC3ParseContext *s = s1->priv_data;
     s->inbuf_ptr = s->inbuf;
Index: mythtv/libs/libavcodec/ppc/gmc_altivec.c
===================================================================
--- mythtv/libs/libavcodec/ppc/gmc_altivec.c	(revision 18209)
+++ mythtv/libs/libavcodec/ppc/gmc_altivec.c	(working copy)
@@ -29,7 +29,7 @@
 
 /*
   altivec-enhanced gmc1. ATM this code assume stride is a multiple of 8,
-  to preserve proper dst alignement.
+  to preserve proper dst alignment.
 */
 #define GMC1_PERF_COND (h==8)
 void gmc1_altivec(uint8_t *dst /* align 8 */, uint8_t *src /* align1 */, int stride, int h, int x16, int y16, int rounder)
Index: mythtv/libs/libavcodec/ppc/mpegvideo_altivec.c
===================================================================
--- mythtv/libs/libavcodec/ppc/mpegvideo_altivec.c	(revision 18209)
+++ mythtv/libs/libavcodec/ppc/mpegvideo_altivec.c	(working copy)
@@ -80,7 +80,7 @@
     vector float row0, row1, row2, row3, row4, row5, row6, row7;
     vector float alt0, alt1, alt2, alt3, alt4, alt5, alt6, alt7;
     const vector float zero = (const vector float)FOUROF(0.);
-    // used after quantise step
+    // used after quantize step
     int oldBaseValue = 0;
 
     // Load the data into the row/alt vectors
@@ -258,7 +258,7 @@
         }
     }
 
-    // perform the quantise step, using the floating point data
+    // perform the quantize step, using the floating point data
     // still in the row/alt registers
     {
         const int* biasAddr;
@@ -474,7 +474,7 @@
         data[0] = (oldBaseValue + 4) >> 3;
     }
 
-    // We handled the tranpose permutation above and we don't
+    // We handled the transpose permutation above and we don't
     // need to permute the "no" permutation case.
     if ((lastNonZero > 0) &&
         (s->dsp.idct_permutation_type != FF_TRANSPOSE_IDCT_PERM) &&
Index: mythtv/libs/libavcodec/ppc/dsputil_altivec.c
===================================================================
--- mythtv/libs/libavcodec/ppc/dsputil_altivec.c	(revision 18209)
+++ mythtv/libs/libavcodec/ppc/dsputil_altivec.c	(working copy)
@@ -1094,7 +1094,7 @@
       dstV =                                                            \
         (vector signed short)vec_mergeh((vector signed char)vzero,      \
         (vector signed char)dstO);                                      \
-      /* substractions inside the first butterfly */                    \
+      /* subtractions inside the first butterfly */                    \
       but0 = vec_sub(srcV, dstV);                                       \
       op1 = vec_perm(but0, but0, perm1);                                \
       but1 = vec_mladd(but0, vprod1, op1);                              \
@@ -1175,7 +1175,7 @@
   schedule for the 7450, and its code isn't much faster than
   gcc-3.3 on the 7450 (but uses 25% less instructions...)
 
-  On the 970, the hand-made RA is still a win (arount 690
+  On the 970, the hand-made RA is still a win (around 690
   vs. around 780), but xlc goes to around 660 on the
   regular C code...
 */
@@ -1267,7 +1267,7 @@
       dstW =                                                            \
         (vector signed short)vec_mergel((vector signed char)vzero,      \
         (vector signed char)dstO);                                      \
-      /* substractions inside the first butterfly */                    \
+      /* subtractions inside the first butterfly */                    \
       but0 = vec_sub(srcV, dstV);                                       \
       but0S = vec_sub(srcW, dstW);                                      \
       op1 = vec_perm(but0, but0, perm1);                                \
Index: mythtv/libs/libavcodec/svq1dec.c
===================================================================
--- mythtv/libs/libavcodec/svq1dec.c	(revision 18209)
+++ mythtv/libs/libavcodec/svq1dec.c	(working copy)
@@ -575,7 +575,7 @@
   if(s->pict_type==4)
       return -1;
 
-  if (s->pict_type == I_TYPE) {
+  if (s->pict_type == FF_I_TYPE) {
 
     /* unknown fields */
     if (s->f_code == 0x50 || s->f_code == 0x60) {
@@ -678,11 +678,11 @@
 
   //FIXME this avoids some confusion for "B frames" without 2 references
   //this should be removed after libavcodec can handle more flexible picture types & ordering
-  if(s->pict_type==B_TYPE && s->last_picture_ptr==NULL) return buf_size;
+  if(s->pict_type==FF_B_TYPE && s->last_picture_ptr==NULL) return buf_size;
 
-  if(avctx->hurry_up && s->pict_type==B_TYPE) return buf_size;
-  if(  (avctx->skip_frame >= AVDISCARD_NONREF && s->pict_type==B_TYPE)
-     ||(avctx->skip_frame >= AVDISCARD_NONKEY && s->pict_type!=I_TYPE)
+  if(avctx->hurry_up && s->pict_type==FF_B_TYPE) return buf_size;
+  if(  (avctx->skip_frame >= AVDISCARD_NONREF && s->pict_type==FF_B_TYPE)
+     ||(avctx->skip_frame >= AVDISCARD_NONKEY && s->pict_type!=FF_I_TYPE)
      || avctx->skip_frame >= AVDISCARD_ALL)
       return buf_size;
 
@@ -705,13 +705,13 @@
 
     current  = s->current_picture.data[i];
 
-    if(s->pict_type==B_TYPE){
+    if(s->pict_type==FF_B_TYPE){
         previous = s->next_picture.data[i];
     }else{
         previous = s->last_picture.data[i];
     }
 
-    if (s->pict_type == I_TYPE) {
+    if (s->pict_type == FF_I_TYPE) {
       /* keyframe */
       for (y=0; y < height; y+=16) {
         for (x=0; x < width; x+=16) {
@@ -761,7 +761,7 @@
   return buf_size;
 }
 
-static int svq1_decode_init(AVCodecContext *avctx)
+static av_cold int svq1_decode_init(AVCodecContext *avctx)
 {
     MpegEncContext *s = avctx->priv_data;
     int i;
@@ -805,7 +805,7 @@
     return 0;
 }
 
-static int svq1_decode_end(AVCodecContext *avctx)
+static av_cold int svq1_decode_end(AVCodecContext *avctx)
 {
     MpegEncContext *s = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/rpza.c
===================================================================
--- mythtv/libs/libavcodec/rpza.c	(revision 18209)
+++ mythtv/libs/libavcodec/rpza.c	(working copy)
@@ -228,7 +228,7 @@
     }
 }
 
-static int rpza_decode_init(AVCodecContext *avctx)
+static av_cold int rpza_decode_init(AVCodecContext *avctx)
 {
     RpzaContext *s = avctx->priv_data;
 
@@ -266,7 +266,7 @@
     return buf_size;
 }
 
-static int rpza_decode_end(AVCodecContext *avctx)
+static av_cold int rpza_decode_end(AVCodecContext *avctx)
 {
     RpzaContext *s = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/apedec.c
===================================================================
--- mythtv/libs/libavcodec/apedec.c	(revision 18209)
+++ mythtv/libs/libavcodec/apedec.c	(working copy)
@@ -183,7 +183,7 @@
     return res;
 }
 
-static int ape_decode_init(AVCodecContext * avctx)
+static av_cold int ape_decode_init(AVCodecContext * avctx)
 {
     APEContext *s = avctx->priv_data;
     int i;
@@ -222,7 +222,7 @@
     return 0;
 }
 
-static int ape_decode_close(AVCodecContext * avctx)
+static av_cold int ape_decode_close(AVCodecContext * avctx)
 {
     APEContext *s = avctx->priv_data;
     int i;
@@ -490,7 +490,7 @@
     /* Keep a count of the blocks decoded in this frame */
     ctx->blocksdecoded = 0;
 
-    /* Initialise the rice structs */
+    /* Initialize the rice structs */
     ctx->riceX.k = 10;
     ctx->riceX.ksum = (1 << ctx->riceX.k) * 16;
     ctx->riceY.k = 10;
@@ -514,7 +514,7 @@
     memset(p->historybuffer, 0, PREDICTOR_SIZE * sizeof(int32_t));
     p->buf = p->historybuffer;
 
-    /* Initialise and zero the co-efficients */
+    /* Initialize and zero the co-efficients */
     memcpy(p->coeffsA[0], initial_coeffs, sizeof(initial_coeffs));
     memcpy(p->coeffsA[1], initial_coeffs, sizeof(initial_coeffs));
     memset(p->coeffsB, 0, sizeof(p->coeffsB));
Index: mythtv/libs/libavcodec/tta.c
===================================================================
--- mythtv/libs/libavcodec/tta.c	(revision 18209)
+++ mythtv/libs/libavcodec/tta.c	(working copy)
@@ -197,7 +197,7 @@
     return ret;
 }
 
-static int tta_decode_init(AVCodecContext * avctx)
+static av_cold int tta_decode_init(AVCodecContext * avctx)
 {
     TTAContext *s = avctx->priv_data;
     int i;
@@ -425,7 +425,7 @@
     return buf_size;
 }
 
-static int tta_decode_close(AVCodecContext *avctx) {
+static av_cold int tta_decode_close(AVCodecContext *avctx) {
     TTAContext *s = avctx->priv_data;
 
     if (s->decode_buffer)
Index: mythtv/libs/libavcodec/flashsvenc.c
===================================================================
--- mythtv/libs/libavcodec/flashsvenc.c	(revision 18209)
+++ mythtv/libs/libavcodec/flashsvenc.c	(working copy)
@@ -97,7 +97,7 @@
     return 0;
 }
 
-static int flashsv_encode_init(AVCodecContext *avctx)
+static av_cold int flashsv_encode_init(AVCodecContext *avctx)
 {
     FlashSVContext *s = avctx->priv_data;
 
@@ -271,7 +271,7 @@
     return res;
 }
 
-static int flashsv_encode_end(AVCodecContext *avctx)
+static av_cold int flashsv_encode_end(AVCodecContext *avctx)
 {
     FlashSVContext *s = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/cavs.c
===================================================================
--- mythtv/libs/libavcodec/cavs.c	(revision 18209)
+++ mythtv/libs/libavcodec/cavs.c	(working copy)
@@ -668,7 +668,7 @@
     h->block        = av_mallocz(64*sizeof(DCTELEM));
 }
 
-int ff_cavs_init(AVCodecContext *avctx) {
+av_cold int ff_cavs_init(AVCodecContext *avctx) {
     AVSContext *h = avctx->priv_data;
     MpegEncContext * const s = &h->s;
 
@@ -699,7 +699,7 @@
     return 0;
 }
 
-int ff_cavs_end(AVCodecContext *avctx) {
+av_cold int ff_cavs_end(AVCodecContext *avctx) {
     AVSContext *h = avctx->priv_data;
 
     av_free(h->top_qp);
Index: mythtv/libs/libavcodec/mmvideo.c
===================================================================
--- mythtv/libs/libavcodec/mmvideo.c	(revision 18209)
+++ mythtv/libs/libavcodec/mmvideo.c	(working copy)
@@ -47,7 +47,7 @@
     AVFrame frame;
 } MmContext;
 
-static int mm_decode_init(AVCodecContext *avctx)
+static av_cold int mm_decode_init(AVCodecContext *avctx)
 {
     MmContext *s = avctx->priv_data;
 
@@ -182,7 +182,7 @@
     return buf_size;
 }
 
-static int mm_decode_end(AVCodecContext *avctx)
+static av_cold int mm_decode_end(AVCodecContext *avctx)
 {
     MmContext *s = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/rectangle.h
===================================================================
--- mythtv/libs/libavcodec/rectangle.h	(revision 0)
+++ mythtv/libs/libavcodec/rectangle.h	(revision 0)
@@ -0,0 +1,121 @@
+/*
+ * rectangle filling function
+ * Copyright (c) 2003 Michael Niedermayer <michaelni@gmx.at>
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+/**
+ * @file rectangle.h
+ * useful rectangle filling function
+ * @author Michael Niedermayer <michaelni@gmx.at>
+ */
+
+#ifndef FFMPEG_RECTANGLE_H
+#define FFMPEG_RECTANGLE_H
+
+#include "common.h"
+
+/**
+ * fill a rectangle.
+ * @param h height of the rectangle, should be a constant
+ * @param w width of the rectangle, should be a constant
+ * @param size the size of val (1 or 4), should be a constant
+ */
+static av_always_inline void fill_rectangle(void *vp, int w, int h, int stride, uint32_t val, int size){
+    uint8_t *p= (uint8_t*)vp;
+    assert(size==1 || size==4);
+    assert(w<=4);
+
+    w      *= size;
+    stride *= size;
+
+    assert((((long)vp)&(FFMIN(w, STRIDE_ALIGN)-1)) == 0);
+    assert((stride&(w-1))==0);
+    if(w==2){
+        const uint16_t v= size==4 ? val : val*0x0101;
+        *(uint16_t*)(p + 0*stride)= v;
+        if(h==1) return;
+        *(uint16_t*)(p + 1*stride)= v;
+        if(h==2) return;
+        *(uint16_t*)(p + 2*stride)= v;
+        *(uint16_t*)(p + 3*stride)= v;
+    }else if(w==4){
+        const uint32_t v= size==4 ? val : val*0x01010101;
+        *(uint32_t*)(p + 0*stride)= v;
+        if(h==1) return;
+        *(uint32_t*)(p + 1*stride)= v;
+        if(h==2) return;
+        *(uint32_t*)(p + 2*stride)= v;
+        *(uint32_t*)(p + 3*stride)= v;
+    }else if(w==8){
+    //gcc can't optimize 64bit math on x86_32
+#if defined(ARCH_X86_64) || (defined(MP_WORDSIZE) && MP_WORDSIZE >= 64)
+        const uint64_t v= val*0x0100000001ULL;
+        *(uint64_t*)(p + 0*stride)= v;
+        if(h==1) return;
+        *(uint64_t*)(p + 1*stride)= v;
+        if(h==2) return;
+        *(uint64_t*)(p + 2*stride)= v;
+        *(uint64_t*)(p + 3*stride)= v;
+    }else if(w==16){
+        const uint64_t v= val*0x0100000001ULL;
+        *(uint64_t*)(p + 0+0*stride)= v;
+        *(uint64_t*)(p + 8+0*stride)= v;
+        *(uint64_t*)(p + 0+1*stride)= v;
+        *(uint64_t*)(p + 8+1*stride)= v;
+        if(h==2) return;
+        *(uint64_t*)(p + 0+2*stride)= v;
+        *(uint64_t*)(p + 8+2*stride)= v;
+        *(uint64_t*)(p + 0+3*stride)= v;
+        *(uint64_t*)(p + 8+3*stride)= v;
+#else
+        *(uint32_t*)(p + 0+0*stride)= val;
+        *(uint32_t*)(p + 4+0*stride)= val;
+        if(h==1) return;
+        *(uint32_t*)(p + 0+1*stride)= val;
+        *(uint32_t*)(p + 4+1*stride)= val;
+        if(h==2) return;
+        *(uint32_t*)(p + 0+2*stride)= val;
+        *(uint32_t*)(p + 4+2*stride)= val;
+        *(uint32_t*)(p + 0+3*stride)= val;
+        *(uint32_t*)(p + 4+3*stride)= val;
+    }else if(w==16){
+        *(uint32_t*)(p + 0+0*stride)= val;
+        *(uint32_t*)(p + 4+0*stride)= val;
+        *(uint32_t*)(p + 8+0*stride)= val;
+        *(uint32_t*)(p +12+0*stride)= val;
+        *(uint32_t*)(p + 0+1*stride)= val;
+        *(uint32_t*)(p + 4+1*stride)= val;
+        *(uint32_t*)(p + 8+1*stride)= val;
+        *(uint32_t*)(p +12+1*stride)= val;
+        if(h==2) return;
+        *(uint32_t*)(p + 0+2*stride)= val;
+        *(uint32_t*)(p + 4+2*stride)= val;
+        *(uint32_t*)(p + 8+2*stride)= val;
+        *(uint32_t*)(p +12+2*stride)= val;
+        *(uint32_t*)(p + 0+3*stride)= val;
+        *(uint32_t*)(p + 4+3*stride)= val;
+        *(uint32_t*)(p + 8+3*stride)= val;
+        *(uint32_t*)(p +12+3*stride)= val;
+#endif
+    }else
+        assert(0);
+    assert(h==4);
+}
+
+#endif /* FFMPEG_RECTANGLE_H */
Index: mythtv/libs/libavcodec/sp5xdec.c
===================================================================
--- mythtv/libs/libavcodec/sp5xdec.c	(revision 18209)
+++ mythtv/libs/libavcodec/sp5xdec.c	(working copy)
@@ -124,7 +124,7 @@
         return -1;
     }
 
-    s->picture.pict_type = I_TYPE;
+    s->picture.pict_type = FF_I_TYPE;
     s->picture.key_frame = 1;
 
     for (i = 0; i < 3; i++)
Index: mythtv/libs/libavcodec/fraps.c
===================================================================
--- mythtv/libs/libavcodec/fraps.c	(revision 18209)
+++ mythtv/libs/libavcodec/fraps.c	(working copy)
@@ -55,7 +55,7 @@
  * @param avctx codec context
  * @return 0 on success or negative if fails
  */
-static int decode_init(AVCodecContext *avctx)
+static av_cold int decode_init(AVCodecContext *avctx)
 {
     FrapsContext * const s = avctx->priv_data;
 
@@ -300,7 +300,7 @@
  * @param avctx codec context
  * @return 0 on success or negative if fails
  */
-static int decode_end(AVCodecContext *avctx)
+static av_cold int decode_end(AVCodecContext *avctx)
 {
     FrapsContext *s = (FrapsContext*)avctx->priv_data;
 
Index: mythtv/libs/libavcodec/cscd.c
===================================================================
--- mythtv/libs/libavcodec/cscd.c	(revision 18209)
+++ mythtv/libs/libavcodec/cscd.c	(working copy)
@@ -212,7 +212,7 @@
     return buf_size;
 }
 
-static int decode_init(AVCodecContext *avctx) {
+static av_cold int decode_init(AVCodecContext *avctx) {
     CamStudioContext *c = avctx->priv_data;
     if (avcodec_check_dimensions(avctx, avctx->height, avctx->width) < 0) {
         return 1;
@@ -240,7 +240,7 @@
     return 0;
 }
 
-static int decode_end(AVCodecContext *avctx) {
+static av_cold int decode_end(AVCodecContext *avctx) {
     CamStudioContext *c = avctx->priv_data;
     av_freep(&c->decomp_buf);
     if (c->pic.data[0])
Index: mythtv/libs/libavcodec/bmp.c
===================================================================
--- mythtv/libs/libavcodec/bmp.c	(revision 18209)
+++ mythtv/libs/libavcodec/bmp.c	(working copy)
@@ -23,7 +23,7 @@
 #include "bytestream.h"
 #include "bmp.h"
 
-static int bmp_decode_init(AVCodecContext *avctx){
+static av_cold int bmp_decode_init(AVCodecContext *avctx){
     BMPContext *s = avctx->priv_data;
 
     avcodec_get_frame_defaults((AVFrame*)&s->picture);
@@ -231,7 +231,7 @@
     return buf_size;
 }
 
-static int bmp_decode_end(AVCodecContext *avctx)
+static av_cold int bmp_decode_end(AVCodecContext *avctx)
 {
     BMPContext* c = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/mpeg12enc.c
===================================================================
--- mythtv/libs/libavcodec/mpeg12enc.c	(revision 18209)
+++ mythtv/libs/libavcodec/mpeg12enc.c	(working copy)
@@ -133,7 +133,7 @@
         return 0;
 }
 
-static int encode_init(AVCodecContext *avctx)
+static av_cold int encode_init(AVCodecContext *avctx)
 {
     MpegEncContext *s = avctx->priv_data;
 
@@ -349,7 +349,7 @@
     put_bits(&s->pb, 16, 0xFFFF); /* vbv_delay */
 
     // RAL: Forward f_code also needed for B frames
-    if (s->pict_type == P_TYPE || s->pict_type == B_TYPE) {
+    if (s->pict_type == FF_P_TYPE || s->pict_type == FF_B_TYPE) {
         put_bits(&s->pb, 1, 0); /* half pel coordinates */
         if(s->codec_id == CODEC_ID_MPEG1VIDEO)
             put_bits(&s->pb, 3, s->f_code); /* forward_f_code */
@@ -358,7 +358,7 @@
     }
 
     // RAL: Backward f_code necessary for B frames
-    if (s->pict_type == B_TYPE) {
+    if (s->pict_type == FF_B_TYPE) {
         put_bits(&s->pb, 1, 0); /* half pel coordinates */
         if(s->codec_id == CODEC_ID_MPEG1VIDEO)
             put_bits(&s->pb, 3, s->b_code); /* backward_f_code */
@@ -372,13 +372,13 @@
     if(s->codec_id == CODEC_ID_MPEG2VIDEO){
         put_header(s, EXT_START_CODE);
         put_bits(&s->pb, 4, 8); //pic ext
-        if (s->pict_type == P_TYPE || s->pict_type == B_TYPE) {
+        if (s->pict_type == FF_P_TYPE || s->pict_type == FF_B_TYPE) {
             put_bits(&s->pb, 4, s->f_code);
             put_bits(&s->pb, 4, s->f_code);
         }else{
             put_bits(&s->pb, 8, 255);
         }
-        if (s->pict_type == B_TYPE) {
+        if (s->pict_type == FF_B_TYPE) {
             put_bits(&s->pb, 4, s->b_code);
             put_bits(&s->pb, 4, s->b_code);
         }else{
@@ -451,15 +451,15 @@
 
     if (cbp == 0 && !first_mb && s->mv_type == MV_TYPE_16X16 &&
         (mb_x != s->mb_width - 1 || (mb_y != s->mb_height - 1 && s->codec_id == CODEC_ID_MPEG1VIDEO)) &&
-        ((s->pict_type == P_TYPE && (motion_x | motion_y) == 0) ||
-        (s->pict_type == B_TYPE && s->mv_dir == s->last_mv_dir && (((s->mv_dir & MV_DIR_FORWARD) ? ((s->mv[0][0][0] - s->last_mv[0][0][0])|(s->mv[0][0][1] - s->last_mv[0][0][1])) : 0) |
+        ((s->pict_type == FF_P_TYPE && (motion_x | motion_y) == 0) ||
+        (s->pict_type == FF_B_TYPE && s->mv_dir == s->last_mv_dir && (((s->mv_dir & MV_DIR_FORWARD) ? ((s->mv[0][0][0] - s->last_mv[0][0][0])|(s->mv[0][0][1] - s->last_mv[0][0][1])) : 0) |
         ((s->mv_dir & MV_DIR_BACKWARD) ? ((s->mv[1][0][0] - s->last_mv[1][0][0])|(s->mv[1][0][1] - s->last_mv[1][0][1])) : 0)) == 0))) {
         s->mb_skip_run++;
         s->qscale -= s->dquant;
         s->skip_count++;
         s->misc_bits++;
         s->last_bits++;
-        if(s->pict_type == P_TYPE){
+        if(s->pict_type == FF_P_TYPE){
             s->last_mv[0][1][0]= s->last_mv[0][0][0]=
             s->last_mv[0][1][1]= s->last_mv[0][0][1]= 0;
         }
@@ -471,7 +471,7 @@
             encode_mb_skip_run(s, s->mb_skip_run);
         }
 
-        if (s->pict_type == I_TYPE) {
+        if (s->pict_type == FF_I_TYPE) {
             if(s->dquant && cbp){
                 put_mb_modes(s, 2, 1, 0, 0); /* macroblock_type : macroblock_quant = 1 */
                 put_qscale(s);
@@ -492,7 +492,7 @@
             s->misc_bits+= get_bits_diff(s);
             s->i_count++;
             memset(s->last_mv, 0, sizeof(s->last_mv));
-        } else if (s->pict_type == P_TYPE) {
+        } else if (s->pict_type == FF_P_TYPE) {
             if(s->mv_type == MV_TYPE_16X16){
                 if (cbp != 0) {
                     if ((motion_x|motion_y) == 0) {
Index: mythtv/libs/libavcodec/g726.c
===================================================================
--- mythtv/libs/libavcodec/g726.c	(revision 18209)
+++ mythtv/libs/libavcodec/g726.c	(working copy)
@@ -266,7 +266,7 @@
     return av_clip(re_signal << 2, -0xffff, 0xffff);
 }
 
-static int g726_reset(G726Context* c, int bit_rate)
+static av_cold int g726_reset(G726Context* c, int bit_rate)
 {
     int i;
 
@@ -319,7 +319,7 @@
     int code_size;
 } AVG726Context;
 
-static int g726_init(AVCodecContext * avctx)
+static av_cold int g726_init(AVCodecContext * avctx)
 {
     AVG726Context* c = (AVG726Context*)avctx->priv_data;
 
@@ -346,7 +346,7 @@
     return 0;
 }
 
-static int g726_close(AVCodecContext *avctx)
+static av_cold int g726_close(AVCodecContext *avctx)
 {
     av_freep(&avctx->coded_frame);
     return 0;
@@ -387,7 +387,7 @@
     mask = (1<<c->code_size) - 1;
     init_get_bits(&gb, buf, buf_size * 8);
     if (c->bits_left) {
-        int s = c->code_size - c->bits_left;;
+        int s = c->code_size - c->bits_left;
         code = (c->bit_buffer << s) | get_bits(&gb, s);
         *samples++ = g726_decode(&c->c, code & mask);
     }
Index: mythtv/libs/libavcodec/xan.c
===================================================================
--- mythtv/libs/libavcodec/xan.c	(revision 18209)
+++ mythtv/libs/libavcodec/xan.c	(working copy)
@@ -54,7 +54,7 @@
 
 } XanContext;
 
-static int xan_decode_init(AVCodecContext *avctx)
+static av_cold int xan_decode_init(AVCodecContext *avctx)
 {
     XanContext *s = avctx->priv_data;
 
@@ -447,7 +447,7 @@
     return buf_size;
 }
 
-static int xan_decode_end(AVCodecContext *avctx)
+static av_cold int xan_decode_end(AVCodecContext *avctx)
 {
     XanContext *s = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/eval.c
===================================================================
--- mythtv/libs/libavcodec/eval.c	(revision 18209)
+++ mythtv/libs/libavcodec/eval.c	(working copy)
@@ -451,7 +451,7 @@
     "E",
     0
 };
-main(){
+main(void){
     int i;
     printf("%f == 12.7\n", ff_eval("1+(5-2)^(3-1)+1/2+sin(PI)-max(-2.2,-3.1)", const_values, const_names, NULL, NULL, NULL, NULL, NULL));
     printf("%f == 0.931322575\n", ff_eval("80G/80Gi", const_values, const_names, NULL, NULL, NULL, NULL, NULL));
Index: mythtv/libs/libavcodec/truemotion2.c
===================================================================
--- mythtv/libs/libavcodec/truemotion2.c	(revision 18209)
+++ mythtv/libs/libavcodec/truemotion2.c	(working copy)
@@ -818,7 +818,7 @@
     return buf_size;
 }
 
-static int decode_init(AVCodecContext *avctx){
+static av_cold int decode_init(AVCodecContext *avctx){
     TM2Context * const l = avctx->priv_data;
     int i;
 
@@ -855,7 +855,7 @@
     return 0;
 }
 
-static int decode_end(AVCodecContext *avctx){
+static av_cold int decode_end(AVCodecContext *avctx){
     TM2Context * const l = avctx->priv_data;
     int i;
 
Index: mythtv/libs/libavcodec/dsputil.h
===================================================================
--- mythtv/libs/libavcodec/dsputil.h	(revision 18209)
+++ mythtv/libs/libavcodec/dsputil.h	(working copy)
@@ -321,7 +321,7 @@
     void (*h264_h_loop_filter_chroma_intra)(uint8_t *pix, int stride, int alpha, int beta);
     // h264_loop_filter_strength: simd only. the C version is inlined in h264.c
     void (*h264_loop_filter_strength)(int16_t bS[2][4][4], uint8_t nnz[40], int8_t ref[2][40], int16_t mv[2][40][2],
-                                      int bidir, int edges, int step, int mask_mv0, int mask_mv1);
+                                      int bidir, int edges, int step, int mask_mv0, int mask_mv1, int field);
 
     void (*h263_v_loop_filter)(uint8_t *src, int stride, int qscale);
     void (*h263_h_loop_filter)(uint8_t *src, int stride, int qscale);
Index: mythtv/libs/libavcodec/wmv2.c
===================================================================
--- mythtv/libs/libavcodec/wmv2.c	(revision 18209)
+++ mythtv/libs/libavcodec/wmv2.c	(working copy)
@@ -58,7 +58,7 @@
     DECLARE_ALIGNED_8(DCTELEM, abt_block2[6][64]);
 }Wmv2Context;
 
-static void wmv2_common_init(Wmv2Context * w){
+av_cold void wmv2_common_init(Wmv2Context * w){
     MpegEncContext * const s= &w->s;
 
     ff_init_scantable(s->dsp.idct_permutation, &w->abt_scantable[0], wmv2_scantableA);
Index: mythtv/libs/libavcodec/xsubdec.c
===================================================================
--- mythtv/libs/libavcodec/xsubdec.c	(revision 18209)
+++ mythtv/libs/libavcodec/xsubdec.c	(working copy)
@@ -22,7 +22,7 @@
 #include "bitstream.h"
 #include "bytestream.h"
 
-static int decode_init(AVCodecContext *avctx) {
+static av_cold int decode_init(AVCodecContext *avctx) {
     avctx->pix_fmt = PIX_FMT_PAL8;
     return 0;
 }
Index: mythtv/libs/libavcodec/lclenc.c
===================================================================
--- mythtv/libs/libavcodec/lclenc.c	(revision 18209)
+++ mythtv/libs/libavcodec/lclenc.c	(working copy)
@@ -139,7 +139,7 @@
  * Init lcl encoder
  *
  */
-static int encode_init(AVCodecContext *avctx)
+static av_cold int encode_init(AVCodecContext *avctx)
 {
     LclEncContext *c = avctx->priv_data;
     int zret; // Zlib return code
@@ -207,7 +207,7 @@
  * Uninit lcl encoder
  *
  */
-static int encode_end(AVCodecContext *avctx)
+static av_cold int encode_end(AVCodecContext *avctx)
 {
     LclEncContext *c = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/imgresample.c
===================================================================
--- mythtv/libs/libavcodec/imgresample.c	(revision 18209)
+++ mythtv/libs/libavcodec/imgresample.c	(working copy)
@@ -285,7 +285,7 @@
 }
 #endif /* HAVE_MMX */
 
-/* slow version to handle limit cases. Does not need optimisation */
+/* slow version to handle limit cases. Does not need optimization */
 static void h_resample_slow(uint8_t *dst, int dst_width,
                             const uint8_t *src, int src_width,
                             int src_start, int src_incr, int16_t *filters)
Index: mythtv/libs/libavcodec/rangecoder.c
===================================================================
--- mythtv/libs/libavcodec/rangecoder.c	(revision 18209)
+++ mythtv/libs/libavcodec/rangecoder.c	(working copy)
@@ -109,9 +109,9 @@
     return c->bytestream - c->bytestream_start;
 }
 
-#if 0 //selftest
+#ifdef TEST
 #define SIZE 10240
-int main(){
+int main(void){
     RangeCoder c;
     uint8_t b[9*SIZE];
     uint8_t r[9*SIZE];
@@ -148,4 +148,4 @@
 
     return 0;
 }
-#endif
+#endif /* TEST */
Index: mythtv/libs/libavcodec/motion_est_template.c
===================================================================
--- mythtv/libs/libavcodec/motion_est_template.c	(revision 18209)
+++ mythtv/libs/libavcodec/motion_est_template.c	(working copy)
@@ -1035,7 +1035,7 @@
     score_map[0]= dmin;
 
     //FIXME precalc first term below?
-    if((s->pict_type == B_TYPE && !(c->flags & FLAG_DIRECT)) || s->flags&CODEC_FLAG_MV0)
+    if((s->pict_type == FF_B_TYPE && !(c->flags & FLAG_DIRECT)) || s->flags&CODEC_FLAG_MV0)
         dmin += (mv_penalty[pred_x] + mv_penalty[pred_y])*penalty_factor;
 
     /* first line */
Index: mythtv/libs/libavcodec/imgconvert_template.h
===================================================================
--- mythtv/libs/libavcodec/imgconvert_template.h	(revision 18209)
+++ mythtv/libs/libavcodec/imgconvert_template.h	(working copy)
@@ -414,7 +414,7 @@
     }
 }
 
-// RGB24 has optimised routines
+// RGB24 has optimized routines
 #if !defined(FMT_RGB32) && !defined(FMT_RGB24)
 /* alpha support */
 
Index: mythtv/libs/libavcodec/ac3_parser.c
===================================================================
--- mythtv/libs/libavcodec/ac3_parser.c	(revision 18209)
+++ mythtv/libs/libavcodec/ac3_parser.c	(working copy)
@@ -147,7 +147,7 @@
     return 0;
 }
 
-static int ac3_parse_init(AVCodecParserContext *s1)
+static av_cold int ac3_parse_init(AVCodecParserContext *s1)
 {
     AACAC3ParseContext *s = s1->priv_data;
     s->inbuf_ptr = s->inbuf;
Index: mythtv/libs/libavcodec/libmp3lame.c
===================================================================
--- mythtv/libs/libavcodec/libmp3lame.c	(revision 18209)
+++ mythtv/libs/libavcodec/libmp3lame.c	(working copy)
@@ -36,7 +36,7 @@
     int buffer_index;
 } Mp3AudioContext;
 
-static int MP3lame_encode_init(AVCodecContext *avctx)
+static av_cold int MP3lame_encode_init(AVCodecContext *avctx)
 {
     Mp3AudioContext *s = avctx->priv_data;
 
@@ -197,7 +197,7 @@
             return 0;
 }
 
-static int MP3lame_encode_close(AVCodecContext *avctx)
+static av_cold int MP3lame_encode_close(AVCodecContext *avctx)
 {
     Mp3AudioContext *s = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/lcldec.c
===================================================================
--- mythtv/libs/libavcodec/lcldec.c	(revision 18209)
+++ mythtv/libs/libavcodec/lcldec.c	(working copy)
@@ -514,7 +514,7 @@
  * Init lcl decoder
  *
  */
-static int decode_init(AVCodecContext *avctx)
+static av_cold int decode_init(AVCodecContext *avctx)
 {
     LclDecContext * const c = avctx->priv_data;
     unsigned int basesize = avctx->width * avctx->height;
@@ -673,7 +673,7 @@
  * Uninit lcl decoder
  *
  */
-static int decode_end(AVCodecContext *avctx)
+static av_cold int decode_end(AVCodecContext *avctx)
 {
     LclDecContext * const c = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/txd.c
===================================================================
--- mythtv/libs/libavcodec/txd.c	(revision 18209)
+++ mythtv/libs/libavcodec/txd.c	(working copy)
@@ -28,7 +28,7 @@
     AVFrame picture;
 } TXDContext;
 
-static int txd_init(AVCodecContext *avctx) {
+static av_cold int txd_init(AVCodecContext *avctx) {
     TXDContext *s = avctx->priv_data;
 
     avcodec_get_frame_defaults(&s->picture);
@@ -142,7 +142,7 @@
     return -1;
 }
 
-static int txd_end(AVCodecContext *avctx) {
+static av_cold int txd_end(AVCodecContext *avctx) {
     TXDContext *s = avctx->priv_data;
 
     if (s->picture.data[0])
Index: mythtv/libs/libavcodec/alac.c
===================================================================
--- mythtv/libs/libavcodec/alac.c	(revision 18209)
+++ mythtv/libs/libavcodec/alac.c	(working copy)
@@ -325,15 +325,15 @@
 
 #if 0
     /* 4 and 8 are very common cases (the only ones i've seen). these
-     * should be unrolled and optimised
+     * should be unrolled and optimized
      */
     if (predictor_coef_num == 4) {
-        /* FIXME: optimised general case */
+        /* FIXME: optimized general case */
         return;
     }
 
     if (predictor_coef_table == 8) {
-        /* FIXME: optimised general case */
+        /* FIXME: optimized general case */
         return;
     }
 #endif
@@ -624,7 +624,7 @@
     return input_buffer_size;
 }
 
-static int alac_decode_init(AVCodecContext * avctx)
+static av_cold int alac_decode_init(AVCodecContext * avctx)
 {
     ALACContext *alac = avctx->priv_data;
     alac->avctx = avctx;
@@ -637,7 +637,7 @@
     return 0;
 }
 
-static int alac_decode_close(AVCodecContext *avctx)
+static av_cold int alac_decode_close(AVCodecContext *avctx)
 {
     ALACContext *alac = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/dca_parser.c
===================================================================
--- mythtv/libs/libavcodec/dca_parser.c	(revision 18209)
+++ mythtv/libs/libavcodec/dca_parser.c	(working copy)
@@ -84,7 +84,7 @@
     return END_NOT_FOUND;
 }
 
-static int dca_parse_init(AVCodecParserContext * s)
+static av_cold int dca_parse_init(AVCodecParserContext * s)
 {
     DCAParseContext *pc1 = s->priv_data;
 
Index: mythtv/libs/libavcodec/ac3.c
===================================================================
--- mythtv/libs/libavcodec/ac3.c	(revision 18209)
+++ mythtv/libs/libavcodec/ac3.c	(working copy)
@@ -223,7 +223,7 @@
  * note: This function must remain thread safe because it is called by the
  *       AVParser init code.
  */
-void ac3_common_init(void)
+av_cold void ac3_common_init(void)
 {
     int i, j, k, l, v;
     /* compute bndtab and masktab from bandsz */
Index: mythtv/libs/libavcodec/imc.c
===================================================================
--- mythtv/libs/libavcodec/imc.c	(revision 18209)
+++ mythtv/libs/libavcodec/imc.c	(working copy)
@@ -89,7 +89,7 @@
 } IMCContext;
 
 
-static int imc_decode_init(AVCodecContext * avctx)
+static av_cold int imc_decode_init(AVCodecContext * avctx)
 {
     int i, j;
     IMCContext *q = avctx->priv_data;
@@ -792,7 +792,7 @@
 }
 
 
-static int imc_decode_close(AVCodecContext * avctx)
+static av_cold int imc_decode_close(AVCodecContext * avctx)
 {
     IMCContext *q = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/4xm.c
===================================================================
--- mythtv/libs/libavcodec/4xm.c	(revision 18209)
+++ mythtv/libs/libavcodec/4xm.c	(working copy)
@@ -235,7 +235,7 @@
     }
 }
 
-static void init_vlcs(FourXContext *f){
+static av_cold void init_vlcs(FourXContext *f){
     int i;
 
     for(i=0; i<8; i++){
@@ -796,7 +796,7 @@
     f->avctx= avctx;
 }
 
-static int decode_init(AVCodecContext *avctx){
+static av_cold int decode_init(AVCodecContext *avctx){
     FourXContext * const f = avctx->priv_data;
 
     if(avctx->extradata_size != 4 || !avctx->extradata) {
@@ -815,7 +815,7 @@
 }
 
 
-static int decode_end(AVCodecContext *avctx){
+static av_cold int decode_end(AVCodecContext *avctx){
     FourXContext * const f = avctx->priv_data;
     int i;
 
Index: mythtv/libs/libavcodec/avcodec.h
===================================================================
--- mythtv/libs/libavcodec/avcodec.h	(revision 18209)
+++ mythtv/libs/libavcodec/avcodec.h	(working copy)
@@ -753,6 +753,7 @@
 #define FF_S_TYPE  4 // S(GMC)-VOP MPEG4
 #define FF_SI_TYPE 5
 #define FF_SP_TYPE 6
+#define FF_BI_TYPE 7
 
 #define FF_BUFFER_HINTS_VALID    0x01 // Buffer hints value is meaningful (if 0 ignore).
 #define FF_BUFFER_HINTS_READABLE 0x02 // Codec will read from buffer.
Index: mythtv/libs/libavcodec/vp5.c
===================================================================
--- mythtv/libs/libavcodec/vp5.c	(revision 18209)
+++ mythtv/libs/libavcodec/vp5.c	(working copy)
@@ -266,7 +266,7 @@
     memset(model->vector_pdv, 0x80, sizeof(model->vector_pdv));
 }
 
-static int vp5_decode_init(AVCodecContext *avctx)
+static av_cold int vp5_decode_init(AVCodecContext *avctx)
 {
     vp56_context_t *s = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/imgconvert.c
===================================================================
--- mythtv/libs/libavcodec/imgconvert.c	(revision 18209)
+++ mythtv/libs/libavcodec/imgconvert.c	(working copy)
@@ -1935,7 +1935,7 @@
 
    - PIX_FMT_422 must convert to and from PIX_FMT_422P.
 
-   The other conversion functions are just optimisations for common cases.
+   The other conversion functions are just optimizations for common cases.
 */
 static const ConvertEntry convert_table[PIX_FMT_NB][PIX_FMT_NB] = {
     [PIX_FMT_YUV420P] = {
Index: mythtv/libs/libavcodec/liba52.c
===================================================================
--- mythtv/libs/libavcodec/liba52.c	(revision 18209)
+++ mythtv/libs/libavcodec/liba52.c	(working copy)
@@ -80,7 +80,7 @@
 }
 #endif
 
-static int a52_decode_init(AVCodecContext *avctx)
+static av_cold int a52_decode_init(AVCodecContext *avctx)
 {
     AC3DecodeState *s = avctx->priv_data;
 
@@ -415,7 +415,7 @@
     return buf_ptr - buf;
 }
 
-static int a52_decode_end(AVCodecContext *avctx)
+static av_cold int a52_decode_end(AVCodecContext *avctx)
 {
     AC3DecodeState *s = avctx->priv_data;
     s->a52_free(s->state);
Index: mythtv/libs/libavcodec/vc1.c
===================================================================
--- mythtv/libs/libavcodec/vc1.c	(revision 18209)
+++ mythtv/libs/libavcodec/vc1.c	(working copy)
@@ -407,7 +407,7 @@
     my = s->mv[dir][0][1];
 
     // store motion vectors for further use in B frames
-    if(s->pict_type == P_TYPE) {
+    if(s->pict_type == FF_P_TYPE) {
         s->current_picture.motion_val[1][s->block_index[0]][0] = mx;
         s->current_picture.motion_val[1][s->block_index[0]][1] = my;
     }
@@ -1041,26 +1041,26 @@
     v->s.pict_type = get_bits1(gb);
     if (v->s.avctx->max_b_frames) {
         if (!v->s.pict_type) {
-            if (get_bits1(gb)) v->s.pict_type = I_TYPE;
-            else v->s.pict_type = B_TYPE;
-        } else v->s.pict_type = P_TYPE;
-    } else v->s.pict_type = v->s.pict_type ? P_TYPE : I_TYPE;
+            if (get_bits1(gb)) v->s.pict_type = FF_I_TYPE;
+            else v->s.pict_type = FF_B_TYPE;
+        } else v->s.pict_type = FF_P_TYPE;
+    } else v->s.pict_type = v->s.pict_type ? FF_P_TYPE : FF_I_TYPE;
 
     v->bi_type = 0;
-    if(v->s.pict_type == B_TYPE) {
+    if(v->s.pict_type == FF_B_TYPE) {
         v->bfraction = get_vlc2(gb, ff_vc1_bfraction_vlc.table, VC1_BFRACTION_VLC_BITS, 1);
         v->bfraction = ff_vc1_bfraction_lut[v->bfraction];
         if(v->bfraction == 0) {
-            v->s.pict_type = BI_TYPE;
+            v->s.pict_type = FF_BI_TYPE;
         }
     }
-    if(v->s.pict_type == I_TYPE || v->s.pict_type == BI_TYPE)
+    if(v->s.pict_type == FF_I_TYPE || v->s.pict_type == FF_BI_TYPE)
         skip_bits(gb, 7); // skip buffer fullness
 
     /* calculate RND */
-    if(v->s.pict_type == I_TYPE || v->s.pict_type == BI_TYPE)
+    if(v->s.pict_type == FF_I_TYPE || v->s.pict_type == FF_BI_TYPE)
         v->rnd = 1;
-    if(v->s.pict_type == P_TYPE)
+    if(v->s.pict_type == FF_P_TYPE)
         v->rnd ^= 1;
 
     /* Quantizer stuff */
@@ -1091,18 +1091,18 @@
         if (v->postprocflag) v->postproc = get_bits1(gb);
     }
     else
-        if (v->multires && v->s.pict_type != B_TYPE) v->respic = get_bits(gb, 2);
+        if (v->multires && v->s.pict_type != FF_B_TYPE) v->respic = get_bits(gb, 2);
 
-    if(v->res_x8 && (v->s.pict_type == I_TYPE || v->s.pict_type == BI_TYPE)){
+    if(v->res_x8 && (v->s.pict_type == FF_I_TYPE || v->s.pict_type == FF_BI_TYPE)){
         v->x8_type = get_bits1(gb);
     }else v->x8_type = 0;
 //av_log(v->s.avctx, AV_LOG_INFO, "%c Frame: QP=[%i]%i (+%i/2) %i\n",
-//        (v->s.pict_type == P_TYPE) ? 'P' : ((v->s.pict_type == I_TYPE) ? 'I' : 'B'), pqindex, v->pq, v->halfpq, v->rangeredfrm);
+//        (v->s.pict_type == FF_P_TYPE) ? 'P' : ((v->s.pict_type == FF_I_TYPE) ? 'I' : 'B'), pqindex, v->pq, v->halfpq, v->rangeredfrm);
 
-    if(v->s.pict_type == I_TYPE || v->s.pict_type == P_TYPE) v->use_ic = 0;
+    if(v->s.pict_type == FF_I_TYPE || v->s.pict_type == FF_P_TYPE) v->use_ic = 0;
 
     switch(v->s.pict_type) {
-    case P_TYPE:
+    case FF_P_TYPE:
         if (v->pq < 5) v->tt_index = 0;
         else if(v->pq < 13) v->tt_index = 1;
         else v->tt_index = 2;
@@ -1185,7 +1185,7 @@
             v->ttfrm = TT_8X8;
         }
         break;
-    case B_TYPE:
+    case FF_B_TYPE:
         if (v->pq < 5) v->tt_index = 0;
         else if(v->pq < 13) v->tt_index = 1;
         else v->tt_index = 2;
@@ -1232,7 +1232,7 @@
     {
         /* AC Syntax */
         v->c_ac_table_index = decode012(gb);
-        if (v->s.pict_type == I_TYPE || v->s.pict_type == BI_TYPE)
+        if (v->s.pict_type == FF_I_TYPE || v->s.pict_type == FF_BI_TYPE)
         {
             v->y_ac_table_index = decode012(gb);
         }
@@ -1240,8 +1240,8 @@
         v->s.dc_table_index = get_bits1(gb);
     }
 
-    if(v->s.pict_type == BI_TYPE) {
-        v->s.pict_type = B_TYPE;
+    if(v->s.pict_type == FF_BI_TYPE) {
+        v->s.pict_type = FF_B_TYPE;
         v->bi_type = 1;
     }
     return 0;
@@ -1260,19 +1260,19 @@
     }
     switch(get_unary(gb, 0, 4)) {
     case 0:
-        v->s.pict_type = P_TYPE;
+        v->s.pict_type = FF_P_TYPE;
         break;
     case 1:
-        v->s.pict_type = B_TYPE;
+        v->s.pict_type = FF_B_TYPE;
         break;
     case 2:
-        v->s.pict_type = I_TYPE;
+        v->s.pict_type = FF_I_TYPE;
         break;
     case 3:
-        v->s.pict_type = BI_TYPE;
+        v->s.pict_type = FF_BI_TYPE;
         break;
     case 4:
-        v->s.pict_type = P_TYPE; // skipped pic
+        v->s.pict_type = FF_P_TYPE; // skipped pic
         v->p_frame_skipped = 1;
         return 0;
     }
@@ -1293,11 +1293,11 @@
     if(v->interlace)
         v->uvsamp = get_bits1(gb);
     if(v->finterpflag) v->interpfrm = get_bits1(gb);
-    if(v->s.pict_type == B_TYPE) {
+    if(v->s.pict_type == FF_B_TYPE) {
         v->bfraction = get_vlc2(gb, ff_vc1_bfraction_vlc.table, VC1_BFRACTION_VLC_BITS, 1);
         v->bfraction = ff_vc1_bfraction_lut[v->bfraction];
         if(v->bfraction == 0) {
-            v->s.pict_type = BI_TYPE; /* XXX: should not happen here */
+            v->s.pict_type = FF_BI_TYPE; /* XXX: should not happen here */
         }
     }
     pqindex = get_bits(gb, 5);
@@ -1318,11 +1318,11 @@
     if (v->quantizer_mode == QUANT_FRAME_EXPLICIT)
         v->pquantizer = get_bits1(gb);
 
-    if(v->s.pict_type == I_TYPE || v->s.pict_type == P_TYPE) v->use_ic = 0;
+    if(v->s.pict_type == FF_I_TYPE || v->s.pict_type == FF_P_TYPE) v->use_ic = 0;
 
     switch(v->s.pict_type) {
-    case I_TYPE:
-    case BI_TYPE:
+    case FF_I_TYPE:
+    case FF_BI_TYPE:
         status = bitplane_decoding(v->acpred_plane, &v->acpred_is_raw, v);
         if (status < 0) return -1;
         av_log(v->s.avctx, AV_LOG_DEBUG, "ACPRED plane encoding: "
@@ -1338,7 +1338,7 @@
             }
         }
         break;
-    case P_TYPE:
+    case FF_P_TYPE:
         if(v->postprocflag)
             v->postproc = get_bits1(gb);
         if (v->extended_mv) v->mvrange = get_unary(gb, 0, 3);
@@ -1429,7 +1429,7 @@
             v->ttfrm = TT_8X8;
         }
         break;
-    case B_TYPE:
+    case FF_B_TYPE:
         if(v->postprocflag)
             v->postproc = get_bits1(gb);
         if (v->extended_mv) v->mvrange = get_unary(gb, 0, 3);
@@ -1483,20 +1483,20 @@
 
     /* AC Syntax */
     v->c_ac_table_index = decode012(gb);
-    if (v->s.pict_type == I_TYPE || v->s.pict_type == BI_TYPE)
+    if (v->s.pict_type == FF_I_TYPE || v->s.pict_type == FF_BI_TYPE)
     {
         v->y_ac_table_index = decode012(gb);
     }
     /* DC Syntax */
     v->s.dc_table_index = get_bits1(gb);
-    if ((v->s.pict_type == I_TYPE || v->s.pict_type == BI_TYPE) && v->dquant) {
+    if ((v->s.pict_type == FF_I_TYPE || v->s.pict_type == FF_BI_TYPE) && v->dquant) {
         av_log(v->s.avctx, AV_LOG_DEBUG, "VOP DQuant info\n");
         vop_dquant_decoding(v);
     }
 
     v->bi_type = 0;
-    if(v->s.pict_type == BI_TYPE) {
-        v->s.pict_type = B_TYPE;
+    if(v->s.pict_type == FF_BI_TYPE) {
+        v->s.pict_type = FF_B_TYPE;
         v->bi_type = 1;
     }
     return 0;
@@ -3017,7 +3017,7 @@
       offset_table[6] = { 0, 1, 3, 7, 15, 31 };
     int mb_has_coeffs = 1; /* last_flag */
     int dmv_x, dmv_y; /* Differential MV components */
-    int index, index1; /* LUT indices */
+    int index, index1; /* LUT indexes */
     int val, sign; /* temp values */
     int first_block = 1;
     int dst_idx, off;
@@ -3250,7 +3250,7 @@
     static const int size_table[6] = { 0, 2, 3, 4, 5, 8 },
       offset_table[6] = { 0, 1, 3, 7, 15, 31 };
     int mb_has_coeffs = 0; /* last_flag */
-    int index, index1; /* LUT indices */
+    int index, index1; /* LUT indexes */
     int val, sign; /* temp values */
     int first_block = 1;
     int dst_idx, off;
@@ -3742,7 +3742,7 @@
         ff_draw_horiz_band(s, s->mb_y * 16, 16);
         s->first_slice_line = 0;
     }
-    s->pict_type = P_TYPE;
+    s->pict_type = FF_P_TYPE;
 }
 
 static void vc1_decode_blocks(VC1Context *v)
@@ -3754,19 +3754,19 @@
     }else{
 
         switch(v->s.pict_type) {
-        case I_TYPE:
+        case FF_I_TYPE:
             if(v->profile == PROFILE_ADVANCED)
                 vc1_decode_i_blocks_adv(v);
             else
                 vc1_decode_i_blocks(v);
             break;
-        case P_TYPE:
+        case FF_P_TYPE:
             if(v->p_frame_skipped)
                 vc1_decode_skip_blocks(v);
             else
                 vc1_decode_p_blocks(v);
             break;
-        case B_TYPE:
+        case FF_B_TYPE:
             if(v->bi_type){
                 if(v->profile == PROFILE_ADVANCED)
                     vc1_decode_i_blocks_adv(v);
@@ -3818,7 +3818,7 @@
  * @todo TODO: Handle VC-1 IDUs (Transport level?)
  * @todo TODO: Decypher remaining bits in extra_data
  */
-static int vc1_decode_init(AVCodecContext *avctx)
+static av_cold int vc1_decode_init(AVCodecContext *avctx)
 {
     VC1Context *v = avctx->priv_data;
     MpegEncContext *s = &v->s;
@@ -4034,24 +4034,24 @@
         }
     }
 
-    if(s->pict_type != I_TYPE && !v->res_rtm_flag){
+    if(s->pict_type != FF_I_TYPE && !v->res_rtm_flag){
         av_free(buf2);
         return -1;
     }
 
     // for hurry_up==5
     s->current_picture.pict_type= s->pict_type;
-    s->current_picture.key_frame= s->pict_type == I_TYPE;
+    s->current_picture.key_frame= s->pict_type == FF_I_TYPE;
 
     /* skip B-frames if we don't have reference frames */
-    if(s->last_picture_ptr==NULL && (s->pict_type==B_TYPE || s->dropable)){
+    if(s->last_picture_ptr==NULL && (s->pict_type==FF_B_TYPE || s->dropable)){
         av_free(buf2);
         return -1;//buf_size;
     }
     /* skip b frames if we are in a hurry */
-    if(avctx->hurry_up && s->pict_type==B_TYPE) return -1;//buf_size;
-    if(   (avctx->skip_frame >= AVDISCARD_NONREF && s->pict_type==B_TYPE)
-       || (avctx->skip_frame >= AVDISCARD_NONKEY && s->pict_type!=I_TYPE)
+    if(avctx->hurry_up && s->pict_type==FF_B_TYPE) return -1;//buf_size;
+    if(   (avctx->skip_frame >= AVDISCARD_NONREF && s->pict_type==FF_B_TYPE)
+       || (avctx->skip_frame >= AVDISCARD_NONKEY && s->pict_type!=FF_I_TYPE)
        ||  avctx->skip_frame >= AVDISCARD_ALL) {
         av_free(buf2);
         return buf_size;
@@ -4063,7 +4063,7 @@
     }
 
     if(s->next_p_frame_damaged){
-        if(s->pict_type==B_TYPE)
+        if(s->pict_type==FF_B_TYPE)
             return buf_size;
         else
             s->next_p_frame_damaged=0;
@@ -4090,7 +4090,7 @@
 
 assert(s->current_picture.pict_type == s->current_picture_ptr->pict_type);
 assert(s->current_picture.pict_type == s->pict_type);
-    if (s->pict_type == B_TYPE || s->low_delay) {
+    if (s->pict_type == FF_B_TYPE || s->low_delay) {
         *pict= *(AVFrame*)s->current_picture_ptr;
     } else if (s->last_picture_ptr != NULL) {
         *pict= *(AVFrame*)s->last_picture_ptr;
@@ -4102,7 +4102,7 @@
     }
 
     /* Return the Picture timestamp as the frame number */
-    /* we substract 1 because it is added on utils.c    */
+    /* we subtract 1 because it is added on utils.c    */
     avctx->frame_number = s->picture_number - 1;
 
     av_free(buf2);
@@ -4113,7 +4113,7 @@
 /** Close a VC1/WMV3 decoder
  * @warning Initial try at using MpegEncContext stuff
  */
-static int vc1_decode_end(AVCodecContext *avctx)
+static av_cold int vc1_decode_end(AVCodecContext *avctx)
 {
     VC1Context *v = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/vorbis_enc.c
===================================================================
--- mythtv/libs/libavcodec/vorbis_enc.c	(revision 18209)
+++ mythtv/libs/libavcodec/vorbis_enc.c	(working copy)
@@ -932,7 +932,7 @@
     return 1;
 }
 
-static int vorbis_encode_init(AVCodecContext * avccontext)
+static av_cold int vorbis_encode_init(AVCodecContext * avccontext)
 {
     venc_context_t * venc = avccontext->priv_data;
 
@@ -1015,7 +1015,7 @@
 }
 
 
-static int vorbis_encode_close(AVCodecContext * avccontext)
+static av_cold int vorbis_encode_close(AVCodecContext * avccontext)
 {
     venc_context_t * venc = avccontext->priv_data;
     int i;
Index: mythtv/libs/libavcodec/bitstream.c
===================================================================
--- mythtv/libs/libavcodec/bitstream.c	(revision 18209)
+++ mythtv/libs/libavcodec/bitstream.c	(working copy)
@@ -109,6 +109,8 @@
     index = vlc->table_size;
     vlc->table_size += size;
     if (vlc->table_size > vlc->table_allocated) {
+        if(use_static>1)
+            abort(); //cant do anything, init_vlc() is used with too little memory
         vlc->table_allocated += (1 << vlc->bits);
         if(use_static)
             vlc->table = ff_realloc_static(vlc->table,
@@ -134,7 +136,7 @@
     VLC_TYPE (*table)[2];
 
     table_size = 1 << table_nb_bits;
-    table_index = alloc_table(vlc, table_size, flags & INIT_VLC_USE_STATIC);
+    table_index = alloc_table(vlc, table_size, flags & (INIT_VLC_USE_STATIC|INIT_VLC_USE_NEW_STATIC));
 #ifdef DEBUG_VLC
     av_log(NULL,AV_LOG_DEBUG,"new table index=%d size=%d code_prefix=%x n=%d\n",
            table_index, table_size, code_prefix, n_prefix);
@@ -263,7 +265,13 @@
              int flags)
 {
     vlc->bits = nb_bits;
-    if(!(flags & INIT_VLC_USE_STATIC)) {
+    if(flags & INIT_VLC_USE_NEW_STATIC){
+        if(vlc->table_size && vlc->table_size == vlc->table_allocated){
+            return 0;
+        }else if(vlc->table_size){
+            abort(); // fatal error, we are called on a partially initialized table
+        }
+    }else if(!(flags & INIT_VLC_USE_STATIC)) {
         vlc->table = NULL;
         vlc->table_allocated = 0;
         vlc->table_size = 0;
@@ -286,6 +294,8 @@
         av_freep(&vlc->table);
         return -1;
     }
+    if((flags & INIT_VLC_USE_NEW_STATIC) && vlc->table_size != vlc->table_allocated)
+        av_log(NULL, AV_LOG_ERROR, "needed %d had %d\n", vlc->table_size, vlc->table_allocated);
     return 0;
 }
 
Index: mythtv/libs/libavcodec/cook.c
===================================================================
--- mythtv/libs/libavcodec/cook.c	(revision 18209)
+++ mythtv/libs/libavcodec/cook.c	(working copy)
@@ -359,7 +359,7 @@
  * Fill the gain array for the timedomain quantization.
  *
  * @param q                 pointer to the COOKContext
- * @param gaininfo[9]       array of gain indices
+ * @param gaininfo[9]       array of gain indexes
  */
 
 static void decode_gain_info(GetBitContext *gb, int *gaininfo)
Index: mythtv/libs/libavcodec/wnv1.c
===================================================================
--- mythtv/libs/libavcodec/wnv1.c	(revision 18209)
+++ mythtv/libs/libavcodec/wnv1.c	(working copy)
@@ -116,7 +116,7 @@
     return buf_size;
 }
 
-static int decode_init(AVCodecContext *avctx){
+static av_cold int decode_init(AVCodecContext *avctx){
     WNV1Context * const l = avctx->priv_data;
 
     l->avctx = avctx;
Index: mythtv/libs/libavcodec/vc1.h
===================================================================
--- mythtv/libs/libavcodec/vc1.h	(revision 18209)
+++ mythtv/libs/libavcodec/vc1.h	(working copy)
@@ -127,9 +127,6 @@
 };
 //@}
 
-/** One more frame type */
-#define BI_TYPE 7
-
 enum CodingSet {
     CS_HIGH_MOT_INTRA = 0,
     CS_HIGH_MOT_INTER,
Index: mythtv/libs/libavcodec/bitstream.h
===================================================================
--- mythtv/libs/libavcodec/bitstream.h	(revision 18209)
+++ mythtv/libs/libavcodec/bitstream.h	(working copy)
@@ -800,10 +800,20 @@
              const void *codes, int codes_wrap, int codes_size,
              const void *symbols, int symbols_wrap, int symbols_size,
              int flags);
-#define INIT_VLC_USE_STATIC 1
+#define INIT_VLC_USE_STATIC 1 ///< VERY strongly deprecated and forbidden
 #define INIT_VLC_LE         2
+#define INIT_VLC_USE_NEW_STATIC 4
 void free_vlc(VLC *vlc);
 
+#define INIT_VLC_STATIC(vlc, bits, a,b,c,d,e,f,g, static_size)\
+{\
+    static VLC_TYPE table[static_size][2];\
+    (vlc)->table= table;\
+    (vlc)->table_allocated= static_size;\
+    init_vlc(vlc, bits, a,b,c,d,e,f,g, INIT_VLC_USE_NEW_STATIC);\
+}
+
+
 /**
  *
  * if the vlc code is invalid and max_depth=1 than no bits will be removed
Index: mythtv/libs/libavcodec/dsicinav.c
===================================================================
--- mythtv/libs/libavcodec/dsicinav.c	(revision 18209)
+++ mythtv/libs/libavcodec/dsicinav.c	(working copy)
@@ -86,7 +86,7 @@
 };
 
 
-static int cinvideo_decode_init(AVCodecContext *avctx)
+static av_cold int cinvideo_decode_init(AVCodecContext *avctx)
 {
     CinVideoContext *cin = avctx->priv_data;
     unsigned int i;
@@ -284,7 +284,7 @@
     return buf_size;
 }
 
-static int cinvideo_decode_end(AVCodecContext *avctx)
+static av_cold int cinvideo_decode_end(AVCodecContext *avctx)
 {
     CinVideoContext *cin = avctx->priv_data;
     int i;
@@ -298,7 +298,7 @@
     return 0;
 }
 
-static int cinaudio_decode_init(AVCodecContext *avctx)
+static av_cold int cinaudio_decode_init(AVCodecContext *avctx)
 {
     CinAudioContext *cin = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/qdm2.c
===================================================================
--- mythtv/libs/libavcodec/qdm2.c	(revision 18209)
+++ mythtv/libs/libavcodec/qdm2.c	(working copy)
@@ -1431,7 +1431,7 @@
     if (q->sub_packet_list_B[0].packet == NULL)
         return;
 
-    /* reset minimum indices for FFT coefficients */
+    /* reset minimum indexes for FFT coefficients */
     q->fft_coefs_index = 0;
     for (i=0; i < 5; i++)
         q->fft_coefs_min_index[i] = -1;
@@ -1481,7 +1481,7 @@
         }
     } // Loop on B packets
 
-    /* calculate maximum indices for FFT coefficients */
+    /* calculate maximum indexes for FFT coefficients */
     for (i = 0, j = -1; i < 5; i++)
         if (q->fft_coefs_min_index[i] >= 0) {
             if (j >= 0)
Index: mythtv/libs/libavcodec/vorbis_dec.c
===================================================================
--- mythtv/libs/libavcodec/vorbis_dec.c	(revision 18209)
+++ mythtv/libs/libavcodec/vorbis_dec.c	(working copy)
@@ -923,7 +923,7 @@
 
 // Process the extradata using the functions above (identification header, setup header)
 
-static int vorbis_decode_init(AVCodecContext *avccontext) {
+static av_cold int vorbis_decode_init(AVCodecContext *avccontext) {
     vorbis_context *vc = avccontext->priv_data ;
     uint8_t *headers = avccontext->extradata;
     int headers_len=avccontext->extradata_size;
@@ -1617,7 +1617,7 @@
 
 // Close decoder
 
-static int vorbis_decode_close(AVCodecContext *avccontext) {
+static av_cold int vorbis_decode_close(AVCodecContext *avccontext) {
     vorbis_context *vc = avccontext->priv_data;
 
     vorbis_free(vc);
Index: mythtv/libs/libavcodec/libfaac.c
===================================================================
--- mythtv/libs/libavcodec/libfaac.c	(revision 18209)
+++ mythtv/libs/libavcodec/libfaac.c	(working copy)
@@ -31,7 +31,7 @@
     faacEncHandle faac_handle;
 } FaacAudioContext;
 
-static int Faac_encode_init(AVCodecContext *avctx)
+static av_cold int Faac_encode_init(AVCodecContext *avctx)
 {
     FaacAudioContext *s = avctx->priv_data;
     faacEncConfigurationPtr faac_cfg;
@@ -132,7 +132,7 @@
     return bytes_written;
 }
 
-static int Faac_encode_close(AVCodecContext *avctx)
+static av_cold int Faac_encode_close(AVCodecContext *avctx)
 {
     FaacAudioContext *s = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/cyuv.c
===================================================================
--- mythtv/libs/libavcodec/cyuv.c	(revision 18209)
+++ mythtv/libs/libavcodec/cyuv.c	(working copy)
@@ -44,7 +44,7 @@
     AVFrame frame;
 } CyuvDecodeContext;
 
-static int cyuv_decode_init(AVCodecContext *avctx)
+static av_cold int cyuv_decode_init(AVCodecContext *avctx)
 {
     CyuvDecodeContext *s = avctx->priv_data;
 
@@ -164,7 +164,7 @@
     return buf_size;
 }
 
-static int cyuv_decode_end(AVCodecContext *avctx)
+static av_cold int cyuv_decode_end(AVCodecContext *avctx)
 {
 /*    CyuvDecodeContext *s = avctx->priv_data;*/
 
Index: mythtv/libs/libavcodec/loco.c
===================================================================
--- mythtv/libs/libavcodec/loco.c	(revision 18209)
+++ mythtv/libs/libavcodec/loco.c	(working copy)
@@ -225,7 +225,7 @@
     return buf_size;
 }
 
-static int decode_init(AVCodecContext *avctx){
+static av_cold int decode_init(AVCodecContext *avctx){
     LOCOContext * const l = avctx->priv_data;
     int version;
 
Index: mythtv/libs/libavcodec/huffyuv.c
===================================================================
--- mythtv/libs/libavcodec/huffyuv.c	(revision 18209)
+++ mythtv/libs/libavcodec/huffyuv.c	(working copy)
@@ -478,7 +478,7 @@
 }
 
 #ifdef CONFIG_DECODERS
-static int decode_init(AVCodecContext *avctx)
+static av_cold int decode_init(AVCodecContext *avctx)
 {
     HYuvContext *s = avctx->priv_data;
 
@@ -599,7 +599,7 @@
     return index;
 }
 
-static int encode_init(AVCodecContext *avctx)
+static av_cold int encode_init(AVCodecContext *avctx)
 {
     HYuvContext *s = avctx->priv_data;
     int i, j;
@@ -1210,7 +1210,7 @@
 }
 
 #ifdef CONFIG_DECODERS
-static int decode_end(AVCodecContext *avctx)
+static av_cold int decode_end(AVCodecContext *avctx)
 {
     HYuvContext *s = avctx->priv_data;
     int i;
@@ -1420,7 +1420,7 @@
     return size*4;
 }
 
-static int encode_end(AVCodecContext *avctx)
+static av_cold int encode_end(AVCodecContext *avctx)
 {
     HYuvContext *s = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/svq3.c
===================================================================
--- mythtv/libs/libavcodec/svq3.c	(revision 18209)
+++ mythtv/libs/libavcodec/svq3.c	(working copy)
@@ -419,10 +419,10 @@
   h->topright_samples_available        = 0xFFFF;
 
   if (mb_type == 0) {           /* SKIP */
-    if (s->pict_type == P_TYPE || s->next_picture.mb_type[mb_xy] == -1) {
+    if (s->pict_type == FF_P_TYPE || s->next_picture.mb_type[mb_xy] == -1) {
       svq3_mc_dir_part (s, 16*s->mb_x, 16*s->mb_y, 16, 16, 0, 0, 0, 0, 0, 0);
 
-      if (s->pict_type == B_TYPE) {
+      if (s->pict_type == FF_B_TYPE) {
         svq3_mc_dir_part (s, 16*s->mb_x, 16*s->mb_y, 16, 16, 0, 0, 0, 0, 1, 1);
       }
 
@@ -483,15 +483,15 @@
       }else
         memset (&h->ref_cache[m][scan8[0] - 1*8 - 1], PART_NOT_AVAILABLE, 8);
 
-      if (s->pict_type != B_TYPE)
+      if (s->pict_type != FF_B_TYPE)
         break;
     }
 
     /* decode motion vector(s) and form prediction(s) */
-    if (s->pict_type == P_TYPE) {
+    if (s->pict_type == FF_P_TYPE) {
       if(svq3_mc_dir (h, (mb_type - 1), mode, 0, 0) < 0)
         return -1;
-    } else {        /* B_TYPE */
+    } else {        /* FF_B_TYPE */
       if (mb_type != 2) {
         if(svq3_mc_dir (h, 0, mode, 0, 0) < 0)
           return -1;
@@ -590,11 +590,11 @@
     mb_type = MB_TYPE_INTRA16x16;
   }
 
-  if (!IS_INTER(mb_type) && s->pict_type != I_TYPE) {
+  if (!IS_INTER(mb_type) && s->pict_type != FF_I_TYPE) {
     for (i=0; i < 4; i++) {
       memset (s->current_picture.motion_val[0][b_xy + i*h->b_stride], 0, 4*2*sizeof(int16_t));
     }
-    if (s->pict_type == B_TYPE) {
+    if (s->pict_type == FF_B_TYPE) {
       for (i=0; i < 4; i++) {
         memset (s->current_picture.motion_val[1][b_xy + i*h->b_stride], 0, 4*2*sizeof(int16_t));
       }
@@ -603,12 +603,12 @@
   if (!IS_INTRA4x4(mb_type)) {
     memset (h->intra4x4_pred_mode[mb_xy], DC_PRED, 8);
   }
-  if (!IS_SKIP(mb_type) || s->pict_type == B_TYPE) {
+  if (!IS_SKIP(mb_type) || s->pict_type == FF_B_TYPE) {
     memset (h->non_zero_count_cache + 8, 0, 4*9*sizeof(uint8_t));
     s->dsp.clear_blocks(h->mb);
   }
 
-  if (!IS_INTRA16x16(mb_type) && (!IS_SKIP(mb_type) || s->pict_type == B_TYPE)) {
+  if (!IS_INTRA16x16(mb_type) && (!IS_SKIP(mb_type) || s->pict_type == FF_B_TYPE)) {
     if ((vlc = svq3_get_ue_golomb (&s->gb)) >= 48){
       av_log(h->s.avctx, AV_LOG_ERROR, "cbp_vlc=%d\n", vlc);
       return -1;
@@ -616,7 +616,7 @@
 
     cbp = IS_INTRA(mb_type) ? golomb_to_intra4x4_cbp[vlc] : golomb_to_inter_cbp[vlc];
   }
-  if (IS_INTRA16x16(mb_type) || (s->pict_type != I_TYPE && s->adaptive_quant && cbp)) {
+  if (IS_INTRA16x16(mb_type) || (s->pict_type != FF_I_TYPE && s->adaptive_quant && cbp)) {
     s->qscale += svq3_get_se_golomb (&s->gb);
 
     if (s->qscale > 31){
@@ -760,7 +760,7 @@
 
 static int svq3_decode_frame (AVCodecContext *avctx,
                               void *data, int *data_size,
-                              uint8_t *buf, int buf_size) {
+                              const uint8_t *buf, int buf_size) {
   MpegEncContext *const s = avctx->priv_data;
   H264Context *const h = avctx->priv_data;
   int m, mb_type;
@@ -859,21 +859,21 @@
 
   /* for hurry_up==5 */
   s->current_picture.pict_type = s->pict_type;
-  s->current_picture.key_frame = (s->pict_type == I_TYPE);
+  s->current_picture.key_frame = (s->pict_type == FF_I_TYPE);
 
   /* Skip B-frames if we do not have reference frames. */
-  if (s->last_picture_ptr == NULL && s->pict_type == B_TYPE) return 0;
+  if (s->last_picture_ptr == NULL && s->pict_type == FF_B_TYPE) return 0;
   /* Skip B-frames if we are in a hurry. */
-  if (avctx->hurry_up && s->pict_type == B_TYPE) return 0;
+  if (avctx->hurry_up && s->pict_type == FF_B_TYPE) return 0;
   /* Skip everything if we are in a hurry >= 5. */
   if (avctx->hurry_up >= 5) return 0;
-  if(  (avctx->skip_frame >= AVDISCARD_NONREF && s->pict_type==B_TYPE)
-     ||(avctx->skip_frame >= AVDISCARD_NONKEY && s->pict_type!=I_TYPE)
+  if(  (avctx->skip_frame >= AVDISCARD_NONREF && s->pict_type==FF_B_TYPE)
+     ||(avctx->skip_frame >= AVDISCARD_NONKEY && s->pict_type!=FF_I_TYPE)
      || avctx->skip_frame >= AVDISCARD_ALL)
       return 0;
 
   if (s->next_p_frame_damaged) {
-    if (s->pict_type == B_TYPE)
+    if (s->pict_type == FF_B_TYPE)
       return 0;
     else
       s->next_p_frame_damaged = 0;
@@ -882,7 +882,7 @@
   if (frame_start (h) < 0)
     return -1;
 
-  if (s->pict_type == B_TYPE) {
+  if (s->pict_type == FF_B_TYPE) {
     h->frame_num_offset = (h->slice_num - h->prev_frame_num);
 
     if (h->frame_num_offset < 0) {
@@ -930,9 +930,9 @@
 
       mb_type = svq3_get_ue_golomb (&s->gb);
 
-      if (s->pict_type == I_TYPE) {
+      if (s->pict_type == FF_I_TYPE) {
         mb_type += 8;
-      } else if (s->pict_type == B_TYPE && mb_type >= 4) {
+      } else if (s->pict_type == FF_B_TYPE && mb_type >= 4) {
         mb_type += 4;
       }
       if (mb_type > 33 || svq3_decode_mb (h, mb_type)) {
@@ -944,9 +944,9 @@
         hl_decode_mb (h);
       }
 
-      if (s->pict_type != B_TYPE && !s->low_delay) {
+      if (s->pict_type != FF_B_TYPE && !s->low_delay) {
         s->current_picture.mb_type[s->mb_x + s->mb_y*s->mb_stride] =
-                        (s->pict_type == P_TYPE && mb_type < 8) ? (mb_type - 1) : -1;
+                        (s->pict_type == FF_P_TYPE && mb_type < 8) ? (mb_type - 1) : -1;
       }
     }
 
@@ -955,7 +955,7 @@
 
   MPV_frame_end(s);
 
-  if (s->pict_type == B_TYPE || s->low_delay) {
+  if (s->pict_type == FF_B_TYPE || s->low_delay) {
     *(AVFrame *) data = *(AVFrame *) &s->current_picture;
   } else {
     *(AVFrame *) data = *(AVFrame *) &s->last_picture;
Index: mythtv/libs/libavcodec/tscc.c
===================================================================
--- mythtv/libs/libavcodec/tscc.c	(revision 18209)
+++ mythtv/libs/libavcodec/tscc.c	(working copy)
@@ -253,7 +253,7 @@
  * Init tscc decoder
  *
  */
-static int decode_init(AVCodecContext *avctx)
+static av_cold int decode_init(AVCodecContext *avctx)
 {
     CamtasiaContext * const c = avctx->priv_data;
     int zret; // Zlib return code
@@ -316,7 +316,7 @@
  * Uninit tscc decoder
  *
  */
-static int decode_end(AVCodecContext *avctx)
+static av_cold int decode_end(AVCodecContext *avctx)
 {
     CamtasiaContext * const c = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/targa.c
===================================================================
--- mythtv/libs/libavcodec/targa.c	(revision 18209)
+++ mythtv/libs/libavcodec/targa.c	(working copy)
@@ -220,7 +220,7 @@
     return buf_size;
 }
 
-static int targa_init(AVCodecContext *avctx){
+static av_cold int targa_init(AVCodecContext *avctx){
     TargaContext *s = avctx->priv_data;
 
     avcodec_get_frame_defaults((AVFrame*)&s->picture);
@@ -230,7 +230,7 @@
     return 0;
 }
 
-static int targa_end(AVCodecContext *avctx){
+static av_cold int targa_end(AVCodecContext *avctx){
     TargaContext *s = avctx->priv_data;
 
     if(s->picture.data[0])
Index: mythtv/libs/libavcodec/gif.c
===================================================================
--- mythtv/libs/libavcodec/gif.c	(revision 18209)
+++ mythtv/libs/libavcodec/gif.c	(working copy)
@@ -308,7 +308,7 @@
     AVFrame picture;
 } GIFContext;
 
-static int gif_encode_init(AVCodecContext *avctx)
+static av_cold int gif_encode_init(AVCodecContext *avctx)
 {
     GIFContext *s = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/vb.c
===================================================================
--- mythtv/libs/libavcodec/vb.c	(revision 18209)
+++ mythtv/libs/libavcodec/vb.c	(working copy)
@@ -234,7 +234,7 @@
     return buf_size;
 }
 
-static int decode_init(AVCodecContext *avctx)
+static av_cold int decode_init(AVCodecContext *avctx)
 {
     VBDecContext * const c = avctx->priv_data;
 
@@ -257,7 +257,7 @@
     return 0;
 }
 
-static int decode_end(AVCodecContext *avctx)
+static av_cold int decode_end(AVCodecContext *avctx)
 {
     VBDecContext *c = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/vp6.c
===================================================================
--- mythtv/libs/libavcodec/vp6.c	(revision 18209)
+++ mythtv/libs/libavcodec/vp6.c	(working copy)
@@ -610,7 +610,7 @@
     }
 }
 
-static int vp6_decode_init(AVCodecContext *avctx)
+static av_cold int vp6_decode_init(AVCodecContext *avctx)
 {
     vp56_context_t *s = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/pcm.c
===================================================================
--- mythtv/libs/libavcodec/pcm.c	(revision 18209)
+++ mythtv/libs/libavcodec/pcm.c	(working copy)
@@ -42,7 +42,7 @@
  * alaw2linear() - Convert an A-law value to 16-bit linear PCM
  *
  */
-static int alaw2linear(unsigned char a_val)
+static av_cold int alaw2linear(unsigned char a_val)
 {
         int t;
         int seg;
@@ -57,7 +57,7 @@
         return ((a_val & SIGN_BIT) ? t : -t);
 }
 
-static int ulaw2linear(unsigned char u_val)
+static av_cold int ulaw2linear(unsigned char u_val)
 {
         int t;
 
@@ -78,7 +78,7 @@
 static uint8_t linear_to_alaw[16384];
 static uint8_t linear_to_ulaw[16384];
 
-static void build_xlaw_table(uint8_t *linear_to_xlaw,
+static av_cold void build_xlaw_table(uint8_t *linear_to_xlaw,
                              int (*xlaw2linear)(unsigned char),
                              int mask)
 {
@@ -102,7 +102,7 @@
     linear_to_xlaw[0] = linear_to_xlaw[1];
 }
 
-static int pcm_encode_init(AVCodecContext *avctx)
+static av_cold int pcm_encode_init(AVCodecContext *avctx)
 {
     avctx->frame_size = 1;
     switch(avctx->codec->id) {
@@ -152,7 +152,7 @@
     return 0;
 }
 
-static int pcm_encode_close(AVCodecContext *avctx)
+static av_cold int pcm_encode_close(AVCodecContext *avctx)
 {
     av_freep(&avctx->coded_frame);
 
@@ -323,7 +323,7 @@
     short table[256];
 } PCMDecode;
 
-static int pcm_decode_init(AVCodecContext * avctx)
+static av_cold int pcm_decode_init(AVCodecContext * avctx)
 {
     PCMDecode *s = avctx->priv_data;
     int i;
Index: mythtv/libs/libavcodec/pnmenc.c
===================================================================
--- mythtv/libs/libavcodec/pnmenc.c	(revision 18209)
+++ mythtv/libs/libavcodec/pnmenc.c	(working copy)
@@ -23,7 +23,7 @@
 #include "pnm.h"
 
 
-static int common_init(AVCodecContext *avctx){
+static av_cold int common_init(AVCodecContext *avctx){
     PNMContext *s = avctx->priv_data;
 
     avcodec_get_frame_defaults((AVFrame*)&s->picture);
Index: mythtv/libs/libavcodec/gifdec.c
===================================================================
--- mythtv/libs/libavcodec/gifdec.c	(revision 18209)
+++ mythtv/libs/libavcodec/gifdec.c	(working copy)
@@ -272,7 +272,7 @@
     return -1;
 }
 
-static int gif_decode_init(AVCodecContext *avctx)
+static av_cold int gif_decode_init(AVCodecContext *avctx)
 {
     GifState *s = avctx->priv_data;
 
@@ -317,7 +317,7 @@
     return s->bytestream - buf;
 }
 
-static int gif_decode_close(AVCodecContext *avctx)
+static av_cold int gif_decode_close(AVCodecContext *avctx)
 {
     GifState *s = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/adpcm.c
===================================================================
--- mythtv/libs/libavcodec/adpcm.c	(revision 18209)
+++ mythtv/libs/libavcodec/adpcm.c	(working copy)
@@ -629,7 +629,7 @@
 }
 #endif //CONFIG_ENCODERS
 
-static int adpcm_decode_init(AVCodecContext * avctx)
+static av_cold int adpcm_decode_init(AVCodecContext * avctx)
 {
     ADPCMContext *c = avctx->priv_data;
     unsigned int max_channels = 2;
Index: mythtv/libs/libavcodec/libxvid_rc.c
===================================================================
--- mythtv/libs/libavcodec/libxvid_rc.c	(revision 18209)
+++ mythtv/libs/libavcodec/libxvid_rc.c	(working copy)
@@ -134,7 +134,7 @@
     if(!dry_run)
         s->rc_context.dry_run_qscale= 0;
 
-    if(s->pict_type == B_TYPE) //FIXME this is not exactly identical to xvid
+    if(s->pict_type == FF_B_TYPE) //FIXME this is not exactly identical to xvid
         return xvid_plg_data.quant * FF_QP2LAMBDA * s->avctx->b_quant_factor + s->avctx->b_quant_offset;
     else
         return xvid_plg_data.quant * FF_QP2LAMBDA;
Index: mythtv/libs/libavcodec/msvideo1.c
===================================================================
--- mythtv/libs/libavcodec/msvideo1.c	(revision 18209)
+++ mythtv/libs/libavcodec/msvideo1.c	(working copy)
@@ -59,7 +59,7 @@
 
 } Msvideo1Context;
 
-static int msvideo1_decode_init(AVCodecContext *avctx)
+static av_cold int msvideo1_decode_init(AVCodecContext *avctx)
 {
     Msvideo1Context *s = avctx->priv_data;
 
@@ -323,7 +323,7 @@
     return buf_size;
 }
 
-static int msvideo1_decode_end(AVCodecContext *avctx)
+static av_cold int msvideo1_decode_end(AVCodecContext *avctx)
 {
     Msvideo1Context *s = avctx->priv_data;
 
Index: mythtv/libs/libavcodec/ac3enc.c
===================================================================
--- mythtv/libs/libavcodec/ac3enc.c	(revision 18209)
+++ mythtv/libs/libavcodec/ac3enc.c	(working copy)
@@ -624,7 +624,7 @@
     return 0;
 }
 
-static int AC3_encode_init(AVCodecContext *avctx)
+static av_cold int AC3_encode_init(AVCodecContext *avctx)
 {
     int freq = avctx->sample_rate;
     int bitrate = avctx->bit_rate;
@@ -1259,7 +1259,7 @@
     return output_frame_end(s);
 }
 
-static int AC3_encode_close(AVCodecContext *avctx)
+static av_cold int AC3_encode_close(AVCodecContext *avctx)
 {
     av_freep(&avctx->coded_frame);
     return 0;
Index: mythtv/libs/libavcodec/h261dec.c
===================================================================
--- mythtv/libs/libavcodec/h261dec.c	(revision 18209)
+++ mythtv/libs/libavcodec/h261dec.c	(working copy)
@@ -48,7 +48,7 @@
 
 static int h261_decode_block(H261Context * h, DCTELEM * block, int n, int coded);
 
-static void h261_decode_init_vlc(H261Context *h){
+static av_cold void h261_decode_init_vlc(H261Context *h){
     static int done = 0;
 
     if(!done){
@@ -70,7 +70,7 @@
     }
 }
 
-static int h261_decode_init(AVCodecContext *avctx){
+static av_cold int h261_decode_init(AVCodecContext *avctx){
     H261Context *h= avctx->priv_data;
     MpegEncContext * const s = &h->s;
 
@@ -493,9 +493,9 @@
         skip_bits(&s->gb, 8);
     }
 
-    // h261 has no I-FRAMES, but if we pass I_TYPE for the first frame, the codec crashes if it does
+    // h261 has no I-FRAMES, but if we pass FF_I_TYPE for the first frame, the codec crashes if it does
     // not contain all I-blocks (e.g. when a packet is lost)
-    s->pict_type = P_TYPE;
+    s->pict_type = FF_P_TYPE;
 
     h->gob_number = 0;
     return 0;
@@ -593,12 +593,12 @@
 
     // for hurry_up==5
     s->current_picture.pict_type= s->pict_type;
-    s->current_picture.key_frame= s->pict_type == I_TYPE;
+    s->current_picture.key_frame= s->pict_type == FF_I_TYPE;
 
     /* skip everything if we are in a hurry>=5 */
     if(avctx->hurry_up>=5) return get_consumed_bytes(s, buf_size);
-    if(  (avctx->skip_frame >= AVDISCARD_NONREF && s->pict_type==B_TYPE)
-       ||(avctx->skip_frame >= AVDISCARD_NONKEY && s->pict_type!=I_TYPE)
+    if(  (avctx->skip_frame >= AVDISCARD_NONREF && s->pict_type==FF_B_TYPE)
+       ||(avctx->skip_frame >= AVDISCARD_NONKEY && s->pict_type!=FF_I_TYPE)
        || avctx->skip_frame >= AVDISCARD_ALL)
         return get_consumed_bytes(s, buf_size);
 
@@ -628,7 +628,7 @@
     return get_consumed_bytes(s, buf_size);
 }
 
-static int h261_decode_end(AVCodecContext *avctx)
+static av_cold int h261_decode_end(AVCodecContext *avctx)
 {
     H261Context *h= avctx->priv_data;
     MpegEncContext *s = &h->s;
Index: mythtv/libs/libavcodec/wavpack.c
===================================================================
--- mythtv/libs/libavcodec/wavpack.c	(revision 18209)
+++ mythtv/libs/libavcodec/wavpack.c	(working copy)
@@ -354,7 +354,7 @@
     return count;
 }
 
-static int wavpack_decode_init(AVCodecContext *avctx)
+static av_cold int wavpack_decode_init(AVCodecContext *avctx)
 {
     WavpackContext *s = avctx->priv_data;
 
Index: mythtv/libs/libpostproc/postprocess_altivec_template.c
===================================================================
--- mythtv/libs/libpostproc/postprocess_altivec_template.c	(revision 18209)
+++ mythtv/libs/libpostproc/postprocess_altivec_template.c	(working copy)
@@ -194,7 +194,7 @@
     One could remove the recomputation of the perm
     vector by assuming (stride % 16) == 0, unfortunately
     this is not always true. Quite a lot of load/stores
-    can be removed by assuming proper alignement of
+    can be removed by assuming proper alignment of
     src & stride :-(
   */
   uint8_t *src2 = src;
@@ -382,7 +382,7 @@
     One could remove the recomputation of the perm
     vector by assuming (stride % 16) == 0, unfortunately
     this is not always true. Quite a lot of load/stores
-    can be removed by assuming proper alignement of
+    can be removed by assuming proper alignment of
     src & stride :-(
   */
   uint8_t *src2 = src;
@@ -469,7 +469,7 @@
   const vector signed short dornotd = vec_sel((vector signed short)zero,
                                               dclampedfinal,
                                               vec_cmplt(absmE, vqp));
-  /* add/substract to l4 and l5 */
+  /* add/subtract to l4 and l5 */
   const vector signed short vb4minusd = vec_sub(vb4, dornotd);
   const vector signed short vb5plusd = vec_add(vb5, dornotd);
   /* finally, stores */
@@ -506,7 +506,7 @@
     One could remove the recomputation of the perm
     vector by assuming (stride % 16) == 0, unfortunately
     this is not always true. Quite a lot of load/stores
-    can be removed by assuming proper alignement of
+    can be removed by assuming proper alignment of
     src & stride :-(
   */
   uint8_t *srcCopy = src;
Index: mythtv/libs/libavformat/ipmovie.c
===================================================================
--- mythtv/libs/libavformat/ipmovie.c	(revision 18209)
+++ mythtv/libs/libavformat/ipmovie.c	(working copy)
@@ -446,7 +446,7 @@
             last_color = first_color + AV_RL16(&scratch[2]) - 1;
             /* sanity check (since they are 16 bit values) */
             if ((first_color > 0xFF) || (last_color > 0xFF)) {
-                debug_ipmovie("demux_ipmovie: set_palette indices out of range (%d -> %d)\n",
+                debug_ipmovie("demux_ipmovie: set_palette indexes out of range (%d -> %d)\n",
                     first_color, last_color);
                 chunk_type = CHUNK_BAD;
                 break;
Index: mythtv/libs/libavformat/matroskadec.c
===================================================================
--- mythtv/libs/libavformat/matroskadec.c	(revision 18209)
+++ mythtv/libs/libavformat/matroskadec.c	(working copy)
@@ -99,8 +99,8 @@
     //..
 } MatroskaSubtitleTrack;
 
-#define MAX_TRACK_SIZE (FFMAX(FFMAX(sizeof(MatroskaVideoTrack), \
-                                    sizeof(MatroskaAudioTrack)), \
+#define MAX_TRACK_SIZE (FFMAX3(sizeof(MatroskaVideoTrack), \
+                                    sizeof(MatroskaAudioTrack), \
                                     sizeof(MatroskaSubtitleTrack)))
 
 typedef struct MatroskaLevel {
Index: mythtv/libs/libavformat/avidec.c
===================================================================
--- mythtv/libs/libavformat/avidec.c	(revision 18209)
+++ mythtv/libs/libavformat/avidec.c	(working copy)
@@ -957,7 +957,7 @@
 
     if (ENABLE_DV_DEMUXER && avi->dv_demux) {
         /* One and only one real stream for DV in AVI, and it has video  */
-        /* offsets. Calling with other stream indices should have failed */
+        /* offsets. Calling with other stream indexes should have failed */
         /* the av_index_search_timestamp call above.                     */
         assert(stream_index == 0);
 
Index: mythtv/libs/libavformat/avformat.h
===================================================================
--- mythtv/libs/libavformat/avformat.h	(revision 18209)
+++ mythtv/libs/libavformat/avformat.h	(working copy)
@@ -198,9 +198,9 @@
     /** size of private data so that it can be allocated in the wrapper */
     int priv_data_size;
     /**
-     * tell if a given file has a chance of being parsed by this format.
-     * The buffer provided is guranteed to be AVPROBE_PADDING_SIZE bytes big
-     * so you dont have to check for that unless you need more.
+     * Tell if a given file has a chance of being parsed by this format.
+     * The buffer provided is guaranteed to be AVPROBE_PADDING_SIZE bytes
+     * big so you do not have to check for that unless you need more.
      */
     int (*read_probe)(AVProbeData *);
     /** read the format header and initialize the AVFormatContext
Index: mythtv/libs/libavformat/rmenc.c
===================================================================
--- mythtv/libs/libavformat/rmenc.c	(revision 18209)
+++ mythtv/libs/libavformat/rmenc.c	(working copy)
@@ -403,7 +403,7 @@
         put_be16(pb, 0);
 
         for(i=0;i<s->nb_streams;i++) {
-            put_be32(pb, 0); /* zero indices */
+            put_be32(pb, 0); /* zero indexes */
             put_be16(pb, i); /* stream number */
             put_be32(pb, 0); /* next index */
         }
Index: mythtv/libs/libavformat/asf.h
===================================================================
--- mythtv/libs/libavformat/asf.h	(revision 18209)
+++ mythtv/libs/libavformat/asf.h	(working copy)
@@ -56,7 +56,7 @@
     uint64_t send_time;         /**< time to send file, in 100-nanosecond units
                                  *   invalid if broadcasting (could be ignored) */
     uint32_t preroll;           /**< timestamp of the first packet, in milliseconds
-                                 *   if nonzero - substract from time */
+                                 *   if nonzero - subtract from time */
     uint32_t ignore;            ///< preroll is 64bit - but let's just ignore it
     uint32_t flags;             /**< 0x01 - broadcast
                                  *   0x02 - seekable
Index: mythtv/libs/libavformat/nsvdec.c
===================================================================
--- mythtv/libs/libavformat/nsvdec.c	(revision 18209)
+++ mythtv/libs/libavformat/nsvdec.c	(working copy)
@@ -140,7 +140,7 @@
 #define TB_NSVF MKBETAG('N', 'S', 'V', 'f')
 #define TB_NSVS MKBETAG('N', 'S', 'V', 's')
 
-/* hardcoded stream indices */
+/* hardcoded stream indexes */
 #define NSV_ST_VIDEO 0
 #define NSV_ST_AUDIO 1
 #define NSV_ST_SUBT 2
Index: mythtv/libs/libavformat/segafilm.c
===================================================================
--- mythtv/libs/libavformat/segafilm.c	(revision 18209)
+++ mythtv/libs/libavformat/segafilm.c	(working copy)
@@ -107,7 +107,7 @@
         /* normal Saturn .cpk files; 32-byte header */
         if (get_buffer(pb, scratch, 32) != 32)
             return AVERROR(EIO);
-        film->audio_samplerate = AV_RB16(&scratch[24]);;
+        film->audio_samplerate = AV_RB16(&scratch[24]);
         film->audio_channels = scratch[21];
         film->audio_bits = scratch[22];
         if (film->audio_bits == 8)
